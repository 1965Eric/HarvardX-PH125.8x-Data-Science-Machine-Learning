<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Section 3 - Linear Regression for Prediction, Smoothing, and Working with Matrices Overview | Data Science Machine Learning</title>
  <meta name="description" content="4 Section 3 - Linear Regression for Prediction, Smoothing, and Working with Matrices Overview | Data Science Machine Learning" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Section 3 - Linear Regression for Prediction, Smoothing, and Working with Matrices Overview | Data Science Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Section 3 - Linear Regression for Prediction, Smoothing, and Working with Matrices Overview | Data Science Machine Learning" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="section-2-machine-learning-basics-overview.html"/>
<link rel="next" href="section-4-distance-knn-cross-validation-and-generative-models.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="learning-objectives.html"><a href="learning-objectives.html"><i class="fa fa-check"></i><b>1</b> Learning Objectives</a>
<ul>
<li class="chapter" data-level="1.1" data-path="learning-objectives.html"><a href="learning-objectives.html#course-overview"><i class="fa fa-check"></i><b>1.1</b> Course Overview</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="learning-objectives.html"><a href="learning-objectives.html#introduction-to-machine-learning"><i class="fa fa-check"></i><b>1.1.1</b> Introduction to Machine Learning</a></li>
<li class="chapter" data-level="1.1.2" data-path="learning-objectives.html"><a href="learning-objectives.html#machine-learning-basics"><i class="fa fa-check"></i><b>1.1.2</b> Machine Learning Basics</a></li>
<li class="chapter" data-level="1.1.3" data-path="learning-objectives.html"><a href="learning-objectives.html#linear-regression-for-prediction-smoothing-and-working-with-matrices"><i class="fa fa-check"></i><b>1.1.3</b> Linear Regression for Prediction, Smoothing, and Working with Matrices</a></li>
<li class="chapter" data-level="1.1.4" data-path="learning-objectives.html"><a href="learning-objectives.html#distance-knn-cross-validation-and-generative-models"><i class="fa fa-check"></i><b>1.1.4</b> Distance, Knn, Cross Validation, and Generative Models</a></li>
<li class="chapter" data-level="1.1.5" data-path="learning-objectives.html"><a href="learning-objectives.html#classification-with-more-than-two-classes-and-the-caret-package"><i class="fa fa-check"></i><b>1.1.5</b> Classification with More than Two Classes and the Caret Package</a></li>
<li class="chapter" data-level="1.1.6" data-path="learning-objectives.html"><a href="learning-objectives.html#model-fitting-and-recommendation-systems"><i class="fa fa-check"></i><b>1.1.6</b> Model Fitting and Recommendation Systems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="section-1-introduction-to-machine-learning-overview.html"><a href="section-1-introduction-to-machine-learning-overview.html"><i class="fa fa-check"></i><b>2</b> Section 1 - Introduction to Machine Learning Overview</a>
<ul>
<li class="chapter" data-level="2.1" data-path="section-1-introduction-to-machine-learning-overview.html"><a href="section-1-introduction-to-machine-learning-overview.html#notation"><i class="fa fa-check"></i><b>2.1</b> Notation</a></li>
<li class="chapter" data-level="2.2" data-path="section-1-introduction-to-machine-learning-overview.html"><a href="section-1-introduction-to-machine-learning-overview.html#an-example"><i class="fa fa-check"></i><b>2.2</b> An Example</a></li>
<li class="chapter" data-level="2.3" data-path="section-1-introduction-to-machine-learning-overview.html"><a href="section-1-introduction-to-machine-learning-overview.html#comprehension-check---introduction-to-machine-learning"><i class="fa fa-check"></i><b>2.3</b> Comprehension Check - Introduction to Machine Learning</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html"><i class="fa fa-check"></i><b>3</b> Section 2 - Machine Learning Basics Overview</a>
<ul>
<li class="chapter" data-level="3.1" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#caret-package-training-and-test-sets-and-overall-accuracy"><i class="fa fa-check"></i><b>3.1</b> Caret package, training and test sets, and overall accuracy</a></li>
<li class="chapter" data-level="3.2" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#comprehension-check---basics-of-evaluating-machine-learning-algorithms"><i class="fa fa-check"></i><b>3.2</b> Comprehension Check - Basics of Evaluating Machine Learning Algorithms</a></li>
<li class="chapter" data-level="3.3" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#confusion-matrix"><i class="fa fa-check"></i><b>3.3</b> Confusion matrix</a></li>
<li class="chapter" data-level="3.4" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#balanced-accuracy-and-f1-score"><i class="fa fa-check"></i><b>3.4</b> Balanced accuracy and F1 score</a></li>
<li class="chapter" data-level="3.5" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#prevalence-matters-in-practice"><i class="fa fa-check"></i><b>3.5</b> Prevalence matters in practice</a></li>
<li class="chapter" data-level="3.6" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#roc-and-precision-recall-curves"><i class="fa fa-check"></i><b>3.6</b> ROC and precision-recall curves</a></li>
<li class="chapter" data-level="3.7" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#comprehension-check---practice-with-machine-learning-part-1"><i class="fa fa-check"></i><b>3.7</b> Comprehension Check - Practice with Machine Learning, Part 1</a></li>
<li class="chapter" data-level="3.8" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#comprehension-check---practice-with-machine-learning-part-2"><i class="fa fa-check"></i><b>3.8</b> Comprehension Check - Practice with Machine Learning, Part 2</a></li>
<li class="chapter" data-level="3.9" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#conditional-probabilities"><i class="fa fa-check"></i><b>3.9</b> Conditional probabilities</a></li>
<li class="chapter" data-level="3.10" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#conditional-expectations-and-loss-function"><i class="fa fa-check"></i><b>3.10</b> Conditional expectations and loss function</a></li>
<li class="chapter" data-level="3.11" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#comprehension-check---conditional-probabilities-part-1"><i class="fa fa-check"></i><b>3.11</b> Comprehension Check - Conditional Probabilities, Part 1</a></li>
<li class="chapter" data-level="3.12" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#comprehension-check---conditional-probabilities-part-2"><i class="fa fa-check"></i><b>3.12</b> Comprehension Check - Conditional Probabilities, Part 2</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><i class="fa fa-check"></i><b>4</b> Section 3 - Linear Regression for Prediction, Smoothing, and Working with Matrices Overview</a>
<ul>
<li class="chapter" data-level="4.1" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#linear-regression-for-prediction"><i class="fa fa-check"></i><b>4.1</b> Linear Regression for Prediction</a></li>
<li class="chapter" data-level="4.2" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#predict-function"><i class="fa fa-check"></i><b>4.2</b> Predict Function</a></li>
<li class="chapter" data-level="4.3" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#comprehension-check---linear-regression"><i class="fa fa-check"></i><b>4.3</b> Comprehension Check - Linear Regression</a></li>
<li class="chapter" data-level="4.4" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#regression-for-a-categorical-outcome"><i class="fa fa-check"></i><b>4.4</b> Regression for a Categorical Outcome</a></li>
<li class="chapter" data-level="4.5" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#logistic-regression"><i class="fa fa-check"></i><b>4.5</b> Logistic Regression</a></li>
<li class="chapter" data-level="4.6" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#case-study-2-or-7"><i class="fa fa-check"></i><b>4.6</b> Case Study: 2 or 7</a></li>
<li class="chapter" data-level="4.7" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#comprehension-check---logistic-regression"><i class="fa fa-check"></i><b>4.7</b> Comprehension Check - Logistic Regression</a></li>
<li class="chapter" data-level="4.8" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#introduction-to-smoothing"><i class="fa fa-check"></i><b>4.8</b> Introduction to Smoothing</a></li>
<li class="chapter" data-level="4.9" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#bin-smoothing-and-kernels"><i class="fa fa-check"></i><b>4.9</b> Bin Smoothing and Kernels</a></li>
<li class="chapter" data-level="4.10" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#local-weighted-regression-loess"><i class="fa fa-check"></i><b>4.10</b> Local Weighted Regression (loess)</a></li>
<li class="chapter" data-level="4.11" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#comprehension-check---smoothing"><i class="fa fa-check"></i><b>4.11</b> Comprehension Check - Smoothing</a></li>
<li class="chapter" data-level="4.12" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#matrices"><i class="fa fa-check"></i><b>4.12</b> Matrices</a></li>
<li class="chapter" data-level="4.13" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#matrix-notation"><i class="fa fa-check"></i><b>4.13</b> Matrix Notation</a></li>
<li class="chapter" data-level="4.14" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#converting-a-vector-to-a-matrix"><i class="fa fa-check"></i><b>4.14</b> Converting a Vector to a Matrix</a></li>
<li class="chapter" data-level="4.15" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#row-and-column-summaries-and-apply"><i class="fa fa-check"></i><b>4.15</b> Row and Column Summaries and Apply</a></li>
<li class="chapter" data-level="4.16" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#filtering-columns-based-on-summaries"><i class="fa fa-check"></i><b>4.16</b> Filtering Columns Based on Summaries</a></li>
<li class="chapter" data-level="4.17" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#indexing-with-matrices-and-binarizing-the-data"><i class="fa fa-check"></i><b>4.17</b> Indexing with Matrices and Binarizing the Data</a></li>
<li class="chapter" data-level="4.18" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#vectorization-for-matrices-and-matrix-algebra-operations"><i class="fa fa-check"></i><b>4.18</b> Vectorization for Matrices and Matrix Algebra Operations</a></li>
<li class="chapter" data-level="4.19" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#comprehension-check---working-with-matrices"><i class="fa fa-check"></i><b>4.19</b> Comprehension Check - Working with Matrices</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html"><i class="fa fa-check"></i><b>5</b> Section 4 - Distance, Knn, Cross Validation, and Generative Models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#distance"><i class="fa fa-check"></i><b>5.1</b> Distance</a></li>
<li class="chapter" data-level="5.2" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#comprehension-check---distance"><i class="fa fa-check"></i><b>5.2</b> Comprehension Check - Distance</a></li>
<li class="chapter" data-level="5.3" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#knn"><i class="fa fa-check"></i><b>5.3</b> Knn</a></li>
<li class="chapter" data-level="5.4" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#over-training-and-over-smoothing"><i class="fa fa-check"></i><b>5.4</b> Over-training and Over-smoothing</a></li>
<li class="chapter" data-level="5.5" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#comprehension-check---nearest-neighbors"><i class="fa fa-check"></i><b>5.5</b> Comprehension Check - Nearest Neighbors</a></li>
<li class="chapter" data-level="5.6" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>5.6</b> K-fold cross validation</a></li>
<li class="chapter" data-level="5.7" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#comprehension-check---cross-validation"><i class="fa fa-check"></i><b>5.7</b> Comprehension Check - Cross-validation</a></li>
<li class="chapter" data-level="5.8" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#bootstrap"><i class="fa fa-check"></i><b>5.8</b> Bootstrap</a></li>
<li class="chapter" data-level="5.9" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#comprehension-check---bootstrap"><i class="fa fa-check"></i><b>5.9</b> Comprehension Check - Bootstrap</a></li>
<li class="chapter" data-level="5.10" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#generative-models"><i class="fa fa-check"></i><b>5.10</b> Generative Models</a></li>
<li class="chapter" data-level="5.11" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#naive-bayes"><i class="fa fa-check"></i><b>5.11</b> Naive Bayes</a></li>
<li class="chapter" data-level="5.12" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#controlling-prevalence"><i class="fa fa-check"></i><b>5.12</b> Controlling Prevalence</a></li>
<li class="chapter" data-level="5.13" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#qda-and-lda"><i class="fa fa-check"></i><b>5.13</b> qda and lda</a></li>
<li class="chapter" data-level="5.14" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#case-study---more-than-three-classes"><i class="fa fa-check"></i><b>5.14</b> Case Study - More than Three Classes</a></li>
<li class="chapter" data-level="5.15" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#comprehension-check---generative-models"><i class="fa fa-check"></i><b>5.15</b> Comprehension Check - Generative Models</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><i class="fa fa-check"></i><b>6</b> Section 5 - Classification with More than Two Classes and the Caret Package</a>
<ul>
<li class="chapter" data-level="6.1" data-path="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html#trees-motivation"><i class="fa fa-check"></i><b>6.1</b> Trees Motivation</a></li>
<li class="chapter" data-level="6.2" data-path="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html#classification-and-regression-trees-cart"><i class="fa fa-check"></i><b>6.2</b> Classification and Regression Trees (CART)</a></li>
<li class="chapter" data-level="6.3" data-path="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html#classification-decision-trees"><i class="fa fa-check"></i><b>6.3</b> Classification (Decision) Trees</a></li>
<li class="chapter" data-level="6.4" data-path="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html#random-forests"><i class="fa fa-check"></i><b>6.4</b> Random Forests</a></li>
<li class="chapter" data-level="6.5" data-path="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html#comprehension-check---trees-and-random-forests"><i class="fa fa-check"></i><b>6.5</b> Comprehension Check - Trees and Random Forests</a></li>
<li class="chapter" data-level="6.6" data-path="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html#caret-package"><i class="fa fa-check"></i><b>6.6</b> Caret Package</a></li>
<li class="chapter" data-level="6.7" data-path="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html#tuning-parameters-with-caret"><i class="fa fa-check"></i><b>6.7</b> Tuning Parameters with Caret</a></li>
<li class="chapter" data-level="6.8" data-path="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html#comprehension-check---caret-package"><i class="fa fa-check"></i><b>6.8</b> Comprehension Check - Caret Package</a></li>
<li class="chapter" data-level="6.9" data-path="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html#titanic-exercises---part-1"><i class="fa fa-check"></i><b>6.9</b> Titanic Exercises - Part 1</a></li>
<li class="chapter" data-level="6.10" data-path="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html#titanic-exercises---part-2"><i class="fa fa-check"></i><b>6.10</b> Titanic Exercises - Part 2</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html"><i class="fa fa-check"></i><b>7</b> Section 6 - Model Fitting and Recommendation Systems Overview</a>
<ul>
<li class="chapter" data-level="7.1" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#case-study-mnist"><i class="fa fa-check"></i><b>7.1</b> Case Study: MNIST</a></li>
<li class="chapter" data-level="7.2" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#preprocessing-mnist-data"><i class="fa fa-check"></i><b>7.2</b> Preprocessing MNIST Data</a></li>
<li class="chapter" data-level="7.3" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#model-fitting-for-mnist-data"><i class="fa fa-check"></i><b>7.3</b> Model Fitting for MNIST Data</a></li>
<li class="chapter" data-level="7.4" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#variable-importance"><i class="fa fa-check"></i><b>7.4</b> Variable Importance</a></li>
<li class="chapter" data-level="7.5" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#ensembles"><i class="fa fa-check"></i><b>7.5</b> Ensembles</a></li>
<li class="chapter" data-level="7.6" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#comprehension-check---ensembles"><i class="fa fa-check"></i><b>7.6</b> Comprehension Check - Ensembles</a></li>
<li class="chapter" data-level="7.7" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#recommendation-systems"><i class="fa fa-check"></i><b>7.7</b> Recommendation Systems</a></li>
<li class="chapter" data-level="7.8" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#building-the-recommendation-system"><i class="fa fa-check"></i><b>7.8</b> Building the Recommendation System</a></li>
<li class="chapter" data-level="7.9" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#comprehension-check---recommendation-systems"><i class="fa fa-check"></i><b>7.9</b> Comprehension Check - Recommendation Systems</a></li>
<li class="chapter" data-level="7.10" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#regularization"><i class="fa fa-check"></i><b>7.10</b> Regularization</a></li>
<li class="chapter" data-level="7.11" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#comprehension-check---regularization"><i class="fa fa-check"></i><b>7.11</b> Comprehension Check - Regularization</a></li>
<li class="chapter" data-level="7.12" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#matrix-factorization"><i class="fa fa-check"></i><b>7.12</b> Matrix Factorization</a></li>
<li class="chapter" data-level="7.13" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#svd-and-pca"><i class="fa fa-check"></i><b>7.13</b> SVD and PCA</a></li>
<li class="chapter" data-level="7.14" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#comprehension-check---matrix-factorization"><i class="fa fa-check"></i><b>7.14</b> Comprehension Check - Matrix Factorization</a></li>
<li class="chapter" data-level="7.15" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#comprehension-check---dimension-reduction"><i class="fa fa-check"></i><b>7.15</b> Comprehension Check - Dimension Reduction</a></li>
<li class="chapter" data-level="7.16" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#comprehension-check---clustering"><i class="fa fa-check"></i><b>7.16</b> Comprehension Check - Clustering</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="section-7-final-assessment.html"><a href="section-7-final-assessment.html"><i class="fa fa-check"></i><b>8</b> Section 7 - Final Assessment</a>
<ul>
<li class="chapter" data-level="8.1" data-path="section-7-final-assessment.html"><a href="section-7-final-assessment.html#breast-cancer-project---part-1"><i class="fa fa-check"></i><b>8.1</b> Breast Cancer Project - Part 1</a></li>
<li class="chapter" data-level="8.2" data-path="section-7-final-assessment.html"><a href="section-7-final-assessment.html#breast-cancer-project---part-2"><i class="fa fa-check"></i><b>8.2</b> Breast Cancer Project - Part 2</a></li>
<li class="chapter" data-level="8.3" data-path="section-7-final-assessment.html"><a href="section-7-final-assessment.html#breast-cancer-project---part-3"><i class="fa fa-check"></i><b>8.3</b> Breast Cancer Project - Part 3</a></li>
<li class="chapter" data-level="8.4" data-path="section-7-final-assessment.html"><a href="section-7-final-assessment.html#breast-cancer-project---part-4"><i class="fa fa-check"></i><b>8.4</b> Breast Cancer Project - Part 4</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="section-3---linear-regression-for-prediction-smoothing-and-working-with-matrices-overview" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Section 3 - Linear Regression for Prediction, Smoothing, and Working with Matrices Overview</h1>
<p>In the <strong>Linear Regression for Prediction, Smoothing, and Working with Matrices Overview</strong> section, you will learn why linear regression is a useful baseline approach but is often insufficiently flexible for more complex analyses, how to smooth noisy data, and how to use matrices for machine learning.</p>
<p>After completing this section, you will be able to:</p>
<ul>
<li>Use <strong>linear regression for prediction</strong> as a baseline approach.</li>
<li>Use <strong>logistic regression</strong> for categorical data.</li>
<li>Detect trends in noisy data using <strong>smoothing</strong> (also known as <strong>curve fitting</strong> or <strong>low pass filtering</strong>).</li>
<li>Convert predictors to <strong>matrices</strong> and outcomes to <strong>vectors</strong> when all predictors are numeric (or can be converted to numerics in a meaningful way).</li>
<li>Perform basic <strong>matrix algebra</strong> calculations.</li>
</ul>
<p>This section has three parts: <strong>linear regression for prediction</strong>, <strong>smoothing</strong>, and <strong>working with matrices</strong>.</p>
<div id="linear-regression-for-prediction" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Linear Regression for Prediction</h2>
<p>There is a link to the relevant section of the textbook: <a href="https://rafalab.github.io/dsbook/examples-of-algorithms.html#linear-regression" target="_blank">Linear regression for prediction</a></p>
<p><strong>Key points</strong></p>
<ul>
<li>Linear regression can be considered a machine learning algorithm. Although it can be too rigid to be useful, it works rather well for some challenges. It also serves as a baseline approach: if you canâ€™t beat it with a more complex approach, you probably want to stick to linear regression.</li>
</ul>
<p><em>Code</em></p>
<p>Note: the seed was not set before <code>createDataPartition</code> so your results may be different.</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb135-1" aria-hidden="true"></a><span class="cf">if</span>(<span class="op">!</span><span class="kw">require</span>(HistData)) <span class="kw">install.packages</span>(<span class="st">&quot;HistData&quot;</span>)</span></code></pre></div>
<pre><code>## Loading required package: HistData</code></pre>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb137-1" aria-hidden="true"></a><span class="kw">library</span>(HistData)</span>
<span id="cb137-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb137-2" aria-hidden="true"></a></span>
<span id="cb137-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb137-3" aria-hidden="true"></a>galton_heights &lt;-<span class="st"> </span>GaltonFamilies <span class="op">%&gt;%</span></span>
<span id="cb137-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb137-4" aria-hidden="true"></a><span class="st">  </span><span class="kw">filter</span>(childNum <span class="op">==</span><span class="st"> </span><span class="dv">1</span> <span class="op">&amp;</span><span class="st"> </span>gender <span class="op">==</span><span class="st"> &quot;male&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb137-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb137-5" aria-hidden="true"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(father, childHeight) <span class="op">%&gt;%</span></span>
<span id="cb137-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb137-6" aria-hidden="true"></a><span class="st">  </span><span class="kw">rename</span>(<span class="dt">son =</span> childHeight)</span>
<span id="cb137-7"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb137-7" aria-hidden="true"></a></span>
<span id="cb137-8"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb137-8" aria-hidden="true"></a>y &lt;-<span class="st"> </span>galton_heights<span class="op">$</span>son</span>
<span id="cb137-9"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb137-9" aria-hidden="true"></a>test_index &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(y, <span class="dt">times =</span> <span class="dv">1</span>, <span class="dt">p =</span> <span class="fl">0.5</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)</span>
<span id="cb137-10"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb137-10" aria-hidden="true"></a></span>
<span id="cb137-11"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb137-11" aria-hidden="true"></a>train_set &lt;-<span class="st"> </span>galton_heights <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="op">-</span>test_index)</span>
<span id="cb137-12"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb137-12" aria-hidden="true"></a>test_set &lt;-<span class="st"> </span>galton_heights <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(test_index)</span>
<span id="cb137-13"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb137-13" aria-hidden="true"></a></span>
<span id="cb137-14"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb137-14" aria-hidden="true"></a>avg &lt;-<span class="st"> </span><span class="kw">mean</span>(train_set<span class="op">$</span>son)</span>
<span id="cb137-15"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb137-15" aria-hidden="true"></a>avg</span></code></pre></div>
<pre><code>## [1] 70.50114</code></pre>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb139-1" aria-hidden="true"></a><span class="kw">mean</span>((avg <span class="op">-</span><span class="st"> </span>test_set<span class="op">$</span>son)<span class="op">^</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 6.034931</code></pre>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb141-1" aria-hidden="true"></a><span class="co"># fit linear regression model</span></span>
<span id="cb141-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb141-2" aria-hidden="true"></a>fit &lt;-<span class="st"> </span><span class="kw">lm</span>(son <span class="op">~</span><span class="st"> </span>father, <span class="dt">data =</span> train_set)</span>
<span id="cb141-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb141-3" aria-hidden="true"></a>fit<span class="op">$</span>coef</span></code></pre></div>
<pre><code>## (Intercept)      father 
##  34.8934373   0.5170499</code></pre>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb143-1" aria-hidden="true"></a>y_hat &lt;-<span class="st"> </span>fit<span class="op">$</span>coef[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>fit<span class="op">$</span>coef[<span class="dv">2</span>]<span class="op">*</span>test_set<span class="op">$</span>father</span>
<span id="cb143-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb143-2" aria-hidden="true"></a><span class="kw">mean</span>((y_hat <span class="op">-</span><span class="st"> </span>test_set<span class="op">$</span>son)<span class="op">^</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 4.632629</code></pre>
</div>
<div id="predict-function" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Predict Function</h2>
<p>There is a link to the relevant section of the textbook: <a href="https://rafalab.github.io/dsbook/examples-of-algorithms.html#the-predict-function" target="_blank">Predict function</a></p>
<p><strong>Key points</strong></p>
<ul>
<li>The <code>predict()</code> function takes a fitted object from functions such as <code>lm()</code> or <code>glm()</code> and a data frame with the new predictors for which to predict. We can use predict like this:</li>
</ul>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb145-1" aria-hidden="true"></a>y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, test_set)</span></code></pre></div>
<ul>
<li><code>predict()</code> is a generic function in R that calls other functions depending on what kind of object it receives. To learn about the specifics, you can read the help files using code like this:</li>
</ul>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb146-1" aria-hidden="true"></a>?predict.lm    <span class="co"># or ?predict.glm</span></span></code></pre></div>
<p><em>Code</em></p>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb147-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb147-1" aria-hidden="true"></a>y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, test_set)</span>
<span id="cb147-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb147-2" aria-hidden="true"></a><span class="kw">mean</span>((y_hat <span class="op">-</span><span class="st"> </span>test_set<span class="op">$</span>son)<span class="op">^</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 4.632629</code></pre>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb149-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb149-1" aria-hidden="true"></a><span class="co"># read help files</span></span>
<span id="cb149-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb149-2" aria-hidden="true"></a>?predict.lm</span>
<span id="cb149-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb149-3" aria-hidden="true"></a>?predict.glm</span></code></pre></div>
</div>
<div id="comprehension-check---linear-regression" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Comprehension Check - Linear Regression</h2>
<ol style="list-style-type: decimal">
<li>Create a data set using the following code:</li>
</ol>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb150-1" aria-hidden="true"></a><span class="co"># set.seed(1) # if using R 3.5 or earlier</span></span>
<span id="cb150-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb150-2" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">1</span>, <span class="dt">sample.kind=</span><span class="st">&quot;Rounding&quot;</span>) <span class="co"># if using R 3.6 or later</span></span></code></pre></div>
<pre><code>## Warning in set.seed(1, sample.kind = &quot;Rounding&quot;): non-uniform &#39;Rounding&#39; sampler used</code></pre>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb152-1" aria-hidden="true"></a>n &lt;-<span class="st"> </span><span class="dv">100</span></span>
<span id="cb152-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb152-2" aria-hidden="true"></a>Sigma &lt;-<span class="st"> </span><span class="dv">9</span><span class="op">*</span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="fl">1.0</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">1.0</span>), <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb152-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb152-3" aria-hidden="true"></a>dat &lt;-<span class="st"> </span>MASS<span class="op">::</span><span class="kw">mvrnorm</span>(<span class="dt">n =</span> <span class="dv">100</span>, <span class="kw">c</span>(<span class="dv">69</span>, <span class="dv">69</span>), Sigma) <span class="op">%&gt;%</span></span>
<span id="cb152-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb152-4" aria-hidden="true"></a><span class="st">      </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">setNames</span>(<span class="kw">c</span>(<span class="st">&quot;x&quot;</span>, <span class="st">&quot;y&quot;</span>))</span></code></pre></div>
<p>We will build 100 linear models using the data above and calculate the mean and standard deviation of the combined models. First, set the seed to 1 again (make sure to use <code>sample.kind="Rounding"</code> if your R is version 3.6 or later). Then, within a <code>replicate()</code> loop, (1) partition the dataset into test and training sets with <code>p = 0.5</code> and using <code>dat$y</code> to generate your indices, (2) train a linear model predicting <code>y</code> from <code>x</code>, (3) generate predictions on the test set, and (4) calculate the RMSE of that model. Then, report the mean and standard deviation (SD) of the RMSEs from all 100 models.</p>
<p>Report all answers to at least 3 significant digits.</p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb153-1" aria-hidden="true"></a><span class="co"># set.seed(1) # if using R 3.5 or earlier</span></span>
<span id="cb153-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb153-2" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">1</span>, <span class="dt">sample.kind=</span><span class="st">&quot;Rounding&quot;</span>) <span class="co"># if using R 3.6 or later</span></span></code></pre></div>
<pre><code>## Warning in set.seed(1, sample.kind = &quot;Rounding&quot;): non-uniform &#39;Rounding&#39; sampler used</code></pre>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb155-1" aria-hidden="true"></a>rmse &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">100</span>, {</span>
<span id="cb155-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb155-2" aria-hidden="true"></a>    test_index &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(dat<span class="op">$</span>y, <span class="dt">times =</span> <span class="dv">1</span>, <span class="dt">p =</span> <span class="fl">0.5</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)</span>
<span id="cb155-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb155-3" aria-hidden="true"></a>    train_set &lt;-<span class="st"> </span>dat <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="op">-</span>test_index)</span>
<span id="cb155-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb155-4" aria-hidden="true"></a>    test_set &lt;-<span class="st"> </span>dat <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(test_index)</span>
<span id="cb155-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb155-5" aria-hidden="true"></a>    fit &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data =</span> train_set)</span>
<span id="cb155-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb155-6" aria-hidden="true"></a>    y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, <span class="dt">newdata =</span> test_set)</span>
<span id="cb155-7"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb155-7" aria-hidden="true"></a>    <span class="kw">sqrt</span>(<span class="kw">mean</span>((y_hat<span class="op">-</span>test_set<span class="op">$</span>y)<span class="op">^</span><span class="dv">2</span>))</span>
<span id="cb155-8"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb155-8" aria-hidden="true"></a>})</span>
<span id="cb155-9"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb155-9" aria-hidden="true"></a></span>
<span id="cb155-10"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb155-10" aria-hidden="true"></a><span class="kw">mean</span>(rmse)</span></code></pre></div>
<pre><code>## [1] 2.488661</code></pre>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb157-1" aria-hidden="true"></a><span class="kw">sd</span>(rmse)</span></code></pre></div>
<pre><code>## [1] 0.1243952</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Now we will repeat the exercise above but using larger datasets. Write a function that takes a size <code>n</code>, then (1) builds a dataset using the code provided at the top of Q1 but with <code>n</code> observations instead of 100 and without the <code>set.seed(1)</code>, (2) runs the <code>replicate()</code> loop that you wrote to answer Q1, which builds 100 linear models and returns a vector of RMSEs, and (3) calculates the mean and standard deviation of the 100 RMSEs.</li>
</ol>
<p>Set the seed to 1 (if using R 3.6 or later, use the argument <code>sample.kind="Rounding")</code> and then use <code>sapply()</code> or <code>map()</code> to apply your new function to <code>n &lt;- c(100, 500, 1000, 5000, 10000)</code>.</p>
<p>Hint: You only need to set the seed once before running your function; do not set a seed within your function. Also be sure to use <code>sapply()</code> or <code>map()</code> as you will get different answers running the simulations individually due to setting the seed.</p>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb159-1" aria-hidden="true"></a><span class="co"># set.seed(1) # if R 3.5 or earlier</span></span>
<span id="cb159-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb159-2" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">1</span>, <span class="dt">sample.kind=</span><span class="st">&quot;Rounding&quot;</span>) <span class="co"># if R 3.6 or later</span></span></code></pre></div>
<pre><code>## Warning in set.seed(1, sample.kind = &quot;Rounding&quot;): non-uniform &#39;Rounding&#39; sampler used</code></pre>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb161-1" aria-hidden="true"></a>n &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">100</span>, <span class="dv">500</span>, <span class="dv">1000</span>, <span class="dv">5000</span>, <span class="dv">10000</span>)</span>
<span id="cb161-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb161-2" aria-hidden="true"></a>res &lt;-<span class="st"> </span><span class="kw">sapply</span>(n, <span class="cf">function</span>(n){</span>
<span id="cb161-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb161-3" aria-hidden="true"></a>    Sigma &lt;-<span class="st"> </span><span class="dv">9</span><span class="op">*</span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="fl">1.0</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">1.0</span>), <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb161-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb161-4" aria-hidden="true"></a>    dat &lt;-<span class="st"> </span>MASS<span class="op">::</span><span class="kw">mvrnorm</span>(n, <span class="kw">c</span>(<span class="dv">69</span>, <span class="dv">69</span>), Sigma) <span class="op">%&gt;%</span></span>
<span id="cb161-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb161-5" aria-hidden="true"></a><span class="st">        </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">setNames</span>(<span class="kw">c</span>(<span class="st">&quot;x&quot;</span>, <span class="st">&quot;y&quot;</span>))</span>
<span id="cb161-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb161-6" aria-hidden="true"></a>    rmse &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">100</span>, {</span>
<span id="cb161-7"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb161-7" aria-hidden="true"></a>        test_index &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(dat<span class="op">$</span>y, <span class="dt">times =</span> <span class="dv">1</span>, <span class="dt">p =</span> <span class="fl">0.5</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)</span>
<span id="cb161-8"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb161-8" aria-hidden="true"></a>        train_set &lt;-<span class="st"> </span>dat <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="op">-</span>test_index)</span>
<span id="cb161-9"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb161-9" aria-hidden="true"></a>        test_set &lt;-<span class="st"> </span>dat <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(test_index)</span>
<span id="cb161-10"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb161-10" aria-hidden="true"></a>        fit &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data =</span> train_set)</span>
<span id="cb161-11"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb161-11" aria-hidden="true"></a>        y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, <span class="dt">newdata =</span> test_set)</span>
<span id="cb161-12"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb161-12" aria-hidden="true"></a>        <span class="kw">sqrt</span>(<span class="kw">mean</span>((y_hat<span class="op">-</span>test_set<span class="op">$</span>y)<span class="op">^</span><span class="dv">2</span>))</span>
<span id="cb161-13"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb161-13" aria-hidden="true"></a>    })</span>
<span id="cb161-14"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb161-14" aria-hidden="true"></a>    <span class="kw">c</span>(<span class="dt">avg =</span> <span class="kw">mean</span>(rmse), <span class="dt">sd =</span> <span class="kw">sd</span>(rmse))</span>
<span id="cb161-15"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb161-15" aria-hidden="true"></a>})</span>
<span id="cb161-16"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb161-16" aria-hidden="true"></a></span>
<span id="cb161-17"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb161-17" aria-hidden="true"></a>res</span></code></pre></div>
<pre><code>##          [,1]       [,2]       [,3]       [,4]       [,5]
## avg 2.4977540 2.72095125 2.55554451 2.62482800 2.61844227
## sd  0.1180821 0.08002108 0.04560258 0.02309673 0.01689205</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>What happens to the RMSE as the size of the dataset becomes larger?</li>
</ol>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
A. On average, the RMSE does not change much as n gets larger, but the variability of the RMSE decreases.</li>
<li><input type="checkbox" disabled="" />
B. Because of the law of large numbers the RMSE decreases; more data means more precise estimates.</li>
<li><input type="checkbox" disabled="" />
C. n = 10000 is not sufficiently large. To see a decrease in the RMSE we would need to make it larger.</li>
<li><input type="checkbox" disabled="" />
D. The RMSE is not a random variable.</li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>Now repeat the exercise from Q1, this time making the correlation between <code>x</code> and <code>y</code> larger, as in the following code:</li>
</ol>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb163-1" aria-hidden="true"></a><span class="co"># set.seed(1) # if using R 3.5 or earlier</span></span>
<span id="cb163-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb163-2" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">1</span>, <span class="dt">sample.kind=</span><span class="st">&quot;Rounding&quot;</span>) <span class="co"># if using R 3.6 or later</span></span></code></pre></div>
<pre><code>## Warning in set.seed(1, sample.kind = &quot;Rounding&quot;): non-uniform &#39;Rounding&#39; sampler used</code></pre>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb165-1" aria-hidden="true"></a>n &lt;-<span class="st"> </span><span class="dv">100</span></span>
<span id="cb165-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb165-2" aria-hidden="true"></a>Sigma &lt;-<span class="st"> </span><span class="dv">9</span><span class="op">*</span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="fl">1.0</span>, <span class="fl">0.95</span>, <span class="fl">0.95</span>, <span class="fl">1.0</span>), <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb165-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb165-3" aria-hidden="true"></a>dat &lt;-<span class="st"> </span>MASS<span class="op">::</span><span class="kw">mvrnorm</span>(<span class="dt">n =</span> <span class="dv">100</span>, <span class="kw">c</span>(<span class="dv">69</span>, <span class="dv">69</span>), Sigma) <span class="op">%&gt;%</span></span>
<span id="cb165-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb165-4" aria-hidden="true"></a><span class="st">    </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">setNames</span>(<span class="kw">c</span>(<span class="st">&quot;x&quot;</span>, <span class="st">&quot;y&quot;</span>))</span></code></pre></div>
<p>Note what happens to RMSE - set the seed to 1 as before.</p>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb166-1" aria-hidden="true"></a><span class="co"># set.seed(1) # if using R 3.5 or earlier</span></span>
<span id="cb166-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb166-2" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">1</span>, <span class="dt">sample.kind=</span><span class="st">&quot;Rounding&quot;</span>) <span class="co"># if using R 3.6 or later</span></span></code></pre></div>
<pre><code>## Warning in set.seed(1, sample.kind = &quot;Rounding&quot;): non-uniform &#39;Rounding&#39; sampler used</code></pre>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb168-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb168-1" aria-hidden="true"></a>rmse &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">100</span>, {</span>
<span id="cb168-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb168-2" aria-hidden="true"></a>    test_index &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(dat<span class="op">$</span>y, <span class="dt">times =</span> <span class="dv">1</span>, <span class="dt">p =</span> <span class="fl">0.5</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)</span>
<span id="cb168-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb168-3" aria-hidden="true"></a>    train_set &lt;-<span class="st"> </span>dat <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="op">-</span>test_index)</span>
<span id="cb168-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb168-4" aria-hidden="true"></a>    test_set &lt;-<span class="st"> </span>dat <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(test_index)</span>
<span id="cb168-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb168-5" aria-hidden="true"></a>    fit &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data =</span> train_set)</span>
<span id="cb168-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb168-6" aria-hidden="true"></a>    y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, <span class="dt">newdata =</span> test_set)</span>
<span id="cb168-7"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb168-7" aria-hidden="true"></a>    <span class="kw">sqrt</span>(<span class="kw">mean</span>((y_hat<span class="op">-</span>test_set<span class="op">$</span>y)<span class="op">^</span><span class="dv">2</span>))</span>
<span id="cb168-8"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb168-8" aria-hidden="true"></a>})</span>
<span id="cb168-9"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb168-9" aria-hidden="true"></a></span>
<span id="cb168-10"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb168-10" aria-hidden="true"></a><span class="kw">mean</span>(rmse)</span></code></pre></div>
<pre><code>## [1] 0.9099808</code></pre>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb170-1" aria-hidden="true"></a><span class="kw">sd</span>(rmse)</span></code></pre></div>
<pre><code>## [1] 0.06244347</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>Which of the following best explains why the RMSE in question 4 is so much lower than the RMSE in question 1?</li>
</ol>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
A. It is just luck. If we do it again, it will be larger.</li>
<li><input type="checkbox" disabled="" />
B. The central limit theorem tells us that the RMSE is normal.</li>
<li><input type="checkbox" disabled="" checked="" />
C. When we increase the correlation between x and y, x has more predictive power and thus provides a better estimate of y.</li>
<li><input type="checkbox" disabled="" />
D. These are both examples of regression so the RMSE has to be the same.</li>
</ul>
<ol start="6" style="list-style-type: decimal">
<li>Create a data set using the following code.</li>
</ol>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb172-1" aria-hidden="true"></a><span class="co"># set.seed(1) # if using R 3.5 or earlier</span></span>
<span id="cb172-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb172-2" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">1</span>, <span class="dt">sample.kind=</span><span class="st">&quot;Rounding&quot;</span>) <span class="co"># if using R 3.6 or later</span></span></code></pre></div>
<pre><code>## Warning in set.seed(1, sample.kind = &quot;Rounding&quot;): non-uniform &#39;Rounding&#39; sampler used</code></pre>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb174-1" aria-hidden="true"></a>Sigma &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="fl">1.0</span>, <span class="fl">0.75</span>, <span class="fl">0.75</span>, <span class="fl">0.75</span>, <span class="fl">1.0</span>, <span class="fl">0.25</span>, <span class="fl">0.75</span>, <span class="fl">0.25</span>, <span class="fl">1.0</span>), <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb174-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb174-2" aria-hidden="true"></a>dat &lt;-<span class="st"> </span>MASS<span class="op">::</span><span class="kw">mvrnorm</span>(<span class="dt">n =</span> <span class="dv">100</span>, <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>), Sigma) <span class="op">%&gt;%</span></span>
<span id="cb174-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb174-3" aria-hidden="true"></a><span class="st">    </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">setNames</span>(<span class="kw">c</span>(<span class="st">&quot;y&quot;</span>, <span class="st">&quot;x_1&quot;</span>, <span class="st">&quot;x_2&quot;</span>))</span></code></pre></div>
<p>Note that <code>y</code> is correlated with both <code>x_1</code> and <code>x_2</code> but the two predictors are independent of each other, as seen by <code>cor(dat)</code>.</p>
<p>Set the seed to 1, then use the <strong>caret</strong> package to partition into test and training sets with <code>p = 0.5</code>. Compare the RMSE when using just <code>x_1</code>, just <code>x_2</code> and both <code>x_1</code> and <code>x_2</code>. Train a single linear model for each (not 100 like in the previous questions).</p>
<p>Which of the three models performs the best (has the lowest RMSE)?</p>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb175-1" aria-hidden="true"></a><span class="co"># set.seed(1) # if using R 3.5 or earlier</span></span>
<span id="cb175-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb175-2" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">1</span>, <span class="dt">sample.kind=</span><span class="st">&quot;Rounding&quot;</span>) <span class="co"># if using R 3.6 or later</span></span></code></pre></div>
<pre><code>## Warning in set.seed(1, sample.kind = &quot;Rounding&quot;): non-uniform &#39;Rounding&#39; sampler used</code></pre>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb177-1" aria-hidden="true"></a>test_index &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(dat<span class="op">$</span>y, <span class="dt">times =</span> <span class="dv">1</span>, <span class="dt">p =</span> <span class="fl">0.5</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)</span>
<span id="cb177-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb177-2" aria-hidden="true"></a>train_set &lt;-<span class="st"> </span>dat <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="op">-</span>test_index)</span>
<span id="cb177-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb177-3" aria-hidden="true"></a>test_set &lt;-<span class="st"> </span>dat <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(test_index)</span>
<span id="cb177-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb177-4" aria-hidden="true"></a></span>
<span id="cb177-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb177-5" aria-hidden="true"></a>fit &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x_<span class="dv">1</span>, <span class="dt">data =</span> train_set)</span>
<span id="cb177-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb177-6" aria-hidden="true"></a>y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, <span class="dt">newdata =</span> test_set)</span>
<span id="cb177-7"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb177-7" aria-hidden="true"></a><span class="kw">sqrt</span>(<span class="kw">mean</span>((y_hat<span class="op">-</span>test_set<span class="op">$</span>y)<span class="op">^</span><span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] 0.600666</code></pre>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb179-1" aria-hidden="true"></a>fit &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x_<span class="dv">2</span>, <span class="dt">data =</span> train_set)</span>
<span id="cb179-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb179-2" aria-hidden="true"></a>y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, <span class="dt">newdata =</span> test_set)</span>
<span id="cb179-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb179-3" aria-hidden="true"></a><span class="kw">sqrt</span>(<span class="kw">mean</span>((y_hat<span class="op">-</span>test_set<span class="op">$</span>y)<span class="op">^</span><span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] 0.630699</code></pre>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb181-1" aria-hidden="true"></a>fit &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>x_<span class="dv">2</span>, <span class="dt">data =</span> train_set)</span>
<span id="cb181-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb181-2" aria-hidden="true"></a>y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, <span class="dt">newdata =</span> test_set)</span>
<span id="cb181-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb181-3" aria-hidden="true"></a><span class="kw">sqrt</span>(<span class="kw">mean</span>((y_hat<span class="op">-</span>test_set<span class="op">$</span>y)<span class="op">^</span><span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] 0.3070962</code></pre>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
A. <code>x_1</code></li>
<li><input type="checkbox" disabled="" />
B. <code>x_2</code></li>
<li><input type="checkbox" disabled="" checked="" />
C. <code>x_1</code> and <code>x_2</code></li>
</ul>
<ol start="7" style="list-style-type: decimal">
<li>Report the lowest RMSE of the three models tested in Q6.</li>
</ol>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb183-1" aria-hidden="true"></a>fit &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>x_<span class="dv">2</span>, <span class="dt">data =</span> train_set)</span>
<span id="cb183-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb183-2" aria-hidden="true"></a>y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, <span class="dt">newdata =</span> test_set)</span>
<span id="cb183-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb183-3" aria-hidden="true"></a><span class="kw">sqrt</span>(<span class="kw">mean</span>((y_hat<span class="op">-</span>test_set<span class="op">$</span>y)<span class="op">^</span><span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] 0.3070962</code></pre>
<ol start="8" style="list-style-type: decimal">
<li>Repeat the exercise from Q6 but now create an example in which <code>x_1</code> and <code>x_2</code> are highly correlated.</li>
</ol>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb185-1" aria-hidden="true"></a><span class="co"># set.seed(1) # if using R 3.5 or earlier</span></span>
<span id="cb185-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb185-2" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">1</span>, <span class="dt">sample.kind=</span><span class="st">&quot;Rounding&quot;</span>) <span class="co"># if using R 3.6 or later</span></span></code></pre></div>
<pre><code>## Warning in set.seed(1, sample.kind = &quot;Rounding&quot;): non-uniform &#39;Rounding&#39; sampler used</code></pre>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb187-1" aria-hidden="true"></a>Sigma &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="fl">1.0</span>, <span class="fl">0.75</span>, <span class="fl">0.75</span>, <span class="fl">0.75</span>, <span class="fl">1.0</span>, <span class="fl">0.95</span>, <span class="fl">0.75</span>, <span class="fl">0.95</span>, <span class="fl">1.0</span>), <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb187-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb187-2" aria-hidden="true"></a>dat &lt;-<span class="st"> </span>MASS<span class="op">::</span><span class="kw">mvrnorm</span>(<span class="dt">n =</span> <span class="dv">100</span>, <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>), Sigma) <span class="op">%&gt;%</span></span>
<span id="cb187-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb187-3" aria-hidden="true"></a><span class="st">    </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">setNames</span>(<span class="kw">c</span>(<span class="st">&quot;y&quot;</span>, <span class="st">&quot;x_1&quot;</span>, <span class="st">&quot;x_2&quot;</span>))</span></code></pre></div>
<p>Set the seed to 1, then use the <strong>caret</strong> package to partition into a test and training set of equal size. Compare the RMSE when using just <code>x_1</code>, just <code>x_2</code>, and both <code>x_1</code> and <code>x_2</code>.</p>
<p>Compare the results from Q6 and Q8. What can you conclude?</p>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb188-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb188-1" aria-hidden="true"></a><span class="co"># set.seed(1) # if using R 3.5 or earlier</span></span>
<span id="cb188-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb188-2" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">1</span>, <span class="dt">sample.kind=</span><span class="st">&quot;Rounding&quot;</span>) <span class="co"># if using R 3.6 or later</span></span></code></pre></div>
<pre><code>## Warning in set.seed(1, sample.kind = &quot;Rounding&quot;): non-uniform &#39;Rounding&#39; sampler used</code></pre>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb190-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb190-1" aria-hidden="true"></a>test_index &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(dat<span class="op">$</span>y, <span class="dt">times =</span> <span class="dv">1</span>, <span class="dt">p =</span> <span class="fl">0.5</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)</span>
<span id="cb190-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb190-2" aria-hidden="true"></a>train_set &lt;-<span class="st"> </span>dat <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="op">-</span>test_index)</span>
<span id="cb190-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb190-3" aria-hidden="true"></a>test_set &lt;-<span class="st"> </span>dat <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(test_index)</span>
<span id="cb190-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb190-4" aria-hidden="true"></a></span>
<span id="cb190-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb190-5" aria-hidden="true"></a>fit &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x_<span class="dv">1</span>, <span class="dt">data =</span> train_set)</span>
<span id="cb190-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb190-6" aria-hidden="true"></a>y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, <span class="dt">newdata =</span> test_set)</span>
<span id="cb190-7"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb190-7" aria-hidden="true"></a><span class="kw">sqrt</span>(<span class="kw">mean</span>((y_hat<span class="op">-</span>test_set<span class="op">$</span>y)<span class="op">^</span><span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] 0.6592608</code></pre>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb192-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb192-1" aria-hidden="true"></a>fit &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x_<span class="dv">2</span>, <span class="dt">data =</span> train_set)</span>
<span id="cb192-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb192-2" aria-hidden="true"></a>y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, <span class="dt">newdata =</span> test_set)</span>
<span id="cb192-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb192-3" aria-hidden="true"></a><span class="kw">sqrt</span>(<span class="kw">mean</span>((y_hat<span class="op">-</span>test_set<span class="op">$</span>y)<span class="op">^</span><span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] 0.640081</code></pre>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb194-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb194-1" aria-hidden="true"></a>fit &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>x_<span class="dv">2</span>, <span class="dt">data =</span> train_set)</span>
<span id="cb194-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb194-2" aria-hidden="true"></a>y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, <span class="dt">newdata =</span> test_set)</span>
<span id="cb194-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb194-3" aria-hidden="true"></a><span class="kw">sqrt</span>(<span class="kw">mean</span>((y_hat<span class="op">-</span>test_set<span class="op">$</span>y)<span class="op">^</span><span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] 0.6597865</code></pre>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
A. Unless we include all predictors we have no predictive power.</li>
<li><input type="checkbox" disabled="" />
B. Adding extra predictors improves RMSE regardless of whether the added predictors are correlated with other predictors or not.</li>
<li><input type="checkbox" disabled="" />
C. Adding extra predictors results in over fitting.</li>
<li><input type="checkbox" disabled="" checked="" />
D. Adding extra predictors can improve RMSE substantially, but not when the added predictors are highly correlated with other predictors.</li>
</ul>
</div>
<div id="regression-for-a-categorical-outcome" class="section level2" number="4.4">
<h2><span class="header-section-number">4.4</span> Regression for a Categorical Outcome</h2>
<p>There is a link to the relevant section of the textbook: <a href="https://rafalab.github.io/dsbook/examples-of-algorithms.html#logistic-regression" target="_blank">Regression for a categorical outcome</a></p>
<p><strong>Key points</strong></p>
<ul>
<li>The regression approach can be extended to categorical data. For example, we can try regression to estimate the conditional probability:</li>
</ul>
<p><span class="math inline">\(p(x)=Pr(Y=1|X=x)=\beta_{0}+\beta_{1}x\)</span></p>
<ul>
<li>Once we have estimates <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, we can obtain an actual prediction <span class="math inline">\(p(x)\)</span>. Then we can define a specific decision rule to form a prediction.</li>
</ul>
<p><em>Code</em></p>
<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb196-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb196-1" aria-hidden="true"></a><span class="kw">data</span>(<span class="st">&quot;heights&quot;</span>)</span>
<span id="cb196-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb196-2" aria-hidden="true"></a>y &lt;-<span class="st"> </span>heights<span class="op">$</span>height</span>
<span id="cb196-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb196-3" aria-hidden="true"></a></span>
<span id="cb196-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb196-4" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">2</span>) <span class="co">#if you are using R 3.5 or earlier</span></span>
<span id="cb196-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb196-5" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">2</span>, <span class="dt">sample.kind =</span> <span class="st">&quot;Rounding&quot;</span>) <span class="co">#if you are using R 3.6 or later</span></span></code></pre></div>
<pre><code>## Warning in set.seed(2, sample.kind = &quot;Rounding&quot;): non-uniform &#39;Rounding&#39; sampler used</code></pre>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb198-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb198-1" aria-hidden="true"></a>test_index &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(y, <span class="dt">times =</span> <span class="dv">1</span>, <span class="dt">p =</span> <span class="fl">0.5</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)</span>
<span id="cb198-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb198-2" aria-hidden="true"></a>train_set &lt;-<span class="st"> </span>heights <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="op">-</span>test_index)</span>
<span id="cb198-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb198-3" aria-hidden="true"></a>test_set &lt;-<span class="st"> </span>heights <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(test_index)</span>
<span id="cb198-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb198-4" aria-hidden="true"></a></span>
<span id="cb198-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb198-5" aria-hidden="true"></a>train_set <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb198-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb198-6" aria-hidden="true"></a><span class="st">  </span><span class="kw">filter</span>(<span class="kw">round</span>(height)<span class="op">==</span><span class="dv">66</span>) <span class="op">%&gt;%</span></span>
<span id="cb198-7"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb198-7" aria-hidden="true"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">y_hat =</span> <span class="kw">mean</span>(sex<span class="op">==</span><span class="st">&quot;Female&quot;</span>))</span></code></pre></div>
<pre><code>##       y_hat
## 1 0.2424242</code></pre>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb200-1" aria-hidden="true"></a>heights <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb200-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb200-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">x =</span> <span class="kw">round</span>(height)) <span class="op">%&gt;%</span></span>
<span id="cb200-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb200-3" aria-hidden="true"></a><span class="st">  </span><span class="kw">group_by</span>(x) <span class="op">%&gt;%</span></span>
<span id="cb200-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb200-4" aria-hidden="true"></a><span class="st">  </span><span class="kw">filter</span>(<span class="kw">n</span>() <span class="op">&gt;=</span><span class="st"> </span><span class="dv">10</span>) <span class="op">%&gt;%</span></span>
<span id="cb200-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb200-5" aria-hidden="true"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">prop =</span> <span class="kw">mean</span>(sex <span class="op">==</span><span class="st"> &quot;Female&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb200-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb200-6" aria-hidden="true"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(x, prop)) <span class="op">+</span></span>
<span id="cb200-7"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb200-7" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_point</span>()</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<p><img src="img/figures/unnamed-chunk-59-1.png" width="672" /></p>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb202-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb202-1" aria-hidden="true"></a>lm_fit &lt;-<span class="st"> </span><span class="kw">mutate</span>(train_set, <span class="dt">y =</span> <span class="kw">as.numeric</span>(sex <span class="op">==</span><span class="st"> &quot;Female&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>height, <span class="dt">data =</span> .)</span>
<span id="cb202-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb202-2" aria-hidden="true"></a>p_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(lm_fit, test_set)</span>
<span id="cb202-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb202-3" aria-hidden="true"></a>y_hat &lt;-<span class="st"> </span><span class="kw">ifelse</span>(p_hat <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.5</span>, <span class="st">&quot;Female&quot;</span>, <span class="st">&quot;Male&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">factor</span>()</span>
<span id="cb202-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb202-4" aria-hidden="true"></a><span class="kw">confusionMatrix</span>(y_hat, test_set<span class="op">$</span>sex)<span class="op">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span></code></pre></div>
<pre><code>##  Accuracy 
## 0.7851711</code></pre>
</div>
<div id="logistic-regression" class="section level2" number="4.5">
<h2><span class="header-section-number">4.5</span> Logistic Regression</h2>
<p>There is a link to the relevant section of the textbook: <a href="https://rafalab.github.io/dsbook/examples-of-algorithms.html#logistic-regression" target="_blank">Logistic regression</a></p>
<p><strong>Key points</strong></p>
<ul>
<li><strong>Logistic regression</strong> is an extension of linear regression that assures that the estimate of conditional probability <span class="math inline">\(Pr(Y=1|X=x)\)</span> is between 0 and 1. This approach makes use of the logistic transformation:</li>
</ul>
<p><span class="math inline">\(g(p)=log\frac{p}{1-p}\)</span></p>
<ul>
<li>With logistic regression, we model the conditional probability directly with:</li>
</ul>
<p><span class="math inline">\(g\{Pr(Y=1|X=x)\}=\beta_{0}+\beta_{1}x\)</span></p>
<ul>
<li>Note that with this model, we can no longer use least squares. Instead we compute the <strong>maximum likelihood estimate (MLE)</strong>.</li>
<li>In R, we can fit the logistic regression model with the function <code>glm()</code> (generalized linear models). If we want to compute the conditional probabilities, we want <code>type="response"</code> since the default is to return the logistic transformed values.</li>
</ul>
<p><em>Code</em></p>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb204-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb204-1" aria-hidden="true"></a>heights <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb204-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb204-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">x =</span> <span class="kw">round</span>(height)) <span class="op">%&gt;%</span></span>
<span id="cb204-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb204-3" aria-hidden="true"></a><span class="st">  </span><span class="kw">group_by</span>(x) <span class="op">%&gt;%</span></span>
<span id="cb204-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb204-4" aria-hidden="true"></a><span class="st">  </span><span class="kw">filter</span>(<span class="kw">n</span>() <span class="op">&gt;=</span><span class="st"> </span><span class="dv">10</span>) <span class="op">%&gt;%</span></span>
<span id="cb204-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb204-5" aria-hidden="true"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">prop =</span> <span class="kw">mean</span>(sex <span class="op">==</span><span class="st"> &quot;Female&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb204-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb204-6" aria-hidden="true"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(x, prop)) <span class="op">+</span></span>
<span id="cb204-7"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb204-7" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb204-8"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb204-8" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> lm_fit<span class="op">$</span>coef[<span class="dv">1</span>], <span class="dt">slope =</span> lm_fit<span class="op">$</span>coef[<span class="dv">2</span>])</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<p><img src="img/figures/unnamed-chunk-60-1.png" width="672" /></p>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb206-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb206-1" aria-hidden="true"></a><span class="kw">range</span>(p_hat)</span></code></pre></div>
<pre><code>## [1] -0.397868  1.123309</code></pre>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb208-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb208-1" aria-hidden="true"></a><span class="co"># fit logistic regression model</span></span>
<span id="cb208-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb208-2" aria-hidden="true"></a>glm_fit &lt;-<span class="st"> </span>train_set <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb208-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb208-3" aria-hidden="true"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">y =</span> <span class="kw">as.numeric</span>(sex <span class="op">==</span><span class="st"> &quot;Female&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb208-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb208-4" aria-hidden="true"></a><span class="st">  </span><span class="kw">glm</span>(y <span class="op">~</span><span class="st"> </span>height, <span class="dt">data=</span>., <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb208-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb208-5" aria-hidden="true"></a></span>
<span id="cb208-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb208-6" aria-hidden="true"></a>p_hat_logit &lt;-<span class="st"> </span><span class="kw">predict</span>(glm_fit, <span class="dt">newdata =</span> test_set, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb208-7"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb208-7" aria-hidden="true"></a></span>
<span id="cb208-8"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb208-8" aria-hidden="true"></a>tmp &lt;-<span class="st"> </span>heights <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb208-9"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb208-9" aria-hidden="true"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">x =</span> <span class="kw">round</span>(height)) <span class="op">%&gt;%</span></span>
<span id="cb208-10"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb208-10" aria-hidden="true"></a><span class="st">  </span><span class="kw">group_by</span>(x) <span class="op">%&gt;%</span></span>
<span id="cb208-11"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb208-11" aria-hidden="true"></a><span class="st">  </span><span class="kw">filter</span>(<span class="kw">n</span>() <span class="op">&gt;=</span><span class="st"> </span><span class="dv">10</span>) <span class="op">%&gt;%</span></span>
<span id="cb208-12"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb208-12" aria-hidden="true"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">prop =</span> <span class="kw">mean</span>(sex <span class="op">==</span><span class="st"> &quot;Female&quot;</span>)) </span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb210-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb210-1" aria-hidden="true"></a>logistic_curve &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="kw">min</span>(tmp<span class="op">$</span>x), <span class="kw">max</span>(tmp<span class="op">$</span>x))) <span class="op">%&gt;%</span></span>
<span id="cb210-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb210-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">p_hat =</span> <span class="kw">plogis</span>(glm_fit<span class="op">$</span>coef[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>glm_fit<span class="op">$</span>coef[<span class="dv">2</span>]<span class="op">*</span>x))</span>
<span id="cb210-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb210-3" aria-hidden="true"></a>tmp <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb210-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb210-4" aria-hidden="true"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(x, prop)) <span class="op">+</span></span>
<span id="cb210-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb210-5" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb210-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb210-6" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> logistic_curve, <span class="dt">mapping =</span> <span class="kw">aes</span>(x, p_hat), <span class="dt">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-60-2.png" width="672" /></p>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb211-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb211-1" aria-hidden="true"></a>y_hat_logit &lt;-<span class="st"> </span><span class="kw">ifelse</span>(p_hat_logit <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.5</span>, <span class="st">&quot;Female&quot;</span>, <span class="st">&quot;Male&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>factor</span>
<span id="cb211-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb211-2" aria-hidden="true"></a><span class="kw">confusionMatrix</span>(y_hat_logit, test_set<span class="op">$</span>sex)<span class="op">$</span>overall[[<span class="st">&quot;Accuracy&quot;</span>]]</span></code></pre></div>
<pre><code>## [1] 0.7984791</code></pre>
</div>
<div id="case-study-2-or-7" class="section level2" number="4.6">
<h2><span class="header-section-number">4.6</span> Case Study: 2 or 7</h2>
<p>There is a link to the relevant section of the textbook: <a href="https://rafalab.github.io/dsbook/examples-of-algorithms.html#logistic-regression-with-more-than-one-predictor" target="_blank">Case study: 2 or 7</a></p>
<p><strong>Key points</strong></p>
<ul>
<li>In this case study we apply logistic regression to classify whether a digit is two or seven. We are interested in estimating a conditional probability that depends on two variables:</li>
</ul>
<p><span class="math inline">\(g\{p(x_{1},x_{2}\}=g\{Pr(Y=1|X_{1}=x_{1}, X_{2}=x_{2})\} = \beta_{0}+\beta_{1}x_{1}+\beta_{2}x_{2}\)</span></p>
<ul>
<li>Through this case, we know that logistic regression forces our estimates to be a <strong>plane</strong> and our boundary to be a <strong>line</strong>. This implies that a logistic regression approach has no chance of capturing the <strong>non-linear</strong> nature of the true <span class="math inline">\(p(x_{1}, x_{2})\)</span>. Therefore, we need other more flexible methods that permit other shapes.</li>
</ul>
<p><em>Code</em></p>
<div class="sourceCode" id="cb213"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb213-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb213-1" aria-hidden="true"></a>mnist &lt;-<span class="st"> </span><span class="kw">read_mnist</span>()</span>
<span id="cb213-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb213-2" aria-hidden="true"></a>is &lt;-<span class="st"> </span>mnist_<span class="dv">27</span><span class="op">$</span>index_train[<span class="kw">c</span>(<span class="kw">which.min</span>(mnist_<span class="dv">27</span><span class="op">$</span>train<span class="op">$</span>x_<span class="dv">1</span>), <span class="kw">which.max</span>(mnist_<span class="dv">27</span><span class="op">$</span>train<span class="op">$</span>x_<span class="dv">1</span>))]</span>
<span id="cb213-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb213-3" aria-hidden="true"></a>titles &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;smallest&quot;</span>,<span class="st">&quot;largest&quot;</span>)</span>
<span id="cb213-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb213-4" aria-hidden="true"></a>tmp &lt;-<span class="st"> </span><span class="kw">lapply</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>, <span class="cf">function</span>(i){</span>
<span id="cb213-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb213-5" aria-hidden="true"></a>    <span class="kw">expand.grid</span>(<span class="dt">Row=</span><span class="dv">1</span><span class="op">:</span><span class="dv">28</span>, <span class="dt">Column=</span><span class="dv">1</span><span class="op">:</span><span class="dv">28</span>) <span class="op">%&gt;%</span></span>
<span id="cb213-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb213-6" aria-hidden="true"></a><span class="st">        </span><span class="kw">mutate</span>(<span class="dt">label=</span>titles[i],</span>
<span id="cb213-7"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb213-7" aria-hidden="true"></a>               <span class="dt">value =</span> mnist<span class="op">$</span>train<span class="op">$</span>images[is[i],])</span>
<span id="cb213-8"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb213-8" aria-hidden="true"></a>})</span>
<span id="cb213-9"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb213-9" aria-hidden="true"></a>tmp &lt;-<span class="st"> </span><span class="kw">Reduce</span>(rbind, tmp)</span>
<span id="cb213-10"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb213-10" aria-hidden="true"></a>tmp <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(Row, Column, <span class="dt">fill=</span>value)) <span class="op">+</span></span>
<span id="cb213-11"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb213-11" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_raster</span>() <span class="op">+</span></span>
<span id="cb213-12"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb213-12" aria-hidden="true"></a><span class="st">    </span><span class="kw">scale_y_reverse</span>() <span class="op">+</span></span>
<span id="cb213-13"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb213-13" aria-hidden="true"></a><span class="st">    </span><span class="kw">scale_fill_gradient</span>(<span class="dt">low=</span><span class="st">&quot;white&quot;</span>, <span class="dt">high=</span><span class="st">&quot;black&quot;</span>) <span class="op">+</span></span>
<span id="cb213-14"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb213-14" aria-hidden="true"></a><span class="st">    </span><span class="kw">facet_grid</span>(.<span class="op">~</span>label) <span class="op">+</span></span>
<span id="cb213-15"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb213-15" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="fl">14.5</span>) <span class="op">+</span></span>
<span id="cb213-16"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb213-16" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="fl">14.5</span>)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-61-1.png" width="672" /></p>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb214-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb214-1" aria-hidden="true"></a><span class="kw">data</span>(<span class="st">&quot;mnist_27&quot;</span>)</span>
<span id="cb214-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb214-2" aria-hidden="true"></a>mnist_<span class="dv">27</span><span class="op">$</span>train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(x_<span class="dv">1</span>, x_<span class="dv">2</span>, <span class="dt">color =</span> y)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>()</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-61-2.png" width="672" /></p>
<div class="sourceCode" id="cb215"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb215-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb215-1" aria-hidden="true"></a>is &lt;-<span class="st"> </span>mnist_<span class="dv">27</span><span class="op">$</span>index_train[<span class="kw">c</span>(<span class="kw">which.min</span>(mnist_<span class="dv">27</span><span class="op">$</span>train<span class="op">$</span>x_<span class="dv">2</span>), <span class="kw">which.max</span>(mnist_<span class="dv">27</span><span class="op">$</span>train<span class="op">$</span>x_<span class="dv">2</span>))]</span>
<span id="cb215-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb215-2" aria-hidden="true"></a>titles &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;smallest&quot;</span>,<span class="st">&quot;largest&quot;</span>)</span>
<span id="cb215-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb215-3" aria-hidden="true"></a>tmp &lt;-<span class="st"> </span><span class="kw">lapply</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>, <span class="cf">function</span>(i){</span>
<span id="cb215-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb215-4" aria-hidden="true"></a>    <span class="kw">expand.grid</span>(<span class="dt">Row=</span><span class="dv">1</span><span class="op">:</span><span class="dv">28</span>, <span class="dt">Column=</span><span class="dv">1</span><span class="op">:</span><span class="dv">28</span>) <span class="op">%&gt;%</span></span>
<span id="cb215-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb215-5" aria-hidden="true"></a><span class="st">        </span><span class="kw">mutate</span>(<span class="dt">label=</span>titles[i],</span>
<span id="cb215-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb215-6" aria-hidden="true"></a>               <span class="dt">value =</span> mnist<span class="op">$</span>train<span class="op">$</span>images[is[i],])</span>
<span id="cb215-7"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb215-7" aria-hidden="true"></a>})</span>
<span id="cb215-8"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb215-8" aria-hidden="true"></a>tmp &lt;-<span class="st"> </span><span class="kw">Reduce</span>(rbind, tmp)</span>
<span id="cb215-9"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb215-9" aria-hidden="true"></a>tmp <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(Row, Column, <span class="dt">fill=</span>value)) <span class="op">+</span></span>
<span id="cb215-10"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb215-10" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_raster</span>() <span class="op">+</span></span>
<span id="cb215-11"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb215-11" aria-hidden="true"></a><span class="st">    </span><span class="kw">scale_y_reverse</span>() <span class="op">+</span></span>
<span id="cb215-12"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb215-12" aria-hidden="true"></a><span class="st">    </span><span class="kw">scale_fill_gradient</span>(<span class="dt">low=</span><span class="st">&quot;white&quot;</span>, <span class="dt">high=</span><span class="st">&quot;black&quot;</span>) <span class="op">+</span></span>
<span id="cb215-13"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb215-13" aria-hidden="true"></a><span class="st">    </span><span class="kw">facet_grid</span>(.<span class="op">~</span>label) <span class="op">+</span></span>
<span id="cb215-14"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb215-14" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="fl">14.5</span>) <span class="op">+</span></span>
<span id="cb215-15"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb215-15" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="fl">14.5</span>)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-61-3.png" width="672" /></p>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb216-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb216-1" aria-hidden="true"></a>fit_glm &lt;-<span class="st"> </span><span class="kw">glm</span>(y <span class="op">~</span><span class="st"> </span>x_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>x_<span class="dv">2</span>, <span class="dt">data=</span>mnist_<span class="dv">27</span><span class="op">$</span>train, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb216-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb216-2" aria-hidden="true"></a>p_hat_glm &lt;-<span class="st"> </span><span class="kw">predict</span>(fit_glm, mnist_<span class="dv">27</span><span class="op">$</span>test)</span>
<span id="cb216-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb216-3" aria-hidden="true"></a>y_hat_glm &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">ifelse</span>(p_hat_glm <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.5</span>, <span class="dv">7</span>, <span class="dv">2</span>))</span>
<span id="cb216-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb216-4" aria-hidden="true"></a><span class="kw">confusionMatrix</span>(<span class="dt">data =</span> y_hat_glm, <span class="dt">reference =</span> mnist_<span class="dv">27</span><span class="op">$</span>test<span class="op">$</span>y)<span class="op">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span></code></pre></div>
<pre><code>## Accuracy 
##     0.76</code></pre>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb218-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb218-1" aria-hidden="true"></a>mnist_<span class="dv">27</span><span class="op">$</span>true_p <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(x_<span class="dv">1</span>, x_<span class="dv">2</span>, <span class="dt">fill=</span>p)) <span class="op">+</span></span>
<span id="cb218-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb218-2" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_raster</span>()</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-61-4.png" width="672" /></p>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb219-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb219-1" aria-hidden="true"></a>mnist_<span class="dv">27</span><span class="op">$</span>true_p <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(x_<span class="dv">1</span>, x_<span class="dv">2</span>, <span class="dt">z=</span>p, <span class="dt">fill=</span>p)) <span class="op">+</span></span>
<span id="cb219-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb219-2" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_raster</span>() <span class="op">+</span></span>
<span id="cb219-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb219-3" aria-hidden="true"></a><span class="st">    </span><span class="kw">scale_fill_gradientn</span>(<span class="dt">colors=</span><span class="kw">c</span>(<span class="st">&quot;#F8766D&quot;</span>,<span class="st">&quot;white&quot;</span>,<span class="st">&quot;#00BFC4&quot;</span>)) <span class="op">+</span></span>
<span id="cb219-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb219-4" aria-hidden="true"></a><span class="st">    </span><span class="kw">stat_contour</span>(<span class="dt">breaks=</span><span class="kw">c</span>(<span class="fl">0.5</span>), <span class="dt">color=</span><span class="st">&quot;black&quot;</span>) </span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-61-5.png" width="672" /></p>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb220-1" aria-hidden="true"></a>p_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(fit_glm, <span class="dt">newdata =</span> mnist_<span class="dv">27</span><span class="op">$</span>true_p)</span>
<span id="cb220-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb220-2" aria-hidden="true"></a>mnist_<span class="dv">27</span><span class="op">$</span>true_p <span class="op">%&gt;%</span></span>
<span id="cb220-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb220-3" aria-hidden="true"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">p_hat =</span> p_hat) <span class="op">%&gt;%</span></span>
<span id="cb220-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb220-4" aria-hidden="true"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(x_<span class="dv">1</span>, x_<span class="dv">2</span>,  <span class="dt">z=</span>p_hat, <span class="dt">fill=</span>p_hat)) <span class="op">+</span></span>
<span id="cb220-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb220-5" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_raster</span>() <span class="op">+</span></span>
<span id="cb220-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb220-6" aria-hidden="true"></a><span class="st">    </span><span class="kw">scale_fill_gradientn</span>(<span class="dt">colors=</span><span class="kw">c</span>(<span class="st">&quot;#F8766D&quot;</span>,<span class="st">&quot;white&quot;</span>,<span class="st">&quot;#00BFC4&quot;</span>)) <span class="op">+</span></span>
<span id="cb220-7"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb220-7" aria-hidden="true"></a><span class="st">    </span><span class="kw">stat_contour</span>(<span class="dt">breaks=</span><span class="kw">c</span>(<span class="fl">0.5</span>),<span class="dt">color=</span><span class="st">&quot;black&quot;</span>) </span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-61-6.png" width="672" /></p>
<div class="sourceCode" id="cb221"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb221-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb221-1" aria-hidden="true"></a>p_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(fit_glm, <span class="dt">newdata =</span> mnist_<span class="dv">27</span><span class="op">$</span>true_p)</span>
<span id="cb221-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb221-2" aria-hidden="true"></a>mnist_<span class="dv">27</span><span class="op">$</span>true_p <span class="op">%&gt;%</span></span>
<span id="cb221-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb221-3" aria-hidden="true"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">p_hat =</span> p_hat) <span class="op">%&gt;%</span></span>
<span id="cb221-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb221-4" aria-hidden="true"></a><span class="st">    </span><span class="kw">ggplot</span>() <span class="op">+</span></span>
<span id="cb221-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb221-5" aria-hidden="true"></a><span class="st">    </span><span class="kw">stat_contour</span>(<span class="kw">aes</span>(x_<span class="dv">1</span>, x_<span class="dv">2</span>, <span class="dt">z=</span>p_hat), <span class="dt">breaks=</span><span class="kw">c</span>(<span class="fl">0.5</span>), <span class="dt">color=</span><span class="st">&quot;black&quot;</span>) <span class="op">+</span></span>
<span id="cb221-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb221-6" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(x_<span class="dv">1</span>, x_<span class="dv">2</span>, <span class="dt">color=</span>y), <span class="dt">data =</span> mnist_<span class="dv">27</span><span class="op">$</span>test)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-61-7.png" width="672" /></p>
</div>
<div id="comprehension-check---logistic-regression" class="section level2" number="4.7">
<h2><span class="header-section-number">4.7</span> Comprehension Check - Logistic Regression</h2>
<ol style="list-style-type: decimal">
<li>Define a dataset using the following code:</li>
</ol>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb222-1" aria-hidden="true"></a><span class="co"># set.seed(2) #if you are using R 3.5 or earlier</span></span>
<span id="cb222-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb222-2" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">2</span>, <span class="dt">sample.kind=</span><span class="st">&quot;Rounding&quot;</span>) <span class="co">#if you are using R 3.6 or later</span></span></code></pre></div>
<pre><code>## Warning in set.seed(2, sample.kind = &quot;Rounding&quot;): non-uniform &#39;Rounding&#39; sampler used</code></pre>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb224-1" aria-hidden="true"></a>make_data &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">n =</span> <span class="dv">1000</span>, <span class="dt">p =</span> <span class="fl">0.5</span>, </span>
<span id="cb224-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb224-2" aria-hidden="true"></a>                <span class="dt">mu_0 =</span> <span class="dv">0</span>, <span class="dt">mu_1 =</span> <span class="dv">2</span>, </span>
<span id="cb224-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb224-3" aria-hidden="true"></a>                <span class="dt">sigma_0 =</span> <span class="dv">1</span>,  <span class="dt">sigma_1 =</span> <span class="dv">1</span>){</span>
<span id="cb224-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb224-4" aria-hidden="true"></a></span>
<span id="cb224-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb224-5" aria-hidden="true"></a>y &lt;-<span class="st"> </span><span class="kw">rbinom</span>(n, <span class="dv">1</span>, p)</span>
<span id="cb224-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb224-6" aria-hidden="true"></a>f_<span class="dv">0</span> &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, mu_<span class="dv">0</span>, sigma_<span class="dv">0</span>)</span>
<span id="cb224-7"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb224-7" aria-hidden="true"></a>f_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, mu_<span class="dv">1</span>, sigma_<span class="dv">1</span>)</span>
<span id="cb224-8"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb224-8" aria-hidden="true"></a>x &lt;-<span class="st"> </span><span class="kw">ifelse</span>(y <span class="op">==</span><span class="st"> </span><span class="dv">1</span>, f_<span class="dv">1</span>, f_<span class="dv">0</span>)</span>
<span id="cb224-9"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb224-9" aria-hidden="true"></a>  </span>
<span id="cb224-10"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb224-10" aria-hidden="true"></a>test_index &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(y, <span class="dt">times =</span> <span class="dv">1</span>, <span class="dt">p =</span> <span class="fl">0.5</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)</span>
<span id="cb224-11"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb224-11" aria-hidden="true"></a></span>
<span id="cb224-12"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb224-12" aria-hidden="true"></a><span class="kw">list</span>(<span class="dt">train =</span> <span class="kw">data.frame</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> <span class="kw">as.factor</span>(y)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="op">-</span>test_index),</span>
<span id="cb224-13"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb224-13" aria-hidden="true"></a>    <span class="dt">test =</span> <span class="kw">data.frame</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> <span class="kw">as.factor</span>(y)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(test_index))</span>
<span id="cb224-14"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb224-14" aria-hidden="true"></a>}</span>
<span id="cb224-15"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb224-15" aria-hidden="true"></a>dat &lt;-<span class="st"> </span><span class="kw">make_data</span>()</span></code></pre></div>
<p>Note that we have defined a variable <code>x</code> that is predictive of a binary outcome <code>y</code>:</p>
<p><code>dat$train %&gt;% ggplot(aes(x, color = y)) + geom_density()</code>.</p>
<p>Set the seed to 1, then use the <code>make_data()</code> function defined above to generate 25 different datasets with <code>mu_1 &lt;- seq(0, 3, len=25)</code>. Perform logistic regression on each of the 25 different datasets (predict 1 if p &gt; 0.5) and plot accuracy (<code>res</code> in the figures) vs mu_1 (<code>delta</code> in the figures).</p>
<p>Which is the correct plot?</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb225-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb225-1" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">1</span>) <span class="co">#if you are using R 3.5 or earlier</span></span>
<span id="cb225-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb225-2" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">1</span>, <span class="dt">sample.kind=</span><span class="st">&quot;Rounding&quot;</span>) <span class="co">#if you are using R 3.6 or later</span></span></code></pre></div>
<pre><code>## Warning in set.seed(1, sample.kind = &quot;Rounding&quot;): non-uniform &#39;Rounding&#39; sampler used</code></pre>
<div class="sourceCode" id="cb227"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb227-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb227-1" aria-hidden="true"></a>delta &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dt">len =</span> <span class="dv">25</span>)</span>
<span id="cb227-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb227-2" aria-hidden="true"></a>res &lt;-<span class="st"> </span><span class="kw">sapply</span>(delta, <span class="cf">function</span>(d){</span>
<span id="cb227-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb227-3" aria-hidden="true"></a>    dat &lt;-<span class="st"> </span><span class="kw">make_data</span>(<span class="dt">mu_1 =</span> d)</span>
<span id="cb227-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb227-4" aria-hidden="true"></a>    fit_glm &lt;-<span class="st"> </span>dat<span class="op">$</span>train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">glm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">data =</span> .)</span>
<span id="cb227-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb227-5" aria-hidden="true"></a>    y_hat_glm &lt;-<span class="st"> </span><span class="kw">ifelse</span>(<span class="kw">predict</span>(fit_glm, dat<span class="op">$</span>test) <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">factor</span>(<span class="dt">levels =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb227-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb227-6" aria-hidden="true"></a>    <span class="kw">mean</span>(y_hat_glm <span class="op">==</span><span class="st"> </span>dat<span class="op">$</span>test<span class="op">$</span>y)</span>
<span id="cb227-7"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb227-7" aria-hidden="true"></a>})</span>
<span id="cb227-8"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb227-8" aria-hidden="true"></a><span class="kw">qplot</span>(delta, res)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-63-1.png" width="672" /></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
A.</li>
</ul>
<p><img src="images/Plot1.png" /></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
B.</li>
</ul>
<p><img src="images/Plot2.png" /></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
C.</li>
</ul>
<p><img src="images/Plot3.png" /></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
D.</li>
</ul>
<p><img src="images/Plot4.png" /></p>
</div>
<div id="introduction-to-smoothing" class="section level2" number="4.8">
<h2><span class="header-section-number">4.8</span> Introduction to Smoothing</h2>
<p>There is a link to the relevant section of the textbook: <a href="https://rafalab.github.io/dsbook/smoothing.html" target="_blank">Smoothing</a></p>
<p><strong>Key points</strong></p>
<ul>
<li><strong>Smoothing</strong> is a very powerful technique used all across data analysis. It is designed to detect trends in the presence of noisy data in cases in which the shape of the trend is unknown.</li>
<li>The concepts behind smoothing techniques are extremely useful in machine learning because <strong>conditional expectations/probabilities</strong> can be thought of as <strong>trends</strong> of unknown shapes that we need to estimate in the presence of uncertainty.</li>
</ul>
<p><em>Code</em></p>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb228-1" aria-hidden="true"></a><span class="kw">data</span>(<span class="st">&quot;polls_2008&quot;</span>)</span>
<span id="cb228-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb228-2" aria-hidden="true"></a><span class="kw">qplot</span>(day, margin, <span class="dt">data =</span> polls_<span class="dv">2008</span>)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-64-1.png" width="672" /></p>
</div>
<div id="bin-smoothing-and-kernels" class="section level2" number="4.9">
<h2><span class="header-section-number">4.9</span> Bin Smoothing and Kernels</h2>
<p>There is a link to the relevant sections of the textbook: <a href="https://rafalab.github.io/dsbook/smoothing.html#bin-smoothing" target="_blank">Bin smoothing</a> and <a href="https://rafalab.github.io/dsbook/smoothing.html#kernels" target="_blank">Kernels</a></p>
<p><strong>Key points</strong></p>
<ul>
<li>The general idea of smoothing is to group data points into strata in which the value of <span class="math inline">\(f(x)\)</span> can be assumed to be constant. We can make this assumption because we think <span class="math inline">\(f(x)\)</span> changes slowly and, as a result, <span class="math inline">\(f(x)\)</span> is almost constant in small windows of time.</li>
<li>This assumption implies that a good estimate for <span class="math inline">\(f(x)\)</span> is the average of the <span class="math inline">\(Y_{i}\)</span> values in the window. The estimate is:</li>
</ul>
<p><span class="math inline">\(\hat{f}(x_{0})=\frac{1}{N_{0}}\sum_{i\in{A_{0}}}Y_{i}\)</span></p>
<ul>
<li>In smoothing, we call the size of the interval <span class="math inline">\(|x-x_{0}|\)</span> satisfying the particular condition the window size, bandwidth or span.</li>
</ul>
<p><em>Code</em></p>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb229-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb229-1" aria-hidden="true"></a><span class="co"># bin smoothers</span></span>
<span id="cb229-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb229-2" aria-hidden="true"></a>span &lt;-<span class="st"> </span><span class="dv">7</span> </span>
<span id="cb229-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb229-3" aria-hidden="true"></a>fit &lt;-<span class="st"> </span><span class="kw">with</span>(polls_<span class="dv">2008</span>,<span class="kw">ksmooth</span>(day, margin, <span class="dt">x.points =</span> day, <span class="dt">kernel=</span><span class="st">&quot;box&quot;</span>, <span class="dt">bandwidth =</span>span))</span>
<span id="cb229-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb229-4" aria-hidden="true"></a>polls_<span class="dv">2008</span> <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">smooth =</span> fit<span class="op">$</span>y) <span class="op">%&gt;%</span></span>
<span id="cb229-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb229-5" aria-hidden="true"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(day, margin)) <span class="op">+</span></span>
<span id="cb229-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb229-6" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">3</span>, <span class="dt">alpha =</span> <span class="fl">.5</span>, <span class="dt">color =</span> <span class="st">&quot;grey&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb229-7"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb229-7" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(day, smooth), <span class="dt">color=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-65-1.png" width="672" /></p>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb230-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb230-1" aria-hidden="true"></a><span class="co"># kernel</span></span>
<span id="cb230-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb230-2" aria-hidden="true"></a>span &lt;-<span class="st"> </span><span class="dv">7</span></span>
<span id="cb230-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb230-3" aria-hidden="true"></a>fit &lt;-<span class="st"> </span><span class="kw">with</span>(polls_<span class="dv">2008</span>, <span class="kw">ksmooth</span>(day, margin,  <span class="dt">x.points =</span> day, <span class="dt">kernel=</span><span class="st">&quot;normal&quot;</span>, <span class="dt">bandwidth =</span> span))</span>
<span id="cb230-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb230-4" aria-hidden="true"></a>polls_<span class="dv">2008</span> <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">smooth =</span> fit<span class="op">$</span>y) <span class="op">%&gt;%</span></span>
<span id="cb230-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb230-5" aria-hidden="true"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(day, margin)) <span class="op">+</span></span>
<span id="cb230-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb230-6" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">3</span>, <span class="dt">alpha =</span> <span class="fl">.5</span>, <span class="dt">color =</span> <span class="st">&quot;grey&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb230-7"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb230-7" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(day, smooth), <span class="dt">color=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-65-2.png" width="672" /></p>
</div>
<div id="local-weighted-regression-loess" class="section level2" number="4.10">
<h2><span class="header-section-number">4.10</span> Local Weighted Regression (loess)</h2>
<p>There is a link to the relevant section of the textbook: <a href="https://rafalab.github.io/dsbook/smoothing.html#local-weighted-regression-loess" target="_blank">Local weighted regression</a></p>
<p><strong>Key points</strong></p>
<ul>
<li>A limitation of the bin smoothing approach is that we need small windows for the approximately constant assumptions to hold which may lead to imprecise estimates of <span class="math inline">\(f(x)\)</span>. <strong>Local weighted regression (loess)</strong> permits us to consider larger window sizes.</li>
<li>One important difference between loess and bin smoother is that we assume the smooth function is locally <strong>linear</strong> in a window instead of constant.</li>
<li>The result of loess is a smoother fit than bin smoothing because we use larger sample sizes to estimate our local parameters.</li>
</ul>
<p><em>Code</em></p>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb231-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb231-1" aria-hidden="true"></a>polls_<span class="dv">2008</span> <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(day, margin)) <span class="op">+</span></span>
<span id="cb231-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb231-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb231-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb231-3" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">color=</span><span class="st">&quot;red&quot;</span>, <span class="dt">span =</span> <span class="fl">0.15</span>, <span class="dt">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="dt">method.args =</span> <span class="kw">list</span>(<span class="dt">degree=</span><span class="dv">1</span>))</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="img/figures/unnamed-chunk-66-1.png" width="672" /></p>
</div>
<div id="comprehension-check---smoothing" class="section level2" number="4.11">
<h2><span class="header-section-number">4.11</span> Comprehension Check - Smoothing</h2>
<ol style="list-style-type: decimal">
<li>In the Wrangling course of this series, PH125.6x, we used the following code to obtain mortality counts for Puerto Rico for 2015-2018:</li>
</ol>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb233-1" aria-hidden="true"></a><span class="cf">if</span>(<span class="op">!</span><span class="kw">require</span>(purrr)) <span class="kw">install.packages</span>(<span class="st">&quot;purrr&quot;</span>)</span>
<span id="cb233-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb233-2" aria-hidden="true"></a><span class="cf">if</span>(<span class="op">!</span><span class="kw">require</span>(pdftools)) <span class="kw">install.packages</span>(<span class="st">&quot;pdftools&quot;</span>)</span></code></pre></div>
<pre><code>## Loading required package: pdftools</code></pre>
<pre><code>## Using poppler version 0.73.0</code></pre>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb236-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-1" aria-hidden="true"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb236-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-2" aria-hidden="true"></a><span class="kw">library</span>(lubridate)</span>
<span id="cb236-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-3" aria-hidden="true"></a><span class="kw">library</span>(purrr)</span>
<span id="cb236-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-4" aria-hidden="true"></a><span class="kw">library</span>(pdftools)</span>
<span id="cb236-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-5" aria-hidden="true"></a>    </span>
<span id="cb236-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-6" aria-hidden="true"></a>fn &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;RD-Mortality-Report_2015-18-180531.pdf&quot;</span>, <span class="dt">package=</span><span class="st">&quot;dslabs&quot;</span>)</span>
<span id="cb236-7"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-7" aria-hidden="true"></a>dat &lt;-<span class="st"> </span><span class="kw">map_df</span>(<span class="kw">str_split</span>(<span class="kw">pdf_text</span>(fn), <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>), <span class="cf">function</span>(s){</span>
<span id="cb236-8"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-8" aria-hidden="true"></a>    s &lt;-<span class="st"> </span><span class="kw">str_trim</span>(s)</span>
<span id="cb236-9"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-9" aria-hidden="true"></a>    header_index &lt;-<span class="st"> </span><span class="kw">str_which</span>(s, <span class="st">&quot;2015&quot;</span>)[<span class="dv">1</span>]</span>
<span id="cb236-10"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-10" aria-hidden="true"></a>    tmp &lt;-<span class="st"> </span><span class="kw">str_split</span>(s[header_index], <span class="st">&quot;</span><span class="ch">\\</span><span class="st">s+&quot;</span>, <span class="dt">simplify =</span> <span class="ot">TRUE</span>)</span>
<span id="cb236-11"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-11" aria-hidden="true"></a>    month &lt;-<span class="st"> </span>tmp[<span class="dv">1</span>]</span>
<span id="cb236-12"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-12" aria-hidden="true"></a>    header &lt;-<span class="st"> </span>tmp[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb236-13"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-13" aria-hidden="true"></a>    tail_index  &lt;-<span class="st"> </span><span class="kw">str_which</span>(s, <span class="st">&quot;Total&quot;</span>)</span>
<span id="cb236-14"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-14" aria-hidden="true"></a>    n &lt;-<span class="st"> </span><span class="kw">str_count</span>(s, <span class="st">&quot;</span><span class="ch">\\</span><span class="st">d+&quot;</span>)</span>
<span id="cb236-15"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-15" aria-hidden="true"></a>    out &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span>header_index, <span class="kw">which</span>(n<span class="op">==</span><span class="dv">1</span>), <span class="kw">which</span>(n<span class="op">&gt;=</span><span class="dv">28</span>), tail_index<span class="op">:</span><span class="kw">length</span>(s))</span>
<span id="cb236-16"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-16" aria-hidden="true"></a>    s[<span class="op">-</span>out] <span class="op">%&gt;%</span></span>
<span id="cb236-17"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-17" aria-hidden="true"></a><span class="st">        </span><span class="kw">str_remove_all</span>(<span class="st">&quot;[^</span><span class="ch">\\</span><span class="st">d</span><span class="ch">\\</span><span class="st">s]&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb236-18"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-18" aria-hidden="true"></a><span class="st">        </span><span class="kw">str_trim</span>() <span class="op">%&gt;%</span></span>
<span id="cb236-19"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-19" aria-hidden="true"></a><span class="st">        </span><span class="kw">str_split_fixed</span>(<span class="st">&quot;</span><span class="ch">\\</span><span class="st">s+&quot;</span>, <span class="dt">n =</span> <span class="dv">6</span>) <span class="op">%&gt;%</span></span>
<span id="cb236-20"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-20" aria-hidden="true"></a><span class="st">        </span>.[,<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>] <span class="op">%&gt;%</span></span>
<span id="cb236-21"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-21" aria-hidden="true"></a><span class="st">        </span><span class="kw">as_data_frame</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb236-22"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-22" aria-hidden="true"></a><span class="st">        </span><span class="kw">setNames</span>(<span class="kw">c</span>(<span class="st">&quot;day&quot;</span>, header)) <span class="op">%&gt;%</span></span>
<span id="cb236-23"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-23" aria-hidden="true"></a><span class="st">        </span><span class="kw">mutate</span>(<span class="dt">month =</span> month,</span>
<span id="cb236-24"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-24" aria-hidden="true"></a>            <span class="dt">day =</span> <span class="kw">as.numeric</span>(day)) <span class="op">%&gt;%</span></span>
<span id="cb236-25"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-25" aria-hidden="true"></a><span class="st">        </span><span class="kw">gather</span>(year, deaths, <span class="op">-</span><span class="kw">c</span>(day, month)) <span class="op">%&gt;%</span></span>
<span id="cb236-26"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-26" aria-hidden="true"></a><span class="st">        </span><span class="kw">mutate</span>(<span class="dt">deaths =</span> <span class="kw">as.numeric</span>(deaths))</span>
<span id="cb236-27"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-27" aria-hidden="true"></a>}) <span class="op">%&gt;%</span></span>
<span id="cb236-28"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-28" aria-hidden="true"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">month =</span> <span class="kw">recode</span>(month, <span class="st">&quot;JAN&quot;</span> =<span class="st"> </span><span class="dv">1</span>, <span class="st">&quot;FEB&quot;</span> =<span class="st"> </span><span class="dv">2</span>, <span class="st">&quot;MAR&quot;</span> =<span class="st"> </span><span class="dv">3</span>, <span class="st">&quot;APR&quot;</span> =<span class="st"> </span><span class="dv">4</span>, <span class="st">&quot;MAY&quot;</span> =<span class="st"> </span><span class="dv">5</span>, <span class="st">&quot;JUN&quot;</span> =<span class="st"> </span><span class="dv">6</span>, </span>
<span id="cb236-29"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-29" aria-hidden="true"></a>                          <span class="st">&quot;JUL&quot;</span> =<span class="st"> </span><span class="dv">7</span>, <span class="st">&quot;AGO&quot;</span> =<span class="st"> </span><span class="dv">8</span>, <span class="st">&quot;SEP&quot;</span> =<span class="st"> </span><span class="dv">9</span>, <span class="st">&quot;OCT&quot;</span> =<span class="st"> </span><span class="dv">10</span>, <span class="st">&quot;NOV&quot;</span> =<span class="st"> </span><span class="dv">11</span>, <span class="st">&quot;DEC&quot;</span> =<span class="st"> </span><span class="dv">12</span>)) <span class="op">%&gt;%</span></span>
<span id="cb236-30"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-30" aria-hidden="true"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">date =</span> <span class="kw">make_date</span>(year, month, day)) <span class="op">%&gt;%</span></span>
<span id="cb236-31"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb236-31" aria-hidden="true"></a><span class="st">        </span>dplyr<span class="op">::</span><span class="kw">filter</span>(date <span class="op">&lt;=</span><span class="st"> &quot;2018-05-01&quot;</span>)</span></code></pre></div>
<pre><code>## Warning: `as_data_frame()` is deprecated as of tibble 2.0.0.
## Please use `as_tibble()` instead.
## The signature and semantics have changed, see `?as_tibble`.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.</code></pre>
<pre><code>## Warning: The `x` argument of `as_tibble.matrix()` must have unique column names if `.name_repair` is omitted as of tibble 2.0.0.
## Using compatibility `.name_repair`.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.</code></pre>
<p>Use the <code>loess()</code> function to obtain a smooth estimate of the expected number of deaths as a function of date. Plot this resulting smooth function. Make the span about two months long.</p>
<p>Which of the following plots is correct?</p>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb239-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb239-1" aria-hidden="true"></a>span &lt;-<span class="st"> </span><span class="dv">60</span> <span class="op">/</span><span class="st"> </span><span class="kw">as.numeric</span>(<span class="kw">diff</span>(<span class="kw">range</span>(dat<span class="op">$</span>date)))</span>
<span id="cb239-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb239-2" aria-hidden="true"></a>fit &lt;-<span class="st"> </span>dat <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">x =</span> <span class="kw">as.numeric</span>(date)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">loess</span>(deaths <span class="op">~</span><span class="st"> </span>x, <span class="dt">data =</span> ., <span class="dt">span =</span> span, <span class="dt">degree =</span> <span class="dv">1</span>)</span>
<span id="cb239-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb239-3" aria-hidden="true"></a>dat <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">smooth =</span> <span class="kw">predict</span>(fit, <span class="kw">as.numeric</span>(date))) <span class="op">%&gt;%</span></span>
<span id="cb239-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb239-4" aria-hidden="true"></a><span class="st">    </span><span class="kw">ggplot</span>() <span class="op">+</span></span>
<span id="cb239-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb239-5" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(date, deaths)) <span class="op">+</span></span>
<span id="cb239-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb239-6" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(date, smooth), <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<pre><code>## Warning: Removed 1 rows containing missing values (geom_point).</code></pre>
<p><img src="img/figures/unnamed-chunk-68-1.png" width="672" /></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
A.</li>
</ul>
<p><img src="images/Smoothplot1.png" /></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
B.</li>
</ul>
<p><img src="images/Smoothplot2.png" /></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
C.</li>
</ul>
<p><img src="images/Smoothplot3.png" /></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
D.</li>
</ul>
<p><img src="images/Smoothplot4.png" /></p>
<ol start="2" style="list-style-type: decimal">
<li>Work with the same data as in Q1 to plot smooth estimates against day of the year, all on the same plot, but with different colors for each year.</li>
</ol>
<p>Which code produces the desired plot?</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb241-1" aria-hidden="true"></a>dat <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb241-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb241-2" aria-hidden="true"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">smooth =</span> <span class="kw">predict</span>(fit, <span class="kw">as.numeric</span>(date)), <span class="dt">day =</span> <span class="kw">yday</span>(date), <span class="dt">year =</span> <span class="kw">as.character</span>(<span class="kw">year</span>(date))) <span class="op">%&gt;%</span></span>
<span id="cb241-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb241-3" aria-hidden="true"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(day, smooth, <span class="dt">col =</span> year)) <span class="op">+</span></span>
<span id="cb241-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb241-4" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_line</span>(<span class="dt">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-69-1.png" width="672" /></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
A.</li>
</ul>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb242-1" aria-hidden="true"></a>dat <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb242-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb242-2" aria-hidden="true"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">smooth =</span> <span class="kw">predict</span>(fit), <span class="dt">day =</span> <span class="kw">yday</span>(date), <span class="dt">year =</span> <span class="kw">as.character</span>(<span class="kw">year</span>(date))) <span class="op">%&gt;%</span></span>
<span id="cb242-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb242-3" aria-hidden="true"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(day, smooth, <span class="dt">col =</span> year)) <span class="op">+</span></span>
<span id="cb242-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb242-4" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_line</span>(<span class="dt">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
B.</li>
</ul>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb243-1" aria-hidden="true"></a>dat <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb243-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb243-2" aria-hidden="true"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">smooth =</span> <span class="kw">predict</span>(fit, <span class="kw">as.numeric</span>(date)), <span class="dt">day =</span> <span class="kw">mday</span>(date), <span class="dt">year =</span> <span class="kw">as.character</span>(<span class="kw">year</span>(date))) <span class="op">%&gt;%</span></span>
<span id="cb243-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb243-3" aria-hidden="true"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(day, smooth, <span class="dt">col =</span> year)) <span class="op">+</span></span>
<span id="cb243-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb243-4" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_line</span>(<span class="dt">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
C.</li>
</ul>
<div class="sourceCode" id="cb244"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb244-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb244-1" aria-hidden="true"></a> dat <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb244-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb244-2" aria-hidden="true"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">smooth =</span> <span class="kw">predict</span>(fit, <span class="kw">as.numeric</span>(date)), <span class="dt">day =</span> <span class="kw">yday</span>(date), <span class="dt">year =</span> <span class="kw">as.character</span>(<span class="kw">year</span>(date))) <span class="op">%&gt;%</span></span>
<span id="cb244-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb244-3" aria-hidden="true"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(day, smooth)) <span class="op">+</span></span>
<span id="cb244-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb244-4" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_line</span>(<span class="dt">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
D.</li>
</ul>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb245-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb245-1" aria-hidden="true"></a>dat <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb245-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb245-2" aria-hidden="true"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">smooth =</span> <span class="kw">predict</span>(fit, <span class="kw">as.numeric</span>(date)), <span class="dt">day =</span> <span class="kw">yday</span>(date), <span class="dt">year =</span> <span class="kw">as.character</span>(<span class="kw">year</span>(date))) <span class="op">%&gt;%</span></span>
<span id="cb245-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb245-3" aria-hidden="true"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(day, smooth, <span class="dt">col =</span> year)) <span class="op">+</span></span>
<span id="cb245-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb245-4" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_line</span>(<span class="dt">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li>Suppose we want to predict 2s and 7s in the <code>mnist_27</code> dataset with just the second covariate. Can we do this? On first inspection it appears the data does not have much predictive power.</li>
</ol>
<p>In fact, if we fit a regular logistic regression the coefficient for <code>x_2</code> is not significant!</p>
<p>This can be seen using this code:</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb246-1" aria-hidden="true"></a><span class="cf">if</span>(<span class="op">!</span><span class="kw">require</span>(broom)) <span class="kw">install.packages</span>(<span class="st">&quot;broom&quot;</span>)</span></code></pre></div>
<pre><code>## Loading required package: broom</code></pre>
<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb248-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb248-1" aria-hidden="true"></a><span class="kw">library</span>(broom)</span>
<span id="cb248-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb248-2" aria-hidden="true"></a>mnist_<span class="dv">27</span><span class="op">$</span>train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">glm</span>(y <span class="op">~</span><span class="st"> </span>x_<span class="dv">2</span>, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">data =</span> .) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">tidy</span>()</span></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   term        estimate std.error statistic p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 (Intercept)  -0.0907     0.247    -0.368   0.713
## 2 x_2           0.685      0.827     0.829   0.407</code></pre>
<p>Plotting a scatterplot here is not useful since <code>y</code> is binary:</p>
<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb250-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb250-1" aria-hidden="true"></a><span class="kw">qplot</span>(x_<span class="dv">2</span>, y, <span class="dt">data =</span> mnist_<span class="dv">27</span><span class="op">$</span>train)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-75-1.png" width="672" /></p>
<p>Fit a loess line to the data above and plot the results. What do you observe?</p>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb251-1" aria-hidden="true"></a>mnist_<span class="dv">27</span><span class="op">$</span>train <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb251-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb251-2" aria-hidden="true"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">y =</span> <span class="kw">ifelse</span>(y<span class="op">==</span><span class="st">&quot;7&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)) <span class="op">%&gt;%</span></span>
<span id="cb251-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb251-3" aria-hidden="true"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(x_<span class="dv">2</span>, y)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb251-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb251-4" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;loess&quot;</span>)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="img/figures/unnamed-chunk-76-1.png" width="672" /></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
A. There is no predictive power and the conditional probability is linear.</li>
<li><input type="checkbox" disabled="" />
B. There is no predictive power and the conditional probability is non-linear.</li>
<li><input type="checkbox" disabled="" />
C. There is predictive power and the conditional probability is linear.</li>
<li><input type="checkbox" disabled="" checked="" />
D. There is predictive power and the conditional probability is non-linear.</li>
</ul>
</div>
<div id="matrices" class="section level2" number="4.12">
<h2><span class="header-section-number">4.12</span> Matrices</h2>
<p>There is a link to the relevant section of the textbook: <a href="https://rafalab.github.io/dsbook/large-datasets.html#matrix-algebra" target="_blank">Matrices</a></p>
<p><strong>Key points</strong></p>
<ul>
<li>The main reason for using matrices is that certain mathematical operations needed to develop efficient code can be performed using techniques from a branch of mathematics called <strong>linear algebra</strong>.</li>
<li><strong>Linear algebra</strong> and <strong>matrix notation</strong> are key elements of the language used in academic papers describing machine learning techniques.</li>
</ul>
<p><em>Code</em></p>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb253-1" aria-hidden="true"></a><span class="cf">if</span>(<span class="op">!</span><span class="kw">exists</span>(<span class="st">&quot;mnist&quot;</span>)) mnist &lt;-<span class="st"> </span><span class="kw">read_mnist</span>()</span>
<span id="cb253-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb253-2" aria-hidden="true"></a></span>
<span id="cb253-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb253-3" aria-hidden="true"></a><span class="kw">class</span>(mnist<span class="op">$</span>train<span class="op">$</span>images)</span></code></pre></div>
<pre><code>## [1] &quot;matrix&quot; &quot;array&quot;</code></pre>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb255-1" aria-hidden="true"></a>x &lt;-<span class="st"> </span>mnist<span class="op">$</span>train<span class="op">$</span>images[<span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>,] </span>
<span id="cb255-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb255-2" aria-hidden="true"></a>y &lt;-<span class="st"> </span>mnist<span class="op">$</span>train<span class="op">$</span>labels[<span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>]</span></code></pre></div>
</div>
<div id="matrix-notation" class="section level2" number="4.13">
<h2><span class="header-section-number">4.13</span> Matrix Notation</h2>
<p>There is a link to the relevant section of the textbook: <a href="https://rafalab.github.io/dsbook/large-datasets.html#notation-2" target="_blank">Matrix notation</a></p>
<p><strong>Key points</strong></p>
<ul>
<li>In matrix algebra, we have three main types of objects: <strong>scalars</strong>, <strong>vectors</strong>, and <strong>matrices</strong>.
<ul>
<li><strong>Scalar:</strong> <span class="math inline">\(\alpha=1\)</span></li>
<li><strong>Vector:</strong> <span class="math inline">\(X_{1} = \left(\begin{matrix} x_{1,1} \\ \vdots \\ x_{N,1} \\ \end{matrix}\right)\)</span></li>
<li><strong>Matrix:</strong> <span class="math inline">\(X = [X_{1}X_{2}] = \left(\begin{matrix} x_{1,1} &amp; x_{1,2} \\ \vdots &amp; \vdots \\ x_{N,1} &amp; x_{N,2} \\ \end{matrix}\right)\)</span></li>
</ul></li>
<li>In R, we can extract the dimension of a matrix with the function <code>dim()</code>. We can convert a vector into a matrix using the function <code>as.matrix()</code>.</li>
</ul>
<p><em>Code</em></p>
<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb256-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb256-1" aria-hidden="true"></a><span class="kw">length</span>(x[,<span class="dv">1</span>])</span></code></pre></div>
<pre><code>## [1] 1000</code></pre>
<div class="sourceCode" id="cb258"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb258-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb258-1" aria-hidden="true"></a>x_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">5</span></span>
<span id="cb258-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb258-2" aria-hidden="true"></a>x_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="dv">6</span><span class="op">:</span><span class="dv">10</span></span>
<span id="cb258-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb258-3" aria-hidden="true"></a><span class="kw">cbind</span>(x_<span class="dv">1</span>, x_<span class="dv">2</span>)</span></code></pre></div>
<pre><code>##      x_1 x_2
## [1,]   1   6
## [2,]   2   7
## [3,]   3   8
## [4,]   4   9
## [5,]   5  10</code></pre>
<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb260-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb260-1" aria-hidden="true"></a><span class="kw">dim</span>(x)</span></code></pre></div>
<pre><code>## [1] 1000  784</code></pre>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb262-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb262-1" aria-hidden="true"></a><span class="kw">dim</span>(x_<span class="dv">1</span>)</span></code></pre></div>
<pre><code>## NULL</code></pre>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb264-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb264-1" aria-hidden="true"></a><span class="kw">dim</span>(<span class="kw">as.matrix</span>(x_<span class="dv">1</span>))</span></code></pre></div>
<pre><code>## [1] 5 1</code></pre>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb266-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb266-1" aria-hidden="true"></a><span class="kw">dim</span>(x)</span></code></pre></div>
<pre><code>## [1] 1000  784</code></pre>
</div>
<div id="converting-a-vector-to-a-matrix" class="section level2" number="4.14">
<h2><span class="header-section-number">4.14</span> Converting a Vector to a Matrix</h2>
<p>There is a link to the relevant section of the textbook: <a href="https://rafalab.github.io/dsbook/large-datasets.html#converting-a-vector-to-a-matrix" target="_blank">Converting a vector to a matrix</a></p>
<p><strong>Key points</strong></p>
<ul>
<li>In R, we can <strong>convert a vector into a matrix</strong> with the <code>matrix()</code> function. The matrix is filled in by column, but we can fill by row by using the <code>byrow</code> argument. The function <code>t()</code> can be used to directly transpose a matrix.</li>
<li>Note that the matrix function <strong>recycles values in the vector</strong> without warning if the product of columns and rows does not match the length of the vector.</li>
</ul>
<p><em>Code</em></p>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb268-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb268-1" aria-hidden="true"></a>my_vector &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">15</span></span>
<span id="cb268-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb268-2" aria-hidden="true"></a></span>
<span id="cb268-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb268-3" aria-hidden="true"></a><span class="co"># fill the matrix by column</span></span>
<span id="cb268-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb268-4" aria-hidden="true"></a>mat &lt;-<span class="st"> </span><span class="kw">matrix</span>(my_vector, <span class="dv">5</span>, <span class="dv">3</span>)</span>
<span id="cb268-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb268-5" aria-hidden="true"></a>mat</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,]    1    6   11
## [2,]    2    7   12
## [3,]    3    8   13
## [4,]    4    9   14
## [5,]    5   10   15</code></pre>
<div class="sourceCode" id="cb270"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb270-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb270-1" aria-hidden="true"></a><span class="co"># fill by row</span></span>
<span id="cb270-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb270-2" aria-hidden="true"></a>mat_t &lt;-<span class="st"> </span><span class="kw">matrix</span>(my_vector, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)</span>
<span id="cb270-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb270-3" aria-hidden="true"></a>mat_t</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3] [,4] [,5]
## [1,]    1    2    3    4    5
## [2,]    6    7    8    9   10
## [3,]   11   12   13   14   15</code></pre>
<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb272-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb272-1" aria-hidden="true"></a><span class="kw">identical</span>(<span class="kw">t</span>(mat), mat_t)</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb274-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb274-1" aria-hidden="true"></a><span class="kw">matrix</span>(my_vector, <span class="dv">5</span>, <span class="dv">5</span>)</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3] [,4] [,5]
## [1,]    1    6   11    1    6
## [2,]    2    7   12    2    7
## [3,]    3    8   13    3    8
## [4,]    4    9   14    4    9
## [5,]    5   10   15    5   10</code></pre>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb276-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb276-1" aria-hidden="true"></a>grid &lt;-<span class="st"> </span><span class="kw">matrix</span>(x[<span class="dv">3</span>,], <span class="dv">28</span>, <span class="dv">28</span>)</span>
<span id="cb276-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb276-2" aria-hidden="true"></a><span class="kw">image</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">28</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">28</span>, grid)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-79-1.png" width="672" /></p>
<div class="sourceCode" id="cb277"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb277-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb277-1" aria-hidden="true"></a><span class="co"># flip the image back</span></span>
<span id="cb277-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb277-2" aria-hidden="true"></a><span class="kw">image</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">28</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">28</span>, grid[, <span class="dv">28</span><span class="op">:</span><span class="dv">1</span>])</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-79-2.png" width="672" /></p>
</div>
<div id="row-and-column-summaries-and-apply" class="section level2" number="4.15">
<h2><span class="header-section-number">4.15</span> Row and Column Summaries and Apply</h2>
<p>There is a link to the relevant section of the textbook: <a href="https://rafalab.github.io/dsbook/large-datasets.html#row-and-column-summaries" target="_blank">Row and column summaries</a></p>
<p><strong>Key points</strong></p>
<ul>
<li>The function <code>rowSums()</code> computes the sum of each row.</li>
<li>The function <code>rowMeans()</code> computes the average of each row.</li>
<li>We can compute the column sums and averages using the functions <code>colSums()</code> and <code>colMeans()</code>.</li>
<li>The <strong>matrixStats</strong> package adds functions that performs operations on each row or column very efficiently, including the functions <code>rowSds()</code> and <code>colSds()</code>.</li>
<li>The <code>apply()</code> function lets you apply any function to a matrix. The first argument is the <strong>matrix</strong>, the second is the <strong>dimension</strong> (1 for rows, 2 for columns), and the third is the <strong>function</strong>.</li>
</ul>
<p><em>Code</em></p>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb278-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb278-1" aria-hidden="true"></a>sums &lt;-<span class="st"> </span><span class="kw">rowSums</span>(x)</span>
<span id="cb278-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb278-2" aria-hidden="true"></a>avg &lt;-<span class="st"> </span><span class="kw">rowMeans</span>(x)</span>
<span id="cb278-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb278-3" aria-hidden="true"></a></span>
<span id="cb278-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb278-4" aria-hidden="true"></a><span class="kw">data_frame</span>(<span class="dt">labels =</span> <span class="kw">as.factor</span>(y), <span class="dt">row_averages =</span> avg) <span class="op">%&gt;%</span></span>
<span id="cb278-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb278-5" aria-hidden="true"></a><span class="st">    </span><span class="kw">qplot</span>(labels, row_averages, <span class="dt">data =</span> ., <span class="dt">geom =</span> <span class="st">&quot;boxplot&quot;</span>)</span></code></pre></div>
<pre><code>## Warning: `data_frame()` is deprecated as of tibble 1.1.0.
## Please use `tibble()` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.</code></pre>
<p><img src="img/figures/unnamed-chunk-80-1.png" width="672" /></p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb280-1" aria-hidden="true"></a>avgs &lt;-<span class="st"> </span><span class="kw">apply</span>(x, <span class="dv">1</span>, mean)</span>
<span id="cb280-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb280-2" aria-hidden="true"></a>sds &lt;-<span class="st"> </span><span class="kw">apply</span>(x, <span class="dv">2</span>, sd)</span></code></pre></div>
</div>
<div id="filtering-columns-based-on-summaries" class="section level2" number="4.16">
<h2><span class="header-section-number">4.16</span> Filtering Columns Based on Summaries</h2>
<p>There is a link to the relevant section of the textbook: <a href="https://rafalab.github.io/dsbook/large-datasets.html#filtering-columns-based-on-summaries" target="_blank">Filtering columns based on summaries</a></p>
<p><strong>Key points</strong></p>
<ul>
<li>The operations used to extract columns: <code>x[,c(351,352)]</code>.</li>
<li>The operations used to extract rows: <code>x[c(2,3),]</code>.</li>
<li>We can also use logical indexes to determine which columns or rows to keep: <code>new_x &lt;- x[ ,colSds(x) &gt; 60]</code>.</li>
<li><strong>Important note:</strong> if you select only one column or only one row, the result is no longer a matrix but a <strong>vector</strong>. We can <strong>preserve the matrix class</strong> by using the argument <code>drop=FALSE</code>.</li>
</ul>
<p><em>Code</em></p>
<div class="sourceCode" id="cb281"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb281-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb281-1" aria-hidden="true"></a><span class="cf">if</span>(<span class="op">!</span><span class="kw">require</span>(matrixStats)) <span class="kw">install.packages</span>(<span class="st">&quot;matrixStats&quot;</span>)</span></code></pre></div>
<pre><code>## Loading required package: matrixStats</code></pre>
<pre><code>## 
## Attaching package: &#39;matrixStats&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     count</code></pre>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb285-1" aria-hidden="true"></a><span class="kw">library</span>(matrixStats)</span>
<span id="cb285-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb285-2" aria-hidden="true"></a></span>
<span id="cb285-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb285-3" aria-hidden="true"></a>sds &lt;-<span class="st"> </span><span class="kw">colSds</span>(x)</span>
<span id="cb285-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb285-4" aria-hidden="true"></a><span class="kw">qplot</span>(sds, <span class="dt">bins =</span> <span class="st">&quot;30&quot;</span>, <span class="dt">color =</span> <span class="kw">I</span>(<span class="st">&quot;black&quot;</span>))</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-81-1.png" width="672" /></p>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb286-1" aria-hidden="true"></a><span class="kw">image</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">28</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">28</span>, <span class="kw">matrix</span>(sds, <span class="dv">28</span>, <span class="dv">28</span>)[, <span class="dv">28</span><span class="op">:</span><span class="dv">1</span>])</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-81-2.png" width="672" /></p>
<div class="sourceCode" id="cb287"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb287-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb287-1" aria-hidden="true"></a><span class="co">#extract columns and rows</span></span>
<span id="cb287-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb287-2" aria-hidden="true"></a>x[ ,<span class="kw">c</span>(<span class="dv">351</span>,<span class="dv">352</span>)]</span></code></pre></div>
<pre><code>##         [,1] [,2]
##    [1,]   70    0
##    [2,]    0    0
##    [3,]    0    0
##    [4,]  205  253
##    [5,]    8   78
##    [6,]    0    0
##    [7,]  253  253
##    [8,]   91  212
##    [9,]  254  143
##   [10,]    0    0
##   [11,]  254  254
##   [12,]   78   79
##   [13,]  254  248
##   [14,]    0  114
##   [15,]  254  109
##   [16,]    0    0
##   [17,]    0    0
##   [18,]   80  223
##   [19,]    0    0
##   [20,]    8   43
##   [21,]  109  109
##   [22,]   96  204
##   [23,]    0    0
##   [24,]  142  255
##   [25,]   32  254
##   [26,]  250  253
##   [27,]    0    0
##   [28,]  253  253
##   [29,]    0    0
##   [30,]    2    0
##   [31,]  253  253
##   [32,]  253  253
##   [33,]    0    0
##   [34,]  228  216
##   [35,]  225    0
##   [36,]  141   86
##   [37,]  107    0
##   [38,]    0    0
##   [39,]    0   15
##   [40,]    0    0
##   [41,]  253  253
##   [42,]  232  233
##   [43,]    0  182
##   [44,]   71  173
##   [45,]  253  203
##   [46,]   44  199
##   [47,]    0  154
##   [48,]    0    0
##   [49,]  169  254
##   [50,]  252  176
##   [51,]  254  254
##   [52,]    0    0
##   [53,]    0    0
##   [54,]   24  242
##   [55,]   71  122
##   [56,]    0  186
##   [57,]    0    0
##   [58,]    0    0
##   [59,]  111  189
##   [60,]  229  254
##   [61,]    0    0
##   [62,]    0  227
##   [63,]    0    0
##   [64,]  253  251
##   [65,]    0    0
##   [66,]  216  151
##   [67,]  128  128
##   [68,]  254  254
##   [69,]    0    0
##   [70,]   29    0
##   [71,]  253  122
##   [72,]   69    0
##   [73,]  254  204
##   [74,]   17  179
##   [75,]  253  252
##   [76,]  182   15
##   [77,]  254  254
##   [78,]  251  253
##   [79,]  173  253
##   [80,]   10    0
##   [81,]  252  253
##   [82,]    0    0
##   [83,]    0    0
##   [84,]    0  128
##   [85,]    0    0
##   [86,]  253  253
##   [87,]  253  253
##   [88,]   21   52
##   [89,]    0    0
##   [90,]    0    0
##   [91,]    0    0
##   [92,]   53   53
##   [93,]    0    0
##   [94,]   70  236
##   [95,]   38    0
##   [96,]    0    0
##   [97,]    0   26
##   [98,]   38   38
##   [99,]  253  240
##  [100,]   69  253
##  [101,]    0    0
##  [102,]   66    0
##  [103,]  254   95
##  [104,]    0    0
##  [105,]  251    0
##  [106,]  253  253
##  [107,]    0    0
##  [108,]  191  255
##  [109,]    0    0
##  [110,]  163    8
##  [111,]   78  253
##  [112,]   55  139
##  [113,]  252  253
##  [114,]  252  252
##  [115,]    0    0
##  [116,]    0    0
##  [117,]    0   15
##  [118,]  253  253
##  [119,]    0    0
##  [120,]   14    0
##  [121,]    0    0
##  [122,]    0    0
##  [123,]    0  150
##  [124,]    0    0
##  [125,]  253  233
##  [126,]  254  178
##  [127,]    0    0
##  [128,]   61    1
##  [129,]  253  253
##  [130,]  192  252
##  [131,]  254  247
##  [132,]    0    5
##  [133,]  253  253
##  [134,]  141  240
##  [135,]  253  251
##  [136,]  252  252
##  [137,]  254  179
##  [138,]  255  255
##  [139,]  244  253
##  [140,]    0    0
##  [141,]    0    0
##  [142,]  131   44
##  [143,]    0    0
##  [144,]  162  255
##  [145,]   72  142
##  [146,]    0    0
##  [147,]    0   34
##  [148,]    0    0
##  [149,]    0    0
##  [150,]  252  252
##  [151,]  221  254
##  [152,]    0    0
##  [153,]  232  254
##  [154,]    5   89
##  [155,]  253  213
##  [156,]    0   36
##  [157,]    0    0
##  [158,]  179  242
##  [159,]   50   50
##  [160,]    0   90
##  [161,]  254  254
##  [162,]  229  254
##  [163,]    0    0
##  [164,]   76  243
##  [165,]    0    0
##  [166,]   63  167
##  [167,]    0    0
##  [168,]    0    0
##  [169,]  253  252
##  [170,]  105    4
##  [171,]   37  168
##  [172,]   69  168
##  [173,]  255  152
##  [174,]  170    0
##  [175,]  252  253
##  [176,]  185    8
##  [177,]  254  253
##  [178,]  251  253
##  [179,]    0    0
##  [180,]   59  106
##  [181,]    0  178
##  [182,]    0    0
##  [183,]  176  253
##  [184,]    0   64
##  [185,]  253  226
##  [186,]    0    0
##  [187,]    0    0
##  [188,]  254  254
##  [189,]    0    0
##  [190,]  252  252
##  [191,]  167  254
##  [192,]    0    0
##  [193,]    0    0
##  [194,]   32   32
##  [195,]    0    0
##  [196,]  148  149
##  [197,]    0    0
##  [198,]  250  225
##  [199,]  104  252
##  [200,]    0   11
##  [201,]  253  169
##  [202,]  157  252
##  [203,]  100  247
##  [204,]  162  216
##  [205,]    0    0
##  [206,]  253  251
##  [207,]    0    0
##  [208,]    0    0
##  [209,]  253  253
##  [210,]    0    0
##  [211,]    0    0
##  [212,]  253  254
##  [213,]  199  253
##  [214,]    0   20
##  [215,]    0    0
##  [216,]  253  253
##  [217,]    0    0
##  [218,]    0    0
##  [219,]  106  239
##  [220,]  181   84
##  [221,]    0    0
##  [222,]    0   31
##  [223,]  152  244
##  [224,]    0    0
##  [225,]    0   61
##  [226,]  253  227
##  [227,]    0  136
##  [228,]    0    0
##  [229,]    0    0
##  [230,]    0    0
##  [231,]    0    0
##  [232,]  253  251
##  [233,]    0    0
##  [234,]    0    0
##  [235,]    0    2
##  [236,]  253  253
##  [237,]    0    0
##  [238,]    0    0
##  [239,]    0    0
##  [240,]   98   88
##  [241,]  253  252
##  [242,]    0    0
##  [243,]  254  254
##  [244,]    0    0
##  [245,]    0  169
##  [246,]  255  255
##  [247,]    0    0
##  [248,]    0    2
##  [249,]  254  252
##  [250,]    0    0
##  [251,]    0    1
##  [252,]  253  253
##  [253,]  253  252
##  [254,]    0    0
##  [255,]  254  254
##  [256,]  253  253
##  [257,]  253  171
##  [258,]    0    0
##  [259,]    0    0
##  [260,]  254  231
##  [261,]    0    0
##  [262,]    0    0
##  [263,]    0    0
##  [264,]    0    0
##  [265,]    0    0
##  [266,]  236   62
##  [267,]   77    0
##  [268,]    0   90
##  [269,]    0   93
##  [270,]  253  253
##  [271,]  251   57
##  [272,]    0    0
##  [273,]  125  168
##  [274,]  127  127
##  [275,]  232    8
##  [276,]    0    0
##  [277,]  191  254
##  [278,]    0    0
##  [279,]  245  254
##  [280,]    0  128
##  [281,]    0   51
##  [282,]  253  255
##  [283,]    0    0
##  [284,]    0    0
##  [285,]  253  253
##  [286,]    0    0
##  [287,]  253  253
##  [288,]  254  251
##  [289,]    0    0
##  [290,]    0    0
##  [291,]  252  253
##  [292,]  253  253
##  [293,]    2   45
##  [294,]    0    0
##  [295,]    0    0
##  [296,]  133  160
##  [297,]    0    0
##  [298,]    0    0
##  [299,]  253  253
##  [300,]    0  155
##  [301,]   42  235
##  [302,]    0    0
##  [303,]    0    0
##  [304,]    0    0
##  [305,]   29   29
##  [306,]    0    0
##  [307,]  100  176
##  [308,]    0    0
##  [309,]    0    0
##  [310,]  232  253
##  [311,]  235  254
##  [312,]    0    0
##  [313,]  183  102
##  [314,]    0   35
##  [315,]    0    0
##  [316,]  243  253
##  [317,]  255  255
##  [318,]    0    0
##  [319,]  241  224
##  [320,]    0    5
##  [321,]    0    0
##  [322,]  230  253
##  [323,]    0    0
##  [324,]    0    0
##  [325,]    0    0
##  [326,]    0    0
##  [327,]    0    0
##  [328,]  253  253
##  [329,]   45    0
##  [330,]    0    0
##  [331,]   70   70
##  [332,]    0    0
##  [333,]    0    0
##  [334,]  184  184
##  [335,]    0  183
##  [336,]  211   86
##  [337,]    0    0
##  [338,]    0    0
##  [339,]    0    0
##  [340,]    0    0
##  [341,]    0   64
##  [342,]  253  255
##  [343,]  132  152
##  [344,]  252  241
##  [345,]    0    0
##  [346,]  158  254
##  [347,]    8  134
##  [348,]    0    0
##  [349,]  205  254
##  [350,]    0    0
##  [351,]    0    3
##  [352,]  180  253
##  [353,]  253  207
##  [354,]    0    0
##  [355,]    0  102
##  [356,]  254  254
##  [357,]  253  253
##  [358,]  211  253
##  [359,]  254   95
##  [360,]    0    0
##  [361,]  253  253
##  [362,]  160  252
##  [363,]    0    0
##  [364,]    0   96
##  [365,]    0    0
##  [366,]    0    0
##  [367,]  253  217
##  [368,]    0    0
##  [369,]  254  254
##  [370,]    0    0
##  [371,]  253  253
##  [372,]    0    0
##  [373,]    0   43
##  [374,]    0    0
##  [375,]  121  252
##  [376,]    0    0
##  [377,]    0    0
##  [378,]    0    0
##  [379,]    0    0
##  [380,]    0    3
##  [381,]    0    0
##  [382,]    0    0
##  [383,]  254   84
##  [384,]    0    0
##  [385,]    0   56
##  [386,]    0   52
##  [387,]  252  240
##  [388,]    0    0
##  [389,]    0    0
##  [390,]    0    0
##  [391,]   38  233
##  [392,]  197  173
##  [393,]   53  232
##  [394,]   64   64
##  [395,]  181    0
##  [396,]    0    0
##  [397,]    0    0
##  [398,]  207  252
##  [399,]  253  158
##  [400,]   27    0
##  [401,]    0    0
##  [402,]    0    0
##  [403,]    0    0
##  [404,]  105    0
##  [405,]  253  253
##  [406,]   93  239
##  [407,]  253   58
##  [408,]   42   27
##  [409,]  254  195
##  [410,]    0    0
##  [411,]  229  253
##  [412,]    0    0
##  [413,]    0  100
##  [414,]    0    0
##  [415,]    0   70
##  [416,]    0    0
##  [417,]  253  251
##  [418,]   58    0
##  [419,]    7  221
##  [420,]    0   45
##  [421,]  252  253
##  [422,]    0    0
##  [423,]    0   77
##  [424,]    0    0
##  [425,]  253  253
##  [426,]   23   29
##  [427,]  252  252
##  [428,]    0    0
##  [429,]  135  246
##  [430,]    0    0
##  [431,]    0    0
##  [432,]    0    0
##  [433,]    0    0
##  [434,]  253  253
##  [435,]    0    0
##  [436,]    0    0
##  [437,]    0    0
##  [438,]   40    8
##  [439,]    0   34
##  [440,]  254  254
##  [441,]    0    0
##  [442,]    0   47
##  [443,]    0    0
##  [444,]   99  253
##  [445,]  222  246
##  [446,]  252  209
##  [447,]    0    0
##  [448,]  172  253
##  [449,]   12  161
##  [450,]    0    0
##  [451,]  251  180
##  [452,]    0    0
##  [453,]  254  253
##  [454,]    0    0
##  [455,]  254  223
##  [456,]  237  252
##  [457,]  252  252
##  [458,]    0    0
##  [459,]    0    0
##  [460,]   49  159
##  [461,]    0    0
##  [462,]    0    0
##  [463,]    0    0
##  [464,]    0    0
##  [465,]    0    0
##  [466,]    0    0
##  [467,]   98  254
##  [468,]    0    0
##  [469,]    0    0
##  [470,]    0    0
##  [471,]    0    0
##  [472,]   51   51
##  [473,]  154  250
##  [474,]    0    0
##  [475,]    0    0
##  [476,]  211  253
##  [477,]    0    0
##  [478,]    0    0
##  [479,]  114  253
##  [480,]  254  253
##  [481,]    0    0
##  [482,]    0    0
##  [483,]    0    0
##  [484,]    0    0
##  [485,]  253  132
##  [486,]    0    0
##  [487,]   67    0
##  [488,]    0    9
##  [489,]  254  255
##  [490,]    0    0
##  [491,]  253  250
##  [492,]    0  255
##  [493,]  252  250
##  [494,]    0    0
##  [495,]    0    0
##  [496,]  253  253
##  [497,]  202  203
##  [498,]    0    0
##  [499,]    0    0
##  [500,]  130   76
##  [ reached getOption(&quot;max.print&quot;) -- omitted 500 rows ]</code></pre>
<div class="sourceCode" id="cb289"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb289-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb289-1" aria-hidden="true"></a>x[<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">3</span>),]</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26] [,27] [,28] [,29] [,30] [,31]
## [1,]    0    0    0    0    0    0    0    0    0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0
##      [,32] [,33] [,34] [,35] [,36] [,37] [,38] [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50] [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60]
## [1,]     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0
##      [,61] [,62] [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74] [,75] [,76] [,77] [,78] [,79] [,80] [,81] [,82] [,83] [,84] [,85] [,86] [,87] [,88] [,89]
## [1,]     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0
##      [,90] [,91] [,92] [,93] [,94] [,95] [,96] [,97] [,98] [,99] [,100] [,101] [,102] [,103] [,104] [,105] [,106] [,107] [,108] [,109] [,110] [,111] [,112] [,113] [,114] [,115]
## [1,]     0     0     0     0     0     0     0     0     0     0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0
##      [,116] [,117] [,118] [,119] [,120] [,121] [,122] [,123] [,124] [,125] [,126] [,127] [,128] [,129] [,130] [,131] [,132] [,133] [,134] [,135] [,136] [,137] [,138] [,139] [,140]
## [1,]      0      0      0      0      0      0      0      0      0      0      0      0     51    159    253    159     50      0      0      0      0      0      0      0      0
##      [,141] [,142] [,143] [,144] [,145] [,146] [,147] [,148] [,149] [,150] [,151] [,152] [,153] [,154] [,155] [,156] [,157] [,158] [,159] [,160] [,161] [,162] [,163] [,164] [,165]
## [1,]      0      0      0      0      0      0      0      0      0      0      0      0      0      0     48    238    252    252    252    237      0      0      0      0      0
##      [,166] [,167] [,168] [,169] [,170] [,171] [,172] [,173] [,174] [,175] [,176] [,177] [,178] [,179] [,180] [,181] [,182] [,183] [,184] [,185] [,186] [,187] [,188] [,189] [,190]
## [1,]      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0     54    227    253    252    239    233    252     57      6
##      [,191] [,192] [,193] [,194] [,195] [,196] [,197] [,198] [,199] [,200] [,201] [,202] [,203] [,204] [,205] [,206] [,207] [,208] [,209] [,210] [,211] [,212] [,213] [,214] [,215]
## [1,]      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0     10     60    224    252    253    252    202     84
##      [,216] [,217] [,218] [,219] [,220] [,221] [,222] [,223] [,224] [,225] [,226] [,227] [,228] [,229] [,230] [,231] [,232] [,233] [,234] [,235] [,236] [,237] [,238] [,239] [,240]
## [1,]    252    253    122      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0    163    252    252    252    253
##      [,241] [,242] [,243] [,244] [,245] [,246] [,247] [,248] [,249] [,250] [,251] [,252] [,253] [,254] [,255] [,256] [,257] [,258] [,259] [,260] [,261] [,262] [,263] [,264] [,265]
## [1,]    252    252     96    189    253    167      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0     51    238    253
##      [,266] [,267] [,268] [,269] [,270] [,271] [,272] [,273] [,274] [,275] [,276] [,277] [,278] [,279] [,280] [,281] [,282] [,283] [,284] [,285] [,286] [,287] [,288] [,289] [,290]
## [1,]    253    190    114    253    228     47     79    255    168      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0     48
##      [,291] [,292] [,293] [,294] [,295] [,296] [,297] [,298] [,299] [,300] [,301] [,302] [,303] [,304] [,305] [,306] [,307] [,308] [,309] [,310] [,311] [,312] [,313] [,314] [,315]
## [1,]    238    252    252    179     12     75    121     21      0      0    253    243     50      0      0      0      0      0      0      0      0      0      0      0      0
##      [,316] [,317] [,318] [,319] [,320] [,321] [,322] [,323] [,324] [,325] [,326] [,327] [,328] [,329] [,330] [,331] [,332] [,333] [,334] [,335] [,336] [,337] [,338] [,339] [,340]
## [1,]      0     38    165    253    233    208     84      0      0      0      0      0      0    253    252    165      0      0      0      0      0      0      0      0      0
##      [,341] [,342] [,343] [,344] [,345] [,346] [,347] [,348] [,349] [,350] [,351] [,352] [,353] [,354] [,355] [,356] [,357] [,358] [,359] [,360] [,361] [,362] [,363] [,364] [,365]
## [1,]      0      0      0      7    178    252    240     71     19     28      0      0      0      0      0      0    253    252    195      0      0      0      0      0      0
##      [,366] [,367] [,368] [,369] [,370] [,371] [,372] [,373] [,374] [,375] [,376] [,377] [,378] [,379] [,380] [,381] [,382] [,383] [,384] [,385] [,386] [,387] [,388] [,389] [,390]
## [1,]      0      0      0      0      0      0     57    252    252     63      0      0      0      0      0      0      0      0      0    253    252    195      0      0      0
##      [,391] [,392] [,393] [,394] [,395] [,396] [,397] [,398] [,399] [,400] [,401] [,402] [,403] [,404] [,405] [,406] [,407] [,408] [,409] [,410] [,411] [,412] [,413] [,414] [,415]
## [1,]      0      0      0      0      0      0      0      0      0    198    253    190      0      0      0      0      0      0      0      0      0      0    255    253    196
##      [,416] [,417] [,418] [,419] [,420] [,421] [,422] [,423] [,424] [,425] [,426] [,427] [,428] [,429] [,430] [,431] [,432] [,433] [,434] [,435] [,436] [,437] [,438] [,439] [,440]
## [1,]      0      0      0      0      0      0      0      0      0      0      0     76    246    252    112      0      0      0      0      0      0      0      0      0      0
##      [,441] [,442] [,443] [,444] [,445] [,446] [,447] [,448] [,449] [,450] [,451] [,452] [,453] [,454] [,455] [,456] [,457] [,458] [,459] [,460] [,461] [,462] [,463] [,464] [,465]
## [1,]    253    252    148      0      0      0      0      0      0      0      0      0      0      0     85    252    230     25      0      0      0      0      0      0      0
##      [,466] [,467] [,468] [,469] [,470] [,471] [,472] [,473] [,474] [,475] [,476] [,477] [,478] [,479] [,480] [,481] [,482] [,483] [,484] [,485] [,486] [,487] [,488] [,489] [,490]
## [1,]      0      7    135    253    186     12      0      0      0      0      0      0      0      0      0      0      0     85    252    223      0      0      0      0      0
##      [,491] [,492] [,493] [,494] [,495] [,496] [,497] [,498] [,499] [,500] [,501] [,502] [,503] [,504] [,505] [,506] [,507] [,508] [,509] [,510] [,511] [,512] [,513] [,514] [,515]
## [1,]      0      0      0      7    131    252    225     71      0      0      0      0      0      0      0      0      0      0      0      0     85    252    145      0      0
##      [,516] [,517] [,518] [,519] [,520] [,521] [,522] [,523] [,524] [,525] [,526] [,527] [,528] [,529] [,530] [,531] [,532] [,533] [,534] [,535] [,536] [,537] [,538] [,539] [,540]
## [1,]      0      0      0      0      0     48    165    252    173      0      0      0      0      0      0      0      0      0      0      0      0      0      0     86    253
##      [,541] [,542] [,543] [,544] [,545] [,546] [,547] [,548] [,549] [,550] [,551] [,552] [,553] [,554] [,555] [,556] [,557] [,558] [,559] [,560] [,561] [,562] [,563] [,564] [,565]
## [1,]    225      0      0      0      0      0      0    114    238    253    162      0      0      0      0      0      0      0      0      0      0      0      0      0      0
##      [,566] [,567] [,568] [,569] [,570] [,571] [,572] [,573] [,574] [,575] [,576] [,577] [,578] [,579] [,580] [,581] [,582] [,583] [,584] [,585] [,586] [,587] [,588] [,589] [,590]
## [1,]      0     85    252    249    146     48     29     85    178    225    253    223    167     56      0      0      0      0      0      0      0      0      0      0      0
##      [,591] [,592] [,593] [,594] [,595] [,596] [,597] [,598] [,599] [,600] [,601] [,602] [,603] [,604] [,605] [,606] [,607] [,608] [,609] [,610] [,611] [,612] [,613] [,614] [,615]
## [1,]      0      0      0      0     85    252    252    252    229    215    252    252    252    196    130      0      0      0      0      0      0      0      0      0      0
##      [,616] [,617] [,618] [,619] [,620] [,621] [,622] [,623] [,624] [,625] [,626] [,627] [,628] [,629] [,630] [,631] [,632] [,633] [,634] [,635] [,636] [,637] [,638] [,639] [,640]
## [1,]      0      0      0      0      0      0      0     28    199    252    252    253    252    252    233    145      0      0      0      0      0      0      0      0      0
##      [,641] [,642] [,643] [,644] [,645] [,646] [,647] [,648] [,649] [,650] [,651] [,652] [,653] [,654] [,655] [,656] [,657] [,658] [,659] [,660] [,661] [,662] [,663] [,664] [,665]
## [1,]      0      0      0      0      0      0      0      0      0      0      0     25    128    252    253    252    141     37      0      0      0      0      0      0      0
##      [,666] [,667] [,668] [,669] [,670] [,671] [,672] [,673] [,674] [,675] [,676] [,677] [,678] [,679] [,680] [,681] [,682] [,683] [,684] [,685] [,686] [,687] [,688] [,689] [,690]
## [1,]      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0
##      [,691] [,692] [,693] [,694] [,695] [,696] [,697] [,698] [,699] [,700] [,701] [,702] [,703] [,704] [,705] [,706] [,707] [,708] [,709] [,710] [,711] [,712] [,713] [,714] [,715]
## [1,]      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0
##      [,716] [,717] [,718] [,719] [,720] [,721] [,722] [,723] [,724] [,725] [,726] [,727] [,728] [,729] [,730] [,731] [,732] [,733] [,734] [,735] [,736] [,737] [,738] [,739] [,740]
## [1,]      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0
##      [,741] [,742] [,743] [,744] [,745] [,746] [,747] [,748] [,749] [,750] [,751] [,752] [,753] [,754] [,755] [,756] [,757] [,758] [,759] [,760] [,761] [,762] [,763] [,764] [,765]
## [1,]      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0
##      [,766] [,767] [,768] [,769] [,770] [,771] [,772] [,773] [,774] [,775] [,776] [,777] [,778] [,779] [,780] [,781] [,782] [,783] [,784]
## [1,]      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0
##  [ reached getOption(&quot;max.print&quot;) -- omitted 1 row ]</code></pre>
<div class="sourceCode" id="cb291"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb291-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb291-1" aria-hidden="true"></a>new_x &lt;-<span class="st"> </span>x[ ,<span class="kw">colSds</span>(x) <span class="op">&gt;</span><span class="st"> </span><span class="dv">60</span>]</span>
<span id="cb291-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb291-2" aria-hidden="true"></a><span class="kw">dim</span>(new_x)</span></code></pre></div>
<pre><code>## [1] 1000  314</code></pre>
<div class="sourceCode" id="cb293"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb293-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb293-1" aria-hidden="true"></a><span class="kw">class</span>(x[,<span class="dv">1</span>])</span></code></pre></div>
<pre><code>## [1] &quot;integer&quot;</code></pre>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb295-1" aria-hidden="true"></a><span class="kw">dim</span>(x[<span class="dv">1</span>,])</span></code></pre></div>
<pre><code>## NULL</code></pre>
<div class="sourceCode" id="cb297"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb297-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb297-1" aria-hidden="true"></a><span class="co">#preserve the matrix class</span></span>
<span id="cb297-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb297-2" aria-hidden="true"></a><span class="kw">class</span>(x[ , <span class="dv">1</span>, <span class="dt">drop=</span><span class="ot">FALSE</span>])</span></code></pre></div>
<pre><code>## [1] &quot;matrix&quot; &quot;array&quot;</code></pre>
<div class="sourceCode" id="cb299"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb299-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb299-1" aria-hidden="true"></a><span class="kw">dim</span>(x[, <span class="dv">1</span>, <span class="dt">drop=</span><span class="ot">FALSE</span>])</span></code></pre></div>
<pre><code>## [1] 1000    1</code></pre>
</div>
<div id="indexing-with-matrices-and-binarizing-the-data" class="section level2" number="4.17">
<h2><span class="header-section-number">4.17</span> Indexing with Matrices and Binarizing the Data</h2>
<p>There is a link to the relevant sections of the textbook: <a href="https://rafalab.github.io/dsbook/large-datasets.html#indexing-with-matrices" target="_blank">Indexing with matrices</a> and <a href="https://rafalab.github.io/dsbook/large-datasets.html#binarizing-the-data" target="_blank">Binarizing the data</a></p>
<p><strong>Key points</strong></p>
<ul>
<li>We can use logical operations with matrices:</li>
</ul>
<div class="sourceCode" id="cb301"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb301-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb301-1" aria-hidden="true"></a>mat &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">15</span>, <span class="dv">5</span>, <span class="dv">3</span>)</span>
<span id="cb301-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb301-2" aria-hidden="true"></a>mat[mat <span class="op">&gt;</span><span class="st"> </span><span class="dv">6</span> <span class="op">&amp;</span><span class="st"> </span>mat <span class="op">&lt;</span><span class="st"> </span><span class="dv">12</span>] &lt;-<span class="st"> </span><span class="dv">0</span></span></code></pre></div>
<ul>
<li>We can also binarize the data using just matrix operations:</li>
</ul>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb302-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb302-1" aria-hidden="true"></a>bin_x &lt;-<span class="st"> </span>x</span>
<span id="cb302-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb302-2" aria-hidden="true"></a>bin_x[bin_x <span class="op">&lt;</span><span class="st"> </span><span class="dv">255</span><span class="op">/</span><span class="dv">2</span>] &lt;-<span class="st"> </span><span class="dv">0</span> </span>
<span id="cb302-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb302-3" aria-hidden="true"></a>bin_x[bin_x <span class="op">&gt;</span><span class="st"> </span><span class="dv">255</span><span class="op">/</span><span class="dv">2</span>] &lt;-<span class="st"> </span><span class="dv">1</span></span></code></pre></div>
<p><em>Code</em></p>
<div class="sourceCode" id="cb303"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb303-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb303-1" aria-hidden="true"></a><span class="co">#index with matrices</span></span>
<span id="cb303-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb303-2" aria-hidden="true"></a>mat &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">15</span>, <span class="dv">5</span>, <span class="dv">3</span>)</span>
<span id="cb303-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb303-3" aria-hidden="true"></a><span class="kw">as.vector</span>(mat)</span></code></pre></div>
<pre><code>##  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15</code></pre>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb305-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb305-1" aria-hidden="true"></a><span class="kw">qplot</span>(<span class="kw">as.vector</span>(x), <span class="dt">bins =</span> <span class="dv">30</span>, <span class="dt">color =</span> <span class="kw">I</span>(<span class="st">&quot;black&quot;</span>))</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-84-1.png" width="672" /></p>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb306-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb306-1" aria-hidden="true"></a>new_x &lt;-<span class="st"> </span>x</span>
<span id="cb306-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb306-2" aria-hidden="true"></a>new_x[new_x <span class="op">&lt;</span><span class="st"> </span><span class="dv">50</span>] &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb306-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb306-3" aria-hidden="true"></a></span>
<span id="cb306-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb306-4" aria-hidden="true"></a>mat &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">15</span>, <span class="dv">5</span>, <span class="dv">3</span>)</span>
<span id="cb306-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb306-5" aria-hidden="true"></a>mat[mat <span class="op">&lt;</span><span class="st"> </span><span class="dv">3</span>] &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb306-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb306-6" aria-hidden="true"></a>mat</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,]    0    6   11
## [2,]    0    7   12
## [3,]    3    8   13
## [4,]    4    9   14
## [5,]    5   10   15</code></pre>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb308-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb308-1" aria-hidden="true"></a>mat &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">15</span>, <span class="dv">5</span>, <span class="dv">3</span>)</span>
<span id="cb308-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb308-2" aria-hidden="true"></a>mat[mat <span class="op">&gt;</span><span class="st"> </span><span class="dv">6</span> <span class="op">&amp;</span><span class="st"> </span>mat <span class="op">&lt;</span><span class="st"> </span><span class="dv">12</span>] &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb308-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb308-3" aria-hidden="true"></a>mat</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,]    1    6    0
## [2,]    2    0   12
## [3,]    3    0   13
## [4,]    4    0   14
## [5,]    5    0   15</code></pre>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb310-1" aria-hidden="true"></a><span class="co">#binarize the data</span></span>
<span id="cb310-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb310-2" aria-hidden="true"></a>bin_x &lt;-<span class="st"> </span>x</span>
<span id="cb310-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb310-3" aria-hidden="true"></a>bin_x[bin_x <span class="op">&lt;</span><span class="st"> </span><span class="dv">255</span><span class="op">/</span><span class="dv">2</span>] &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb310-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb310-4" aria-hidden="true"></a>bin_x[bin_x <span class="op">&gt;</span><span class="st"> </span><span class="dv">255</span><span class="op">/</span><span class="dv">2</span>] &lt;-<span class="st"> </span><span class="dv">1</span></span>
<span id="cb310-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb310-5" aria-hidden="true"></a>bin_X &lt;-<span class="st"> </span>(x <span class="op">&gt;</span><span class="st"> </span><span class="dv">255</span><span class="op">/</span><span class="dv">2</span>)<span class="op">*</span><span class="dv">1</span></span></code></pre></div>
</div>
<div id="vectorization-for-matrices-and-matrix-algebra-operations" class="section level2" number="4.18">
<h2><span class="header-section-number">4.18</span> Vectorization for Matrices and Matrix Algebra Operations</h2>
<p>There is a link to the relevant sections of the textbook: <a href="https://rafalab.github.io/dsbook/large-datasets.html#vectorization-for-matrices" target="_blank">Vectorization for matrices</a> and <a href="https://rafalab.github.io/dsbook/large-datasets.html#matrix-algebra-operations" target="_blank">Matrix algebra operations</a></p>
<p><strong>Key points</strong></p>
<ul>
<li>We can scale each row of a matrix using this line of code:</li>
</ul>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb311-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb311-1" aria-hidden="true"></a>(x <span class="op">-</span><span class="st"> </span><span class="kw">rowMeans</span>(x)) <span class="op">/</span><span class="st"> </span><span class="kw">rowSds</span>(x)</span></code></pre></div>
<ul>
<li>To scale each column of a matrix, we use this code:</li>
</ul>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb312-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb312-1" aria-hidden="true"></a><span class="kw">t</span>(<span class="kw">t</span>(X) <span class="op">-</span><span class="st"> </span><span class="kw">colMeans</span>(X))</span></code></pre></div>
<ul>
<li>We can also use a function called <code>sweep()</code> that works similarly to <code>apply()</code>. It takes each entry of a vector and subtracts it from the corresponding row or column:</li>
</ul>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb313-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb313-1" aria-hidden="true"></a>X_mean_<span class="dv">0</span> &lt;-<span class="st"> </span><span class="kw">sweep</span>(x, <span class="dv">2</span>, <span class="kw">colMeans</span>(x))</span></code></pre></div>
<ul>
<li>Matrix multiplication: <code>t(x) %*% x</code></li>
<li>The cross product: <code>crossprod(x)</code></li>
<li>The inverse of a function: <code>solve(crossprod(x))</code></li>
<li>The QR decomposition: <code>qr(x)</code></li>
</ul>
<p><em>Code</em></p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb314-1" aria-hidden="true"></a><span class="co">#scale each row of a matrix</span></span>
<span id="cb314-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb314-2" aria-hidden="true"></a>(x <span class="op">-</span><span class="st"> </span><span class="kw">rowMeans</span>(x)) <span class="op">/</span><span class="st"> </span><span class="kw">rowSds</span>(x)</span>
<span id="cb314-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb314-3" aria-hidden="true"></a></span>
<span id="cb314-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb314-4" aria-hidden="true"></a><span class="co">#scale each column</span></span>
<span id="cb314-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb314-5" aria-hidden="true"></a><span class="kw">t</span>(<span class="kw">t</span>(x) <span class="op">-</span><span class="st"> </span><span class="kw">colMeans</span>(x))</span></code></pre></div>
<div class="sourceCode" id="cb315"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb315-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb315-1" aria-hidden="true"></a><span class="co">#take each entry of a vector and subtracts it from the corresponding row or column</span></span>
<span id="cb315-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb315-2" aria-hidden="true"></a>x_mean_<span class="dv">0</span> &lt;-<span class="st"> </span><span class="kw">sweep</span>(x, <span class="dv">2</span>, <span class="kw">colMeans</span>(x))</span>
<span id="cb315-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb315-3" aria-hidden="true"></a></span>
<span id="cb315-4"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb315-4" aria-hidden="true"></a><span class="co">#divide by the standard deviation</span></span>
<span id="cb315-5"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb315-5" aria-hidden="true"></a>x_mean_<span class="dv">0</span> &lt;-<span class="st"> </span><span class="kw">sweep</span>(x, <span class="dv">2</span>, <span class="kw">colMeans</span>(x))</span>
<span id="cb315-6"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb315-6" aria-hidden="true"></a>x_standardized &lt;-<span class="st"> </span><span class="kw">sweep</span>(x_mean_<span class="dv">0</span>, <span class="dv">2</span>, <span class="kw">colSds</span>(x), <span class="dt">FUN =</span> <span class="st">&quot;/&quot;</span>)</span></code></pre></div>
</div>
<div id="comprehension-check---working-with-matrices" class="section level2" number="4.19">
<h2><span class="header-section-number">4.19</span> Comprehension Check - Working with Matrices</h2>
<ol style="list-style-type: decimal">
<li>Which line of code correctly creates a 100 by 10 matrix of randomly generated normal numbers and assigns it to <code>x</code>?</li>
</ol>
<ul class="task-list">
<li><p><input type="checkbox" disabled="" />
A. <code>x &lt;- matrix(rnorm(1000), 100, 100)</code></p></li>
<li><p><input type="checkbox" disabled="" checked="" />
B. <code>x &lt;- matrix(rnorm(100*10), 100, 10)</code></p></li>
<li><p><input type="checkbox" disabled="" />
C. <code>x &lt;- matrix(rnorm(100*10), 10, 10)</code></p></li>
<li><p><input type="checkbox" disabled="" />
D. <code>x &lt;- matrix(rnorm(100*10), 10, 100)</code></p></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Write the line of code that would give you the specified information about the matrix <code>x</code> that you generated in q1. Do not include any spaces in your line of code.</li>
</ol>
<p>Dimension of x: <code>dim(x)</code></p>
<p>Number of rows of x: <code>nrow(x)</code> or <code>dim(x)[1]</code> or <code>length(x[,1])</code></p>
<p>Number of columns of x: <code>ncol(x)</code> or <code>dim(x)[2]</code> or <code>length(x[1,])</code></p>
<ol start="3" style="list-style-type: decimal">
<li>Which of the following lines of code would add the scalar 1 to row 1, the scalar 2 to row 2, and so on, for the matrix <code>x</code>? Select ALL that apply.</li>
</ol>
<ul class="task-list">
<li><p><input type="checkbox" disabled="" checked="" />
A. <code>x &lt;- x + seq(nrow(x))</code></p></li>
<li><p><input type="checkbox" disabled="" />
B. <code>x &lt;- 1:nrow(x)</code></p></li>
<li><p><input type="checkbox" disabled="" />
C. <code>x &lt;- sweep(x, 2, 1:nrow(x),"+")</code></p></li>
<li><p><input type="checkbox" disabled="" checked="" />
D. <code>x &lt;- sweep(x, 1, 1:nrow(x),"+")</code></p></li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>Which of the following lines of code would add the scalar 1 to column 1, the scalar 2 to column 2, and so on, for the matrix <code>x</code>? Select ALL that apply.</li>
</ol>
<ul class="task-list">
<li><p><input type="checkbox" disabled="" />
A. <code>x &lt;- 1:ncol(x)</code></p></li>
<li><p><input type="checkbox" disabled="" />
B. <code>x &lt;- 1:col(x)</code></p></li>
<li><p><input type="checkbox" disabled="" checked="" />
C. <code>x &lt;- sweep(x, 2, 1:ncol(x), FUN = "+")</code></p></li>
<li><p><input type="checkbox" disabled="" />
D. <code>x &lt;- -x</code></p></li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li>Which code correctly computes the average of each row of x?</li>
</ol>
<ul class="task-list">
<li><p><input type="checkbox" disabled="" />
A. <code>mean(x)</code></p></li>
<li><p><input type="checkbox" disabled="" />
B. <code>rowMedians(x)</code></p></li>
<li><p><input type="checkbox" disabled="" />
C. <code>sapply(x,mean)</code></p></li>
<li><p><input type="checkbox" disabled="" />
D. <code>rowSums(x)</code></p></li>
<li><p><input type="checkbox" disabled="" checked="" />
E. <code>rowMeans(x)</code></p></li>
</ul>
<p>Which code correctly computes the average of each column of x?</p>
<ul class="task-list">
<li><p><input type="checkbox" disabled="" />
A. <code>mean(x)</code></p></li>
<li><p><input type="checkbox" disabled="" />
B. <code>sapply(x,mean)</code></p></li>
<li><p><input type="checkbox" disabled="" checked="" />
C. <code>colMeans(x)</code></p></li>
<li><p><input type="checkbox" disabled="" />
D. <code>colMedians(x)</code></p></li>
<li><p><input type="checkbox" disabled="" />
C. <code>colSums(x)</code></p></li>
</ul>
<ol start="6" style="list-style-type: decimal">
<li>For each observation in the mnist training data, compute the proportion of pixels that are in the <strong>grey area</strong>, defined as values between 50 and 205 (but not including 50 and 205). (To visualize this, you can make a boxplot by digit class.)</li>
</ol>
<p>What proportion of the 60000*784 pixels in the mnist training data are in the grey area overall, defined as values between 50 and 205? Report your answer to at least 3 significant digits.</p>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb316-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb316-1" aria-hidden="true"></a>mnist &lt;-<span class="st"> </span><span class="kw">read_mnist</span>()</span>
<span id="cb316-2"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb316-2" aria-hidden="true"></a>y &lt;-<span class="st"> </span><span class="kw">rowMeans</span>(mnist<span class="op">$</span>train<span class="op">$</span>images<span class="op">&gt;</span><span class="dv">50</span> <span class="op">&amp;</span><span class="st"> </span>mnist<span class="op">$</span>train<span class="op">$</span>images<span class="op">&lt;</span><span class="dv">205</span>)</span>
<span id="cb316-3"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb316-3" aria-hidden="true"></a><span class="kw">qplot</span>(<span class="kw">as.factor</span>(mnist<span class="op">$</span>train<span class="op">$</span>labels), y, <span class="dt">geom =</span> <span class="st">&quot;boxplot&quot;</span>)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-90-1.png" width="672" /></p>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb317-1"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#cb317-1" aria-hidden="true"></a><span class="kw">mean</span>(y) <span class="co"># proportion of pixels</span></span></code></pre></div>
<pre><code>## [1] 0.06183703</code></pre>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="section-2-machine-learning-basics-overview.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="section-4-distance-knn-cross-validation-and-generative-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
