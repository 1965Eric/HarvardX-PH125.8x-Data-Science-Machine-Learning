<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7 Section 6 - Model Fitting and Recommendation Systems Overview | Data Science Machine Learning</title>
  <meta name="description" content="7 Section 6 - Model Fitting and Recommendation Systems Overview | Data Science Machine Learning" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="7 Section 6 - Model Fitting and Recommendation Systems Overview | Data Science Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7 Section 6 - Model Fitting and Recommendation Systems Overview | Data Science Machine Learning" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"/>
<link rel="next" href="section-7-final-assessment.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="learning-objectives.html"><a href="learning-objectives.html"><i class="fa fa-check"></i><b>1</b> Learning Objectives</a>
<ul>
<li class="chapter" data-level="1.1" data-path="learning-objectives.html"><a href="learning-objectives.html#course-overview"><i class="fa fa-check"></i><b>1.1</b> Course Overview</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="learning-objectives.html"><a href="learning-objectives.html#introduction-to-machine-learning"><i class="fa fa-check"></i><b>1.1.1</b> Introduction to Machine Learning</a></li>
<li class="chapter" data-level="1.1.2" data-path="learning-objectives.html"><a href="learning-objectives.html#machine-learning-basics"><i class="fa fa-check"></i><b>1.1.2</b> Machine Learning Basics</a></li>
<li class="chapter" data-level="1.1.3" data-path="learning-objectives.html"><a href="learning-objectives.html#linear-regression-for-prediction-smoothing-and-working-with-matrices"><i class="fa fa-check"></i><b>1.1.3</b> Linear Regression for Prediction, Smoothing, and Working with Matrices</a></li>
<li class="chapter" data-level="1.1.4" data-path="learning-objectives.html"><a href="learning-objectives.html#distance-knn-cross-validation-and-generative-models"><i class="fa fa-check"></i><b>1.1.4</b> Distance, Knn, Cross Validation, and Generative Models</a></li>
<li class="chapter" data-level="1.1.5" data-path="learning-objectives.html"><a href="learning-objectives.html#classification-with-more-than-two-classes-and-the-caret-package"><i class="fa fa-check"></i><b>1.1.5</b> Classification with More than Two Classes and the Caret Package</a></li>
<li class="chapter" data-level="1.1.6" data-path="learning-objectives.html"><a href="learning-objectives.html#model-fitting-and-recommendation-systems"><i class="fa fa-check"></i><b>1.1.6</b> Model Fitting and Recommendation Systems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="section-1-introduction-to-machine-learning-overview.html"><a href="section-1-introduction-to-machine-learning-overview.html"><i class="fa fa-check"></i><b>2</b> Section 1 - Introduction to Machine Learning Overview</a>
<ul>
<li class="chapter" data-level="2.1" data-path="section-1-introduction-to-machine-learning-overview.html"><a href="section-1-introduction-to-machine-learning-overview.html#notation"><i class="fa fa-check"></i><b>2.1</b> Notation</a></li>
<li class="chapter" data-level="2.2" data-path="section-1-introduction-to-machine-learning-overview.html"><a href="section-1-introduction-to-machine-learning-overview.html#an-example"><i class="fa fa-check"></i><b>2.2</b> An Example</a></li>
<li class="chapter" data-level="2.3" data-path="section-1-introduction-to-machine-learning-overview.html"><a href="section-1-introduction-to-machine-learning-overview.html#comprehension-check---introduction-to-machine-learning"><i class="fa fa-check"></i><b>2.3</b> Comprehension Check - Introduction to Machine Learning</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html"><i class="fa fa-check"></i><b>3</b> Section 2 - Machine Learning Basics Overview</a>
<ul>
<li class="chapter" data-level="3.1" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#caret-package-training-and-test-sets-and-overall-accuracy"><i class="fa fa-check"></i><b>3.1</b> Caret package, training and test sets, and overall accuracy</a></li>
<li class="chapter" data-level="3.2" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#comprehension-check---basics-of-evaluating-machine-learning-algorithms"><i class="fa fa-check"></i><b>3.2</b> Comprehension Check - Basics of Evaluating Machine Learning Algorithms</a></li>
<li class="chapter" data-level="3.3" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#confusion-matrix"><i class="fa fa-check"></i><b>3.3</b> Confusion matrix</a></li>
<li class="chapter" data-level="3.4" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#balanced-accuracy-and-f1-score"><i class="fa fa-check"></i><b>3.4</b> Balanced accuracy and F1 score</a></li>
<li class="chapter" data-level="3.5" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#prevalence-matters-in-practice"><i class="fa fa-check"></i><b>3.5</b> Prevalence matters in practice</a></li>
<li class="chapter" data-level="3.6" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#roc-and-precision-recall-curves"><i class="fa fa-check"></i><b>3.6</b> ROC and precision-recall curves</a></li>
<li class="chapter" data-level="3.7" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#comprehension-check---practice-with-machine-learning-part-1"><i class="fa fa-check"></i><b>3.7</b> Comprehension Check - Practice with Machine Learning, Part 1</a></li>
<li class="chapter" data-level="3.8" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#comprehension-check---practice-with-machine-learning-part-2"><i class="fa fa-check"></i><b>3.8</b> Comprehension Check - Practice with Machine Learning, Part 2</a></li>
<li class="chapter" data-level="3.9" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#conditional-probabilities"><i class="fa fa-check"></i><b>3.9</b> Conditional probabilities</a></li>
<li class="chapter" data-level="3.10" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#conditional-expectations-and-loss-function"><i class="fa fa-check"></i><b>3.10</b> Conditional expectations and loss function</a></li>
<li class="chapter" data-level="3.11" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#comprehension-check---conditional-probabilities-part-1"><i class="fa fa-check"></i><b>3.11</b> Comprehension Check - Conditional Probabilities, Part 1</a></li>
<li class="chapter" data-level="3.12" data-path="section-2-machine-learning-basics-overview.html"><a href="section-2-machine-learning-basics-overview.html#comprehension-check---conditional-probabilities-part-2"><i class="fa fa-check"></i><b>3.12</b> Comprehension Check - Conditional Probabilities, Part 2</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><i class="fa fa-check"></i><b>4</b> Section 3 - Linear Regression for Prediction, Smoothing, and Working with Matrices Overview</a>
<ul>
<li class="chapter" data-level="4.1" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#linear-regression-for-prediction"><i class="fa fa-check"></i><b>4.1</b> Linear Regression for Prediction</a></li>
<li class="chapter" data-level="4.2" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#predict-function"><i class="fa fa-check"></i><b>4.2</b> Predict Function</a></li>
<li class="chapter" data-level="4.3" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#comprehension-check---linear-regression"><i class="fa fa-check"></i><b>4.3</b> Comprehension Check - Linear Regression</a></li>
<li class="chapter" data-level="4.4" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#regression-for-a-categorical-outcome"><i class="fa fa-check"></i><b>4.4</b> Regression for a Categorical Outcome</a></li>
<li class="chapter" data-level="4.5" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#logistic-regression"><i class="fa fa-check"></i><b>4.5</b> Logistic Regression</a></li>
<li class="chapter" data-level="4.6" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#case-study-2-or-7"><i class="fa fa-check"></i><b>4.6</b> Case Study: 2 or 7</a></li>
<li class="chapter" data-level="4.7" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#comprehension-check---logistic-regression"><i class="fa fa-check"></i><b>4.7</b> Comprehension Check - Logistic Regression</a></li>
<li class="chapter" data-level="4.8" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#introduction-to-smoothing"><i class="fa fa-check"></i><b>4.8</b> Introduction to Smoothing</a></li>
<li class="chapter" data-level="4.9" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#bin-smoothing-and-kernels"><i class="fa fa-check"></i><b>4.9</b> Bin Smoothing and Kernels</a></li>
<li class="chapter" data-level="4.10" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#local-weighted-regression-loess"><i class="fa fa-check"></i><b>4.10</b> Local Weighted Regression (loess)</a></li>
<li class="chapter" data-level="4.11" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#comprehension-check---smoothing"><i class="fa fa-check"></i><b>4.11</b> Comprehension Check - Smoothing</a></li>
<li class="chapter" data-level="4.12" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#matrices"><i class="fa fa-check"></i><b>4.12</b> Matrices</a></li>
<li class="chapter" data-level="4.13" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#matrix-notation"><i class="fa fa-check"></i><b>4.13</b> Matrix Notation</a></li>
<li class="chapter" data-level="4.14" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#converting-a-vector-to-a-matrix"><i class="fa fa-check"></i><b>4.14</b> Converting a Vector to a Matrix</a></li>
<li class="chapter" data-level="4.15" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#row-and-column-summaries-and-apply"><i class="fa fa-check"></i><b>4.15</b> Row and Column Summaries and Apply</a></li>
<li class="chapter" data-level="4.16" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#filtering-columns-based-on-summaries"><i class="fa fa-check"></i><b>4.16</b> Filtering Columns Based on Summaries</a></li>
<li class="chapter" data-level="4.17" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#indexing-with-matrices-and-binarizing-the-data"><i class="fa fa-check"></i><b>4.17</b> Indexing with Matrices and Binarizing the Data</a></li>
<li class="chapter" data-level="4.18" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#vectorization-for-matrices-and-matrix-algebra-operations"><i class="fa fa-check"></i><b>4.18</b> Vectorization for Matrices and Matrix Algebra Operations</a></li>
<li class="chapter" data-level="4.19" data-path="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html"><a href="section-3-linear-regression-for-prediction-smoothing-and-working-with-matrices-overview.html#comprehension-check---working-with-matrices"><i class="fa fa-check"></i><b>4.19</b> Comprehension Check - Working with Matrices</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html"><i class="fa fa-check"></i><b>5</b> Section 4 - Distance, Knn, Cross Validation, and Generative Models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#distance"><i class="fa fa-check"></i><b>5.1</b> Distance</a></li>
<li class="chapter" data-level="5.2" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#comprehension-check---distance"><i class="fa fa-check"></i><b>5.2</b> Comprehension Check - Distance</a></li>
<li class="chapter" data-level="5.3" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#knn"><i class="fa fa-check"></i><b>5.3</b> Knn</a></li>
<li class="chapter" data-level="5.4" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#over-training-and-over-smoothing"><i class="fa fa-check"></i><b>5.4</b> Over-training and Over-smoothing</a></li>
<li class="chapter" data-level="5.5" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#comprehension-check---nearest-neighbors"><i class="fa fa-check"></i><b>5.5</b> Comprehension Check - Nearest Neighbors</a></li>
<li class="chapter" data-level="5.6" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>5.6</b> K-fold cross validation</a></li>
<li class="chapter" data-level="5.7" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#comprehension-check---cross-validation"><i class="fa fa-check"></i><b>5.7</b> Comprehension Check - Cross-validation</a></li>
<li class="chapter" data-level="5.8" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#bootstrap"><i class="fa fa-check"></i><b>5.8</b> Bootstrap</a></li>
<li class="chapter" data-level="5.9" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#comprehension-check---bootstrap"><i class="fa fa-check"></i><b>5.9</b> Comprehension Check - Bootstrap</a></li>
<li class="chapter" data-level="5.10" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#generative-models"><i class="fa fa-check"></i><b>5.10</b> Generative Models</a></li>
<li class="chapter" data-level="5.11" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#naive-bayes"><i class="fa fa-check"></i><b>5.11</b> Naive Bayes</a></li>
<li class="chapter" data-level="5.12" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#controlling-prevalence"><i class="fa fa-check"></i><b>5.12</b> Controlling Prevalence</a></li>
<li class="chapter" data-level="5.13" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#qda-and-lda"><i class="fa fa-check"></i><b>5.13</b> qda and lda</a></li>
<li class="chapter" data-level="5.14" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#case-study---more-than-three-classes"><i class="fa fa-check"></i><b>5.14</b> Case Study - More than Three Classes</a></li>
<li class="chapter" data-level="5.15" data-path="section-4-distance-knn-cross-validation-and-generative-models.html"><a href="section-4-distance-knn-cross-validation-and-generative-models.html#comprehension-check---generative-models"><i class="fa fa-check"></i><b>5.15</b> Comprehension Check - Generative Models</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><i class="fa fa-check"></i><b>6</b> Section 5 - Classification with More than Two Classes and the Caret Package</a>
<ul>
<li class="chapter" data-level="6.1" data-path="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html#trees-motivation"><i class="fa fa-check"></i><b>6.1</b> Trees Motivation</a></li>
<li class="chapter" data-level="6.2" data-path="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html#classification-and-regression-trees-cart"><i class="fa fa-check"></i><b>6.2</b> Classification and Regression Trees (CART)</a></li>
<li class="chapter" data-level="6.3" data-path="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html#classification-decision-trees"><i class="fa fa-check"></i><b>6.3</b> Classification (Decision) Trees</a></li>
<li class="chapter" data-level="6.4" data-path="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html#random-forests"><i class="fa fa-check"></i><b>6.4</b> Random Forests</a></li>
<li class="chapter" data-level="6.5" data-path="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html#comprehension-check---trees-and-random-forests"><i class="fa fa-check"></i><b>6.5</b> Comprehension Check - Trees and Random Forests</a></li>
<li class="chapter" data-level="6.6" data-path="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html#caret-package"><i class="fa fa-check"></i><b>6.6</b> Caret Package</a></li>
<li class="chapter" data-level="6.7" data-path="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html#tuning-parameters-with-caret"><i class="fa fa-check"></i><b>6.7</b> Tuning Parameters with Caret</a></li>
<li class="chapter" data-level="6.8" data-path="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html#comprehension-check---caret-package"><i class="fa fa-check"></i><b>6.8</b> Comprehension Check - Caret Package</a></li>
<li class="chapter" data-level="6.9" data-path="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html#titanic-exercises---part-1"><i class="fa fa-check"></i><b>6.9</b> Titanic Exercises - Part 1</a></li>
<li class="chapter" data-level="6.10" data-path="section-5-classification-with-more-than-two-classes-and-the-caret-package.html"><a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html#titanic-exercises---part-2"><i class="fa fa-check"></i><b>6.10</b> Titanic Exercises - Part 2</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html"><i class="fa fa-check"></i><b>7</b> Section 6 - Model Fitting and Recommendation Systems Overview</a>
<ul>
<li class="chapter" data-level="7.1" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#case-study-mnist"><i class="fa fa-check"></i><b>7.1</b> Case Study: MNIST</a></li>
<li class="chapter" data-level="7.2" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#preprocessing-mnist-data"><i class="fa fa-check"></i><b>7.2</b> Preprocessing MNIST Data</a></li>
<li class="chapter" data-level="7.3" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#model-fitting-for-mnist-data"><i class="fa fa-check"></i><b>7.3</b> Model Fitting for MNIST Data</a></li>
<li class="chapter" data-level="7.4" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#variable-importance"><i class="fa fa-check"></i><b>7.4</b> Variable Importance</a></li>
<li class="chapter" data-level="7.5" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#ensembles"><i class="fa fa-check"></i><b>7.5</b> Ensembles</a></li>
<li class="chapter" data-level="7.6" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#comprehension-check---ensembles"><i class="fa fa-check"></i><b>7.6</b> Comprehension Check - Ensembles</a></li>
<li class="chapter" data-level="7.7" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#recommendation-systems"><i class="fa fa-check"></i><b>7.7</b> Recommendation Systems</a></li>
<li class="chapter" data-level="7.8" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#building-the-recommendation-system"><i class="fa fa-check"></i><b>7.8</b> Building the Recommendation System</a></li>
<li class="chapter" data-level="7.9" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#comprehension-check---recommendation-systems"><i class="fa fa-check"></i><b>7.9</b> Comprehension Check - Recommendation Systems</a></li>
<li class="chapter" data-level="7.10" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#regularization"><i class="fa fa-check"></i><b>7.10</b> Regularization</a></li>
<li class="chapter" data-level="7.11" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#comprehension-check---regularization"><i class="fa fa-check"></i><b>7.11</b> Comprehension Check - Regularization</a></li>
<li class="chapter" data-level="7.12" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#matrix-factorization"><i class="fa fa-check"></i><b>7.12</b> Matrix Factorization</a></li>
<li class="chapter" data-level="7.13" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#svd-and-pca"><i class="fa fa-check"></i><b>7.13</b> SVD and PCA</a></li>
<li class="chapter" data-level="7.14" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#comprehension-check---matrix-factorization"><i class="fa fa-check"></i><b>7.14</b> Comprehension Check - Matrix Factorization</a></li>
<li class="chapter" data-level="7.15" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#comprehension-check---dimension-reduction"><i class="fa fa-check"></i><b>7.15</b> Comprehension Check - Dimension Reduction</a></li>
<li class="chapter" data-level="7.16" data-path="section-6-model-fitting-and-recommendation-systems-overview.html"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#comprehension-check---clustering"><i class="fa fa-check"></i><b>7.16</b> Comprehension Check - Clustering</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="section-7-final-assessment.html"><a href="section-7-final-assessment.html"><i class="fa fa-check"></i><b>8</b> Section 7 - Final Assessment</a>
<ul>
<li class="chapter" data-level="8.1" data-path="section-7-final-assessment.html"><a href="section-7-final-assessment.html#breast-cancer-project---part-1"><i class="fa fa-check"></i><b>8.1</b> Breast Cancer Project - Part 1</a></li>
<li class="chapter" data-level="8.2" data-path="section-7-final-assessment.html"><a href="section-7-final-assessment.html#breast-cancer-project---part-2"><i class="fa fa-check"></i><b>8.2</b> Breast Cancer Project - Part 2</a></li>
<li class="chapter" data-level="8.3" data-path="section-7-final-assessment.html"><a href="section-7-final-assessment.html#breast-cancer-project---part-3"><i class="fa fa-check"></i><b>8.3</b> Breast Cancer Project - Part 3</a></li>
<li class="chapter" data-level="8.4" data-path="section-7-final-assessment.html"><a href="section-7-final-assessment.html#breast-cancer-project---part-4"><i class="fa fa-check"></i><b>8.4</b> Breast Cancer Project - Part 4</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="section-6---model-fitting-and-recommendation-systems-overview" class="section level1" number="7">
<h1><span class="header-section-number">7</span> Section 6 - Model Fitting and Recommendation Systems Overview</h1>
<p>In the <strong>Model Fitting and Recommendation Systems</strong> section, you will learn how to apply the machine learning algorithms you have learned.</p>
<p>After completing this section, you will be able to:</p>
<ul>
<li>Apply the methods we have learned to an example, the <strong>MNIST digits</strong>.</li>
<li>Build a <strong>movie recommendation system</strong> using machine learning.</li>
<li>Penalize large estimates that come from small sample sizes using <strong>regularization</strong>.</li>
</ul>
<p>This section has three parts: <strong>case study: MNIST, recommendation systems</strong>, and <strong>regularization</strong>.</p>
<div id="case-study-mnist" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Case Study: MNIST</h2>
<p>There is a link to the relevant section of the textbook: <a href="https://rafalab.github.io/dsbook/machine-learning-in-practice.html" target="_blank">Machine learning in practice</a></p>
<p><strong>Key points</strong></p>
<ul>
<li>We will apply what we have learned in the course on the Modified National Institute of Standards and Technology database (MNIST) digits, a popular dataset used in machine learning competitions.</li>
</ul>
<p><em>Code</em></p>
<div class="sourceCode" id="cb724"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb724-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb724-1" aria-hidden="true"></a>mnist &lt;-<span class="st"> </span><span class="kw">read_mnist</span>()</span>
<span id="cb724-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb724-2" aria-hidden="true"></a></span>
<span id="cb724-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb724-3" aria-hidden="true"></a><span class="kw">names</span>(mnist)</span></code></pre></div>
<pre><code>## [1] &quot;train&quot; &quot;test&quot;</code></pre>
<div class="sourceCode" id="cb726"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb726-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb726-1" aria-hidden="true"></a><span class="kw">dim</span>(mnist<span class="op">$</span>train<span class="op">$</span>images)</span></code></pre></div>
<pre><code>## [1] 60000   784</code></pre>
<div class="sourceCode" id="cb728"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb728-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb728-1" aria-hidden="true"></a><span class="kw">class</span>(mnist<span class="op">$</span>train<span class="op">$</span>labels)</span></code></pre></div>
<pre><code>## [1] &quot;integer&quot;</code></pre>
<div class="sourceCode" id="cb730"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb730-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb730-1" aria-hidden="true"></a><span class="kw">table</span>(mnist<span class="op">$</span>train<span class="op">$</span>labels)</span></code></pre></div>
<pre><code>## 
##    0    1    2    3    4    5    6    7    8    9 
## 5923 6742 5958 6131 5842 5421 5918 6265 5851 5949</code></pre>
<div class="sourceCode" id="cb732"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb732-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb732-1" aria-hidden="true"></a><span class="co"># sample 10k rows from training set, 1k rows from test set</span></span>
<span id="cb732-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb732-2" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb732-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb732-3" aria-hidden="true"></a>index &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">nrow</span>(mnist<span class="op">$</span>train<span class="op">$</span>images), <span class="dv">10000</span>)</span>
<span id="cb732-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb732-4" aria-hidden="true"></a>x &lt;-<span class="st"> </span>mnist<span class="op">$</span>train<span class="op">$</span>images[index,]</span>
<span id="cb732-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb732-5" aria-hidden="true"></a>y &lt;-<span class="st"> </span><span class="kw">factor</span>(mnist<span class="op">$</span>train<span class="op">$</span>labels[index])</span>
<span id="cb732-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb732-6" aria-hidden="true"></a></span>
<span id="cb732-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb732-7" aria-hidden="true"></a>index &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">nrow</span>(mnist<span class="op">$</span>test<span class="op">$</span>images), <span class="dv">1000</span>)</span>
<span id="cb732-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb732-8" aria-hidden="true"></a><span class="co">#note that the line above is the corrected code - code in video at 0:52 is incorrect</span></span>
<span id="cb732-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb732-9" aria-hidden="true"></a>x_test &lt;-<span class="st"> </span>mnist<span class="op">$</span>test<span class="op">$</span>images[index,]</span>
<span id="cb732-10"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb732-10" aria-hidden="true"></a>y_test &lt;-<span class="st"> </span><span class="kw">factor</span>(mnist<span class="op">$</span>test<span class="op">$</span>labels[index])</span></code></pre></div>
</div>
<div id="preprocessing-mnist-data" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Preprocessing MNIST Data</h2>
<p>There is a link to the relevant section of the textbook: <a href="https://rafalab.github.io/dsbook/machine-learning-in-practice.html#preprocessing" target="_blank">Preprocessing</a></p>
<p><strong>Key points</strong></p>
<ul>
<li>Common **preprocessing steps include:</li>
</ul>
<ol style="list-style-type: decimal">
<li>standardizing or transforming predictors and</li>
<li>removing predictors that are not useful, are highly correlated with others, have very few non-unique values, or have close to zero variation.</li>
</ol>
<p><em>Code</em></p>
<div class="sourceCode" id="cb733"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb733-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb733-1" aria-hidden="true"></a>sds &lt;-<span class="st"> </span><span class="kw">colSds</span>(x)</span>
<span id="cb733-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb733-2" aria-hidden="true"></a><span class="kw">qplot</span>(sds, <span class="dt">bins =</span> <span class="dv">256</span>, <span class="dt">color =</span> <span class="kw">I</span>(<span class="st">&quot;black&quot;</span>))</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-200-1.png" width="672" /></p>
<div class="sourceCode" id="cb734"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb734-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb734-1" aria-hidden="true"></a>nzv &lt;-<span class="st"> </span><span class="kw">nearZeroVar</span>(x)</span>
<span id="cb734-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb734-2" aria-hidden="true"></a><span class="kw">image</span>(<span class="kw">matrix</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">784</span> <span class="op">%in%</span><span class="st"> </span>nzv, <span class="dv">28</span>, <span class="dv">28</span>))</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-200-2.png" width="672" /></p>
<div class="sourceCode" id="cb735"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb735-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb735-1" aria-hidden="true"></a>col_index &lt;-<span class="st"> </span><span class="kw">setdiff</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">ncol</span>(x), nzv)</span>
<span id="cb735-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb735-2" aria-hidden="true"></a><span class="kw">length</span>(col_index)</span></code></pre></div>
<pre><code>## [1] 252</code></pre>
</div>
<div id="model-fitting-for-mnist-data" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Model Fitting for MNIST Data</h2>
<p>There is a link to the relevant section of the textbook: <a href="https://rafalab.github.io/dsbook/machine-learning-in-practice.html#k-nearest-neighbor-and-random-forest" target="_blank">k-nearest neighbor and random forest</a></p>
<p><strong>Key points</strong></p>
<ul>
<li>The <strong>caret</strong> package requires that we <strong>add column names</strong> to the feature matrices.</li>
<li>In general, it is a good idea to <strong>test out a small subset of the data</strong> first to get an idea of how long your code will take to run.</li>
</ul>
<p><em>Code</em></p>
<div class="sourceCode" id="cb737"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb737-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb737-1" aria-hidden="true"></a><span class="kw">colnames</span>(x) &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">ncol</span>(mnist<span class="op">$</span>train<span class="op">$</span>images)</span>
<span id="cb737-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb737-2" aria-hidden="true"></a><span class="kw">colnames</span>(x_test) &lt;-<span class="st"> </span><span class="kw">colnames</span>(x)</span>
<span id="cb737-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb737-3" aria-hidden="true"></a></span>
<span id="cb737-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb737-4" aria-hidden="true"></a>control &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="dt">number =</span> <span class="dv">10</span>, <span class="dt">p =</span> <span class="fl">.9</span>)</span>
<span id="cb737-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb737-5" aria-hidden="true"></a>train_knn &lt;-<span class="st"> </span><span class="kw">train</span>(x[,col_index], y,</span>
<span id="cb737-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb737-6" aria-hidden="true"></a>                                <span class="dt">method =</span> <span class="st">&quot;knn&quot;</span>, </span>
<span id="cb737-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb737-7" aria-hidden="true"></a>                                <span class="dt">tuneGrid =</span> <span class="kw">data.frame</span>(<span class="dt">k =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">7</span>)),</span>
<span id="cb737-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb737-8" aria-hidden="true"></a>                                <span class="dt">trControl =</span> control)</span>
<span id="cb737-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb737-9" aria-hidden="true"></a><span class="kw">ggplot</span>(train_knn)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-201-1.png" width="672" /></p>
<div class="sourceCode" id="cb738"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb738-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb738-1" aria-hidden="true"></a>n &lt;-<span class="st"> </span><span class="dv">1000</span></span>
<span id="cb738-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb738-2" aria-hidden="true"></a>b &lt;-<span class="st"> </span><span class="dv">2</span></span>
<span id="cb738-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb738-3" aria-hidden="true"></a>index &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">nrow</span>(x), n)</span>
<span id="cb738-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb738-4" aria-hidden="true"></a>control &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="dt">number =</span> b, <span class="dt">p =</span> <span class="fl">.9</span>)</span>
<span id="cb738-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb738-5" aria-hidden="true"></a>train_knn &lt;-<span class="st"> </span><span class="kw">train</span>(x[index ,col_index], y[index],</span>
<span id="cb738-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb738-6" aria-hidden="true"></a>                   <span class="dt">method =</span> <span class="st">&quot;knn&quot;</span>,</span>
<span id="cb738-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb738-7" aria-hidden="true"></a>                   <span class="dt">tuneGrid =</span> <span class="kw">data.frame</span>(<span class="dt">k =</span> <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">7</span>)),</span>
<span id="cb738-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb738-8" aria-hidden="true"></a>                   <span class="dt">trControl =</span> control)</span>
<span id="cb738-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb738-9" aria-hidden="true"></a>fit_knn &lt;-<span class="st"> </span><span class="kw">knn3</span>(x[ ,col_index], y,  <span class="dt">k =</span> <span class="dv">3</span>)</span>
<span id="cb738-10"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb738-10" aria-hidden="true"></a></span>
<span id="cb738-11"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb738-11" aria-hidden="true"></a>y_hat_knn &lt;-<span class="st"> </span><span class="kw">predict</span>(fit_knn,</span>
<span id="cb738-12"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb738-12" aria-hidden="true"></a>                     x_test[, col_index],</span>
<span id="cb738-13"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb738-13" aria-hidden="true"></a>                     <span class="dt">type=</span><span class="st">&quot;class&quot;</span>)</span>
<span id="cb738-14"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb738-14" aria-hidden="true"></a>cm &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(y_hat_knn, <span class="kw">factor</span>(y_test))</span>
<span id="cb738-15"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb738-15" aria-hidden="true"></a>cm<span class="op">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span></code></pre></div>
<pre><code>## Accuracy 
##    0.955</code></pre>
<div class="sourceCode" id="cb740"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb740-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb740-1" aria-hidden="true"></a>cm<span class="op">$</span>byClass[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>]</span></code></pre></div>
<pre><code>##          Sensitivity Specificity
## Class: 0       1.000       0.998
## Class: 1       1.000       0.992
## Class: 2       0.953       0.999
## Class: 3       0.917       0.993
## Class: 4       0.936       0.996
## Class: 5       0.971       0.991
## Class: 6       0.990       0.998
## Class: 7       0.945       0.994
## Class: 8       0.846       0.998
## Class: 9       0.971       0.991</code></pre>
<div class="sourceCode" id="cb742"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb742-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb742-1" aria-hidden="true"></a>control &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method=</span><span class="st">&quot;cv&quot;</span>, <span class="dt">number =</span> <span class="dv">5</span>, <span class="dt">p =</span> <span class="fl">0.8</span>)</span>
<span id="cb742-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb742-2" aria-hidden="true"></a>grid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">minNode =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">5</span>) , <span class="dt">predFixed =</span> <span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">25</span>, <span class="dv">35</span>, <span class="dv">50</span>))</span>
<span id="cb742-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb742-3" aria-hidden="true"></a>train_rf &lt;-<span class="st">  </span><span class="kw">train</span>(x[, col_index], y,</span>
<span id="cb742-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb742-4" aria-hidden="true"></a>                   <span class="dt">method =</span> <span class="st">&quot;Rborist&quot;</span>,</span>
<span id="cb742-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb742-5" aria-hidden="true"></a>                   <span class="dt">nTree =</span> <span class="dv">50</span>,</span>
<span id="cb742-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb742-6" aria-hidden="true"></a>                   <span class="dt">trControl =</span> control,</span>
<span id="cb742-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb742-7" aria-hidden="true"></a>                   <span class="dt">tuneGrid =</span> grid,</span>
<span id="cb742-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb742-8" aria-hidden="true"></a>                   <span class="dt">nSamp =</span> <span class="dv">5000</span>)</span>
<span id="cb742-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb742-9" aria-hidden="true"></a><span class="kw">ggplot</span>(train_rf)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-201-2.png" width="672" /></p>
<div class="sourceCode" id="cb743"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb743-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb743-1" aria-hidden="true"></a>train_rf<span class="op">$</span>bestTune</span></code></pre></div>
<pre><code>##   predFixed minNode
## 1        10       1</code></pre>
<div class="sourceCode" id="cb745"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb745-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb745-1" aria-hidden="true"></a>fit_rf &lt;-<span class="st"> </span><span class="kw">Rborist</span>(x[, col_index], y,</span>
<span id="cb745-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb745-2" aria-hidden="true"></a>                  <span class="dt">nTree =</span> <span class="dv">1000</span>,</span>
<span id="cb745-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb745-3" aria-hidden="true"></a>                  <span class="dt">minNode =</span> train_rf<span class="op">$</span>bestTune<span class="op">$</span>minNode,</span>
<span id="cb745-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb745-4" aria-hidden="true"></a>                  <span class="dt">predFixed =</span> train_rf<span class="op">$</span>bestTune<span class="op">$</span>predFixed)</span>
<span id="cb745-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb745-5" aria-hidden="true"></a></span>
<span id="cb745-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb745-6" aria-hidden="true"></a>y_hat_rf &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">levels</span>(y)[<span class="kw">predict</span>(fit_rf, x_test[ ,col_index])<span class="op">$</span>yPred])</span>
<span id="cb745-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb745-7" aria-hidden="true"></a>cm &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(y_hat_rf, y_test)</span>
<span id="cb745-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb745-8" aria-hidden="true"></a>cm<span class="op">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span></code></pre></div>
<pre><code>## Accuracy 
##    0.959</code></pre>
<div class="sourceCode" id="cb747"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb747-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb747-1" aria-hidden="true"></a>rafalib<span class="op">::</span><span class="kw">mypar</span>(<span class="dv">3</span>,<span class="dv">4</span>)</span>
<span id="cb747-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb747-2" aria-hidden="true"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">12</span>){</span>
<span id="cb747-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb747-3" aria-hidden="true"></a>     <span class="kw">image</span>(<span class="kw">matrix</span>(x_test[i,], <span class="dv">28</span>, <span class="dv">28</span>)[, <span class="dv">28</span><span class="op">:</span><span class="dv">1</span>], </span>
<span id="cb747-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb747-4" aria-hidden="true"></a>           <span class="dt">main =</span> <span class="kw">paste</span>(<span class="st">&quot;Our prediction:&quot;</span>, y_hat_rf[i]),</span>
<span id="cb747-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb747-5" aria-hidden="true"></a>           <span class="dt">xaxt=</span><span class="st">&quot;n&quot;</span>, <span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>)</span>
<span id="cb747-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb747-6" aria-hidden="true"></a>}</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-201-3.png" width="672" /></p>
</div>
<div id="variable-importance" class="section level2" number="7.4">
<h2><span class="header-section-number">7.4</span> Variable Importance</h2>
<p>There is a link to the relevant sections of the textbook: <a href="https://rafalab.github.io/dsbook/machine-learning-in-practice.html#variable-importance" target="_blank">Variable importance</a> and <a href="https://rafalab.github.io/dsbook/machine-learning-in-practice.html#visual-assessments" target="_blank">Visual assessments</a></p>
<p><strong>Key points</strong></p>
<ul>
<li>The <strong>Rborist</strong> package does not currently support variable importance calculations, but the <strong>randomForest</strong> package does.</li>
<li>An important part of data science is visualizing results to determine why we are failing.</li>
</ul>
<p><em>Code</em></p>
<div class="sourceCode" id="cb748"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb748-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb748-1" aria-hidden="true"></a>x &lt;-<span class="st"> </span>mnist<span class="op">$</span>train<span class="op">$</span>images[index,]</span>
<span id="cb748-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb748-2" aria-hidden="true"></a>y &lt;-<span class="st"> </span><span class="kw">factor</span>(mnist<span class="op">$</span>train<span class="op">$</span>labels[index])</span>
<span id="cb748-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb748-3" aria-hidden="true"></a>rf &lt;-<span class="st"> </span><span class="kw">randomForest</span>(x, y,  <span class="dt">ntree =</span> <span class="dv">50</span>)</span>
<span id="cb748-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb748-4" aria-hidden="true"></a>imp &lt;-<span class="st"> </span><span class="kw">importance</span>(rf)</span>
<span id="cb748-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb748-5" aria-hidden="true"></a>imp</span></code></pre></div>
<pre><code>##     MeanDecreaseGini
## 1             0.0000
## 2             0.0000
## 3             0.0000
## 4             0.0000
## 5             0.0000
## 6             0.0000
## 7             0.0000
## 8             0.0000
## 9             0.0000
## 10            0.0000
## 11            0.0000
## 12            0.0000
## 13            0.0000
## 14            0.0000
## 15            0.0000
## 16            0.0000
## 17            0.0000
## 18            0.0000
## 19            0.0000
## 20            0.0000
## 21            0.0000
## 22            0.0000
## 23            0.0000
## 24            0.0000
## 25            0.0000
## 26            0.0000
## 27            0.0000
## 28            0.0000
## 29            0.0000
## 30            0.0000
## 31            0.0000
## 32            0.0000
## 33            0.0000
## 34            0.0000
## 35            0.0000
## 36            0.0000
## 37            0.0000
## 38            0.0000
## 39            0.0000
## 40            0.0000
## 41            0.0000
## 42            0.0000
## 43            0.0000
## 44            0.0000
## 45            0.0000
## 46            0.0000
## 47            0.0000
## 48            0.0000
## 49            0.0000
## 50            0.0000
## 51            0.0000
## 52            0.0000
## 53            0.0000
## 54            0.0000
## 55            0.0000
## 56            0.0000
## 57            0.0000
## 58            0.0000
## 59            0.0000
## 60            0.0000
## 61            0.0000
## 62            0.0000
## 63            0.0000
## 64            0.0000
## 65            0.0000
## 66            0.0000
## 67            0.0000
## 68            0.0000
## 69            0.0000
## 70            0.0200
## 71            0.0386
## 72            0.3364
## 73            0.4292
## 74            0.1083
## 75            0.1228
## 76            0.0000
## 77            0.0000
## 78            0.0359
## 79            0.0000
## 80            0.0000
## 81            0.0000
## 82            0.0000
## 83            0.0000
## 84            0.0000
## 85            0.0000
## 86            0.0000
## 87            0.0000
## 88            0.0000
## 89            0.0000
## 90            0.0000
## 91            0.0000
## 92            0.0000
## 93            0.0267
## 94            0.0702
## 95            0.0267
## 96            0.1533
## 97            0.5302
## 98            0.1691
## 99            0.1951
## 100           4.3825
## 101           3.7575
## 102           4.0716
## 103           1.4450
## 104           0.5788
## 105           0.0756
## 106           0.0300
## 107           0.0916
## 108           0.0000
## 109           0.0000
## 110           0.0000
## 111           0.0000
## 112           0.0000
## 113           0.0000
## 114           0.0000
## 115           0.0000
## 116           0.0000
## 117           0.0000
## 118           0.0000
## 119           0.0368
## 120           0.0958
## 121           0.0368
## 122           0.4054
## 123           0.1888
## 124           1.6623
## 125           1.0255
## 126           0.9706
## 127           0.9350
## 128           1.8896
## 129           2.3448
## 130           0.9726
## 131           0.7841
## 132           0.3058
## 133           0.2913
## 134           0.0611
## 135           0.4770
## 136           0.0000
## 137           0.0000
## 138           0.0000
## 139           0.0000
## 140           0.0000
## 141           0.0000
## 142           0.0000
## 143           0.0000
## 144           0.0000
## 145           0.0450
## 146           0.4217
## 147           0.1030
## 148           0.4381
## 149           0.2826
## 150           0.6646
## 151           1.4041
## 152           2.1603
## 153           3.1023
## 154           1.7377
## 155           2.9828
## 156           4.4697
## 157           4.6632
## 158           1.9789
## 159           1.1770
## 160           1.2593
## 161           1.1914
## 162           0.4314
## 163           0.9320
## 164           0.5088
## 165           0.0583
## 166           0.0000
## 167           0.0000
## 168           0.0000
## 169           0.0000
## 170           0.0000
## 171           0.0000
## 172           0.0337
## 173           0.0000
## 174           0.0467
## 175           0.0971
## 176           0.2638
## 177           0.8443
## 178           1.3889
## 179           2.3951
## 180           1.8932
## 181           3.7141
## 182           3.1491
## 183           2.5722
## 184           3.5550
## 185           3.7543
## 186           4.1136
## 187           1.2190
## 188           2.7119
## 189           1.3368
## 190           0.7848
## 191           0.5944
## 192           0.6998
## 193           0.0367
## 194           0.0000
## 195           0.0560
## 196           0.0000
## 197           0.0000
## 198           0.0000
## 199           0.0000
## 200           0.0000
## 201           0.0653
## 202           0.1618
## 203           0.2514
## 204           0.1467
## 205           0.7132
## 206           1.0696
## 207           1.8813
## 208           1.5488
## 209           1.6265
## 210           2.3821
## 211           4.1416
## 212           6.0898
## 213           2.8040
## 214           1.9544
## 215           2.9735
## 216           1.1595
## 217           1.2301
## 218           0.7179
## 219           0.8997
## 220           1.4020
## 221           0.8376
## 222           0.0376
## 223           0.0000
## 224           0.0000
## 225           0.0000
## 226           0.0000
## 227           0.0000
## 228           0.0000
## 229           0.1500
## 230           0.1951
## 231           0.6163
## 232           1.3442
## 233           0.8332
## 234           1.1122
## 235           3.0582
## 236           4.9129
## 237           3.2573
## 238           2.7814
## 239           2.9401
## 240           5.4603
## 241           3.9843
## 242           3.9568
## 243           1.1594
## 244           1.9290
## 245           1.5714
## 246           1.1573
## 247           0.9894
## 248           0.7398
## 249           0.2346
## 250           0.5157
## 251           0.0000
## 252           0.0000
## 253           0.0000
## 254           0.0000
## 255           0.0000
## 256           0.0000
## 257           0.0000
## 258           0.0722
## 259           0.6696
## 260           0.3971
## 261           1.1764
## 262           2.2870
## 263           2.6467
## 264           3.0094
## 265           5.8341
## 266           2.1984
## 267           3.1962
## 268           3.5770
## 269           2.7636
## 270           5.0814
## 271           4.8756
## 272           2.4102
## 273           2.2899
## 274           1.2372
## 275           0.3960
## 276           0.7806
## 277           0.2840
## 278           0.0000
## 279           0.0000
## 280           0.0000
## 281           0.0000
## 282           0.0000
## 283           0.0000
## 284           0.0000
## 285           0.1978
## 286           0.0691
## 287           0.8360
## 288           0.8459
## 289           0.9408
## 290           2.0882
## 291           4.3131
## 292           3.5580
## 293           3.2671
## 294           1.9374
## 295           1.9242
## 296           2.6329
## 297           3.0550
## 298           2.8851
## 299           3.3400
## 300           2.2500
## 301           2.8778
## 302           1.3096
## 303           0.5058
## 304           0.1055
## 305           0.1202
## 306           0.0000
## 307           0.0000
## 308           0.0000
## 309           0.0000
## 310           0.0000
## 311           0.0000
## 312           0.0000
## 313           0.0267
## 314           0.1652
## 315           1.0535
## 316           0.9770
## 317           1.1757
## 318           3.9662
## 319           7.4847
## 320           5.0866
## 321           3.2152
## 322           2.9141
## 323           3.5169
## 324           4.8595
## 325           3.6001
## 326           3.6972
## 327           2.4491
## 328           3.2116
## 329           1.3368
## 330           2.0959
## 331           0.6248
## 332           0.1734
## 333           0.1204
## 334           0.0000
## 335           0.0000
## 336           0.0000
## 337           0.0000
## 338           0.0000
## 339           0.0000
## 340           0.0669
## 341           0.0589
## 342           0.0710
## 343           0.7515
## 344           1.5224
## 345           2.9044
## 346           3.4698
## 347           2.9629
## 348           6.6917
## 349           2.8665
## 350           2.5272
## 351           5.2107
## 352           5.2579
## 353           2.5862
## 354           4.0516
## 355           3.9797
## 356           1.2102
## 357           1.9677
## 358           2.8926
## 359           2.4807
## 360           0.2659
## 361           0.0710
## 362           0.0000
## 363           0.0000
## 364           0.0000
## 365           0.0000
## 366           0.0000
## 367           0.0000
## 368           0.0000
## 369           0.0267
## 370           0.1961
## 371           0.6116
## 372           0.9917
## 373           2.6019
## 374           4.5573
## 375           5.0599
## 376           6.0905
## 377           5.3284
## 378           5.1077
## 379           9.6768
## 380           3.0461
## 381           4.7315
## 382           4.3859
## 383           4.5496
## 384           1.2225
## 385           2.1867
## 386           1.7976
## 387           1.3636
## 388           0.2294
## 389           0.0000
## 390           0.0000
## 391           0.0000
## 392           0.0000
## 393           0.0000
## 394           0.0000
## 395           0.0000
## 396           0.0000
## 397           0.2786
## 398           0.3010
## 399           1.2454
## 400           3.1789
## 401           4.4449
## 402           5.5182
## 403           4.3270
## 404           4.0243
## 405           4.0694
## 406           5.5033
## 407           6.6132
## 408           3.8076
## 409           5.1868
## 410           5.2291
## 411           4.3761
## 412           1.2487
## 413           1.6620
## 414           1.7047
## 415           3.3018
## 416           0.3135
## 417           0.0667
## 418           0.0000
## 419           0.0000
## 420           0.0000
## 421           0.0000
## 422           0.0000
## 423           0.0000
## 424           0.0200
## 425           0.1010
## 426           0.3706
## 427           0.8750
## 428           5.2063
## 429           3.6503
## 430           5.5588
## 431           6.5687
## 432           6.3710
## 433           3.7244
## 434           6.4584
## 435           3.8925
## 436           3.1450
## 437           4.6127
## 438           5.8932
## 439           3.6514
## 440           1.8678
## 441           0.7452
## 442           2.3169
## 443           1.7684
## 444           0.3237
## 445           0.0000
## 446           0.0000
## 447           0.0000
## 448           0.0000
## 449           0.0000
## 450           0.0000
## 451           0.0000
## 452           0.0384
## 453           0.0814
## 454           0.5199
## 455           0.5373
## 456           5.9110
## 457           2.8719
## 458           4.4087
## 459           2.8772
## 460           2.8043
## 461           4.5564
## 462           9.2761
## 463           3.5203
## 464           3.9495
## 465           3.0245
## 466           3.5809
## 467           2.6407
## 468           2.9175
## 469           1.9749
## 470           2.2785
## 471           0.5547
## 472           0.2392
## 473           0.1860
## 474           0.0200
## 475           0.0000
## 476           0.0000
## 477           0.0000
## 478           0.0000
## 479           0.0000
## 480           0.0383
## 481           0.0387
## 482           0.4292
## 483           1.6728
## 484           2.5022
## 485           0.4138
## 486           2.9169
## 487           3.0419
## 488           4.1365
## 489           7.1352
## 490           4.9019
## 491           2.8327
## 492           2.5211
## 493           1.7125
## 494           2.7378
## 495           2.8248
## 496           2.0614
## 497           2.3113
## 498           0.9727
## 499           1.6279
## 500           0.5343
## 501           0.3333
## 502           0.0000
## 503           0.0000
## 504           0.0000
## 505           0.0000
## 506           0.0000
## 507           0.0000
## 508           0.0676
## 509           0.2275
## 510           0.2708
## 511           2.4200
## 512           2.5823
## 513           3.0054
## 514           3.4622
## 515           4.5320
## 516           6.1263
## 517           2.3824
## 518           3.3455
## 519           1.9886
## 520           2.9348
## 521           1.1133
## 522           1.4845
## 523           3.0486
## 524           1.7594
## 525           2.0075
## 526           1.0956
## 527           0.7642
## 528           0.5527
## 529           0.0702
## 530           0.0000
## 531           0.0000
## 532           0.0000
## 533           0.0000
## 534           0.0000
## 535           0.0000
## 536           0.0000
## 537           0.1836
## 538           0.8058
## 539           3.7220
## 540           5.5971
## 541           1.8936
## 542           2.1503
## 543           5.3189
## 544           3.1706
## 545           2.5217
## 546           2.2154
## 547           1.6559
## 548           2.3495
## 549           0.9677
## 550           2.5048
## 551           2.7026
## 552           1.4848
## 553           1.0656
## 554           0.5196
## 555           0.4745
## 556           0.5605
## 557           0.1946
## 558           0.0000
## 559           0.0000
## 560           0.0000
## 561           0.0000
## 562           0.0000
## 563           0.0000
## 564           0.0000
## 565           0.0360
## 566           0.7484
## 567           2.0237
## 568           4.3082
## 569           3.1404
## 570           4.0156
## 571           3.2594
## 572           3.2163
## 573           3.2371
## 574           2.6207
## 575           1.3211
## 576           1.4396
## 577           1.4215
## 578           2.6131
## 579           2.1551
## 580           1.6976
## 581           0.4295
## 582           0.7656
## 583           0.1415
## 584           0.1012
## 585           0.0653
## 586           0.1405
## 587           0.0000
## 588           0.0000
## 589           0.0000
## 590           0.0000
## 591           0.0000
## 592           0.0000
## 593           0.3101
## 594           0.8712
## 595           1.2101
## 596           1.5286
## 597           3.0302
## 598           3.8308
## 599           3.8574
## 600           1.4988
## 601           1.4851
## 602           2.2346
## 603           1.6009
## 604           1.5888
## 605           1.7945
## 606           1.9097
## 607           1.8448
## 608           0.7688
## 609           1.4031
## 610           0.4461
## 611           0.1067
## 612           0.2739
## 613           0.0000
## 614           0.0000
## 615           0.0000
## 616           0.0000
## 617           0.0000
## 618           0.0000
## 619           0.0000
## 620           0.0390
## 621           0.1751
## 622           0.1036
## 623           1.4516
## 624           2.0503
## 625           1.8557
## 626           4.5113
## 627           2.0373
## 628           1.6867
## 629           2.8683
## 630           2.0734
## 631           1.8517
## 632           2.4817
## 633           1.4786
## 634           1.3862
## 635           1.1019
## 636           1.0241
## 637           0.4047
## 638           0.3250
## 639           0.0655
## 640           0.0000
## 641           0.0400
## 642           0.0000
## 643           0.0000
## 644           0.0000
## 645           0.0000
## 646           0.0000
## 647           0.0000
## 648           0.0000
## 649           0.0000
## 650           0.0360
## 651           0.5241
## 652           0.7703
## 653           1.3069
## 654           2.9215
## 655           1.3210
## 656           4.7766
## 657           3.5148
## 658           3.5579
## 659           2.7827
## 660           2.0031
## 661           1.1806
## 662           0.6780
## 663           0.4173
## 664           0.5286
## 665           0.0000
## 666           0.0840
## 667           0.1122
## 668           0.1322
## 669           0.0644
## 670           0.0000
## 671           0.0000
## 672           0.0000
## 673           0.0000
## 674           0.0000
## 675           0.0000
## 676           0.0000
## 677           0.0923
## 678           0.1728
## 679           0.2596
## 680           0.2985
## 681           0.2241
## 682           0.5979
## 683           1.1140
## 684           1.2162
## 685           1.9263
## 686           0.9836
## 687           1.6218
## 688           0.6831
## 689           0.4048
## 690           0.4089
## 691           0.4024
## 692           0.0845
## 693           0.1489
## 694           0.0533
## 695           0.0000
## 696           0.0394
## 697           0.0000
## 698           0.0000
## 699           0.0000
## 700           0.0000
## 701           0.0000
## 702           0.0000
## 703           0.0000
## 704           0.0000
## 705           0.0000
## 706           0.0378
## 707           0.0745
## 708           0.0460
## 709           0.0400
## 710           0.8688
## 711           0.5995
## 712           1.3124
## 713           0.3276
## 714           2.1420
## 715           0.5888
## 716           0.1989
## 717           0.6024
## 718           0.1311
## 719           0.1512
## 720           0.0356
## 721           0.0000
## 722           0.0000
## 723           0.1434
## 724           0.0000
## 725           0.0000
## 726           0.0000
## 727           0.0000
## 728           0.0000
## 729           0.0000
## 730           0.0000
## 731           0.0000
## 732           0.0000
## 733           0.0000
## 734           0.0000
## 735           0.0000
## 736           0.0367
## 737           0.0000
## 738           0.2851
## 739           0.5083
## 740           0.2420
## 741           0.0676
## 742           0.0320
## 743           0.0709
## 744           0.2129
## 745           0.0382
## 746           0.0350
## 747           0.0326
## 748           0.0000
## 749           0.0000
## 750           0.0393
## 751           0.0000
## 752           0.0000
## 753           0.0000
## 754           0.0000
## 755           0.0000
## 756           0.0000
## 757           0.0000
## 758           0.0000
## 759           0.0000
## 760           0.0000
## 761           0.0000
## 762           0.0000
## 763           0.0000
## 764           0.0000
## 765           0.0000
## 766           0.0000
## 767           0.0000
## 768           0.0000
## 769           0.0000
## 770           0.0000
## 771           0.0371
## 772           0.0000
## 773           0.0000
## 774           0.0000
## 775           0.0000
## 776           0.0000
## 777           0.0000
## 778           0.0000
## 779           0.0000
## 780           0.0000
## 781           0.0000
## 782           0.0000
## 783           0.0000
## 784           0.0000</code></pre>
<div class="sourceCode" id="cb750"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb750-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb750-1" aria-hidden="true"></a><span class="kw">image</span>(<span class="kw">matrix</span>(imp, <span class="dv">28</span>, <span class="dv">28</span>))</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-202-1.png" width="672" /></p>
<div class="sourceCode" id="cb751"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb751-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb751-1" aria-hidden="true"></a>p_max &lt;-<span class="st"> </span><span class="kw">predict</span>(fit_knn, x_test[,col_index])</span>
<span id="cb751-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb751-2" aria-hidden="true"></a>p_max &lt;-<span class="st"> </span><span class="kw">apply</span>(p_max, <span class="dv">1</span>, max)</span>
<span id="cb751-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb751-3" aria-hidden="true"></a>ind  &lt;-<span class="st"> </span><span class="kw">which</span>(y_hat_knn <span class="op">!=</span><span class="st"> </span>y_test)</span>
<span id="cb751-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb751-4" aria-hidden="true"></a>ind &lt;-<span class="st"> </span>ind[<span class="kw">order</span>(p_max[ind], <span class="dt">decreasing =</span> <span class="ot">TRUE</span>)]</span>
<span id="cb751-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb751-5" aria-hidden="true"></a>rafalib<span class="op">::</span><span class="kw">mypar</span>(<span class="dv">3</span>,<span class="dv">4</span>)</span>
<span id="cb751-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb751-6" aria-hidden="true"></a><span class="cf">for</span>(i <span class="cf">in</span> ind[<span class="dv">1</span><span class="op">:</span><span class="dv">12</span>]){</span>
<span id="cb751-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb751-7" aria-hidden="true"></a>    <span class="kw">image</span>(<span class="kw">matrix</span>(x_test[i,], <span class="dv">28</span>, <span class="dv">28</span>)[, <span class="dv">28</span><span class="op">:</span><span class="dv">1</span>],</span>
<span id="cb751-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb751-8" aria-hidden="true"></a>                 <span class="dt">main =</span> <span class="kw">paste0</span>(<span class="st">&quot;Pr(&quot;</span>,y_hat_knn[i],<span class="st">&quot;)=&quot;</span>,<span class="kw">round</span>(p_max[i], <span class="dv">2</span>),</span>
<span id="cb751-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb751-9" aria-hidden="true"></a>                                                                        <span class="st">&quot; but is a &quot;</span>,y_test[i]),</span>
<span id="cb751-10"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb751-10" aria-hidden="true"></a>                 <span class="dt">xaxt=</span><span class="st">&quot;n&quot;</span>, <span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>)</span>
<span id="cb751-11"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb751-11" aria-hidden="true"></a>}</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-202-2.png" width="672" /></p>
<div class="sourceCode" id="cb752"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb752-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb752-1" aria-hidden="true"></a>p_max &lt;-<span class="st"> </span><span class="kw">predict</span>(fit_rf, x_test[,col_index])<span class="op">$</span>census  </span>
<span id="cb752-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb752-2" aria-hidden="true"></a>p_max &lt;-<span class="st"> </span>p_max <span class="op">/</span><span class="st"> </span><span class="kw">rowSums</span>(p_max)</span>
<span id="cb752-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb752-3" aria-hidden="true"></a>p_max &lt;-<span class="st"> </span><span class="kw">apply</span>(p_max, <span class="dv">1</span>, max)</span>
<span id="cb752-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb752-4" aria-hidden="true"></a>ind  &lt;-<span class="st"> </span><span class="kw">which</span>(y_hat_rf <span class="op">!=</span><span class="st"> </span>y_test)</span>
<span id="cb752-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb752-5" aria-hidden="true"></a>ind &lt;-<span class="st"> </span>ind[<span class="kw">order</span>(p_max[ind], <span class="dt">decreasing =</span> <span class="ot">TRUE</span>)]</span>
<span id="cb752-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb752-6" aria-hidden="true"></a>rafalib<span class="op">::</span><span class="kw">mypar</span>(<span class="dv">3</span>,<span class="dv">4</span>)</span>
<span id="cb752-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb752-7" aria-hidden="true"></a><span class="cf">for</span>(i <span class="cf">in</span> ind[<span class="dv">1</span><span class="op">:</span><span class="dv">12</span>]){</span>
<span id="cb752-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb752-8" aria-hidden="true"></a>    <span class="kw">image</span>(<span class="kw">matrix</span>(x_test[i,], <span class="dv">28</span>, <span class="dv">28</span>)[, <span class="dv">28</span><span class="op">:</span><span class="dv">1</span>], </span>
<span id="cb752-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb752-9" aria-hidden="true"></a>                 <span class="dt">main =</span> <span class="kw">paste0</span>(<span class="st">&quot;Pr(&quot;</span>,y_hat_rf[i],<span class="st">&quot;)=&quot;</span>,<span class="kw">round</span>(p_max[i], <span class="dv">2</span>),</span>
<span id="cb752-10"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb752-10" aria-hidden="true"></a>                               <span class="st">&quot; but is a &quot;</span>,y_test[i]),</span>
<span id="cb752-11"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb752-11" aria-hidden="true"></a>                 <span class="dt">xaxt=</span><span class="st">&quot;n&quot;</span>, <span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>)</span>
<span id="cb752-12"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb752-12" aria-hidden="true"></a>}</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-202-3.png" width="672" /></p>
</div>
<div id="ensembles" class="section level2" number="7.5">
<h2><span class="header-section-number">7.5</span> Ensembles</h2>
<p>There is a link to the relevant sections of the textbook: <a href="https://rafalab.github.io/dsbook/machine-learning-in-practice.html#ensembles" target="_blank">Ensembles</a></p>
<p><strong>Key points</strong></p>
<ul>
<li><strong>Ensembles</strong> combine multiple machine learning algorithms into one model to improve predictions.</li>
</ul>
<p><em>Code</em></p>
<div class="sourceCode" id="cb753"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb753-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb753-1" aria-hidden="true"></a>p_rf &lt;-<span class="st"> </span><span class="kw">predict</span>(fit_rf, x_test[,col_index])<span class="op">$</span>census</span>
<span id="cb753-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb753-2" aria-hidden="true"></a>p_rf &lt;-<span class="st"> </span>p_rf <span class="op">/</span><span class="st"> </span><span class="kw">rowSums</span>(p_rf)</span>
<span id="cb753-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb753-3" aria-hidden="true"></a>p_knn &lt;-<span class="st"> </span><span class="kw">predict</span>(fit_knn, x_test[,col_index])</span>
<span id="cb753-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb753-4" aria-hidden="true"></a>p &lt;-<span class="st"> </span>(p_rf <span class="op">+</span><span class="st"> </span>p_knn)<span class="op">/</span><span class="dv">2</span></span>
<span id="cb753-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb753-5" aria-hidden="true"></a>y_pred &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">apply</span>(p, <span class="dv">1</span>, which.max)<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb753-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb753-6" aria-hidden="true"></a><span class="kw">confusionMatrix</span>(y_pred, y_test)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1   2   3   4   5   6   7   8   9
##          0 102   0   1   0   0   0   0   0   0   1
##          1   0 121   1   0   1   1   1   2   0   0
##          2   0   0 102   1   0   0   0   3   0   0
##          3   0   0   0  78   0   1   0   0   3   2
##          4   0   0   0   0 102   0   0   1   1   0
##          5   0   0   0   2   0  68   0   0   5   0
##          6   0   0   1   0   1   0 101   0   0   0
##          7   0   0   1   2   0   0   0 102   0   0
##          8   0   0   0   1   0   0   0   0  81   0
##          9   0   0   0   0   5   0   0   2   1 102
## 
## Overall Statistics
##                                        
##                Accuracy : 0.959        
##                  95% CI : (0.945, 0.97)
##     No Information Rate : 0.121        
##     P-Value [Acc &gt; NIR] : &lt;2e-16       
##                                        
##                   Kappa : 0.954        
##                                        
##  Mcnemar&#39;s Test P-Value : NA           
## 
## Statistics by Class:
## 
##                      Class: 0 Class: 1 Class: 2 Class: 3 Class: 4 Class: 5 Class: 6 Class: 7 Class: 8 Class: 9
## Sensitivity             1.000    1.000    0.962    0.929    0.936    0.971    0.990    0.927    0.890    0.971
## Specificity             0.998    0.993    0.996    0.993    0.998    0.992    0.998    0.997    0.999    0.991
## Pos Pred Value          0.981    0.953    0.962    0.929    0.981    0.907    0.981    0.971    0.988    0.927
## Neg Pred Value          1.000    1.000    0.996    0.993    0.992    0.998    0.999    0.991    0.989    0.997
## Prevalence              0.102    0.121    0.106    0.084    0.109    0.070    0.102    0.110    0.091    0.105
## Detection Rate          0.102    0.121    0.102    0.078    0.102    0.068    0.101    0.102    0.081    0.102
## Detection Prevalence    0.104    0.127    0.106    0.084    0.104    0.075    0.103    0.105    0.082    0.110
## Balanced Accuracy       0.999    0.997    0.979    0.961    0.967    0.982    0.994    0.962    0.945    0.981</code></pre>
</div>
<div id="comprehension-check---ensembles" class="section level2" number="7.6">
<h2><span class="header-section-number">7.6</span> Comprehension Check - Ensembles</h2>
<ol style="list-style-type: decimal">
<li>Use the training set to build a model with several of the models available from the caret package. We will test out 10 of the most common machine learning models in this exercise:</li>
</ol>
<div class="sourceCode" id="cb755"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb755-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb755-1" aria-hidden="true"></a>models &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;glm&quot;</span>, <span class="st">&quot;lda&quot;</span>, <span class="st">&quot;naive_bayes&quot;</span>, <span class="st">&quot;svmLinear&quot;</span>, <span class="st">&quot;knn&quot;</span>, <span class="st">&quot;gamLoess&quot;</span>, <span class="st">&quot;multinom&quot;</span>, <span class="st">&quot;qda&quot;</span>, <span class="st">&quot;rf&quot;</span>, <span class="st">&quot;adaboost&quot;</span>)</span></code></pre></div>
<p>Apply all of these models using <code>train()</code> with all the default parameters. You may need to install some packages. Keep in mind that you will probably get some warnings. Also, it will probably take a while to train all of the models - be patient!</p>
<p>Run the following code to train the various models:</p>
<div class="sourceCode" id="cb756"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb756-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb756-1" aria-hidden="true"></a><span class="co"># set.seed(1) # if using R 3.5 or earlier</span></span>
<span id="cb756-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb756-2" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">1</span>, <span class="dt">sample.kind =</span> <span class="st">&quot;Rounding&quot;</span>) <span class="co"># if using R 3.6 or later</span></span></code></pre></div>
<pre><code>## Warning in set.seed(1, sample.kind = &quot;Rounding&quot;): non-uniform &#39;Rounding&#39; sampler used</code></pre>
<div class="sourceCode" id="cb758"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb758-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb758-1" aria-hidden="true"></a><span class="kw">data</span>(<span class="st">&quot;mnist_27&quot;</span>)</span>
<span id="cb758-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb758-2" aria-hidden="true"></a></span>
<span id="cb758-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb758-3" aria-hidden="true"></a>fits &lt;-<span class="st"> </span><span class="kw">lapply</span>(models, <span class="cf">function</span>(model){ </span>
<span id="cb758-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb758-4" aria-hidden="true"></a>    <span class="kw">print</span>(model)</span>
<span id="cb758-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb758-5" aria-hidden="true"></a>    <span class="kw">train</span>(y <span class="op">~</span><span class="st"> </span>., <span class="dt">method =</span> model, <span class="dt">data =</span> mnist_<span class="dv">27</span><span class="op">$</span>train)</span>
<span id="cb758-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb758-6" aria-hidden="true"></a>}) </span></code></pre></div>
<pre><code>## [1] &quot;glm&quot;
## [1] &quot;lda&quot;
## [1] &quot;naive_bayes&quot;
## [1] &quot;svmLinear&quot;
## [1] &quot;knn&quot;
## [1] &quot;gamLoess&quot;</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.46667</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.41586</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.4375</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.41586</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.089286</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : lowerlimit 0.10703</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.094737</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : lowerlimit 0.10703</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.089286</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : lowerlimit 0.092518</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.57895</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.54068</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.46667</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.43969</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.46667</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.43969</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.089286</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : lowerlimit 0.092518</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.57895</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.54068</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.46667</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.43969</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.089286</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : lowerlimit 0.092316</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.089286</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : lowerlimit 0.092316</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.53846</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.53555</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.57895</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.53555</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.46667</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.43969</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.089286</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : lowerlimit 0.10703</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.094737</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : lowerlimit 0.10703</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.57895</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.54071</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.46667</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.43969</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.089286</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : lowerlimit 0.092316</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.46667</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.40628</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.41379</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.40628</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.4375</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.40628</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.089286</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : lowerlimit 0.092518</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.57895</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.54068</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.089286</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : lowerlimit 0.10703</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.094737</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : lowerlimit 0.10703</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.46667</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.43969</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.46667</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.402</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.40323</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.402</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.41379</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.402</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.40426</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.402</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.4375</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.402</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.46667</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.41586</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.4375</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.41586</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.46667</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.43969</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.57895</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.54071</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.46667</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.41586</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.4375</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.41586</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.089286</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : lowerlimit 0.092316</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.089286</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : lowerlimit 0.092518</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.57895</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.54068</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.089286</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : lowerlimit 0.10877</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.094737</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : lowerlimit 0.10877</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.089286</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : lowerlimit 0.092316</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.46667</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.43969</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_1, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.53846</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.50797</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.51111</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.50797</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.57895</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.50797</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : eval 0.53333</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : upperlimit 0.50797</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(x_2, span = 0.5, degree = 1)&quot;]], z, w, span = 0.5, : extrapolation not allowed with blending</code></pre>
<pre><code>## [1] &quot;multinom&quot;
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 384.794809
## final  value 384.794775 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 421.251454 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 384.848555
## final  value 384.848522 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 358.466023
## final  value 358.466014 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 400.257332 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 358.528966
## final  value 358.528958 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 345.361326
## final  value 345.361319 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 389.162400 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 345.427631
## final  value 345.427624 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 370.819967
## iter  10 value 370.819967
## iter  10 value 370.819967
## final  value 370.819967 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 411.520894 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 370.881269
## iter  10 value 370.881269
## iter  10 value 370.881269
## final  value 370.881269 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 338.339240
## final  value 337.642174 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 389.552735 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 337.725860
## final  value 337.725851 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 362.651997
## iter  10 value 362.651996
## iter  10 value 362.651996
## final  value 362.651996 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 404.947235 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 362.716896
## iter  10 value 362.716895
## iter  10 value 362.716894
## final  value 362.716894 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 353.360649 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 396.615883 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 353.427369 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 331.505876
## final  value 331.505837 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 382.233327 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 331.587049
## final  value 331.587010 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 364.158073
## iter  10 value 364.158073
## iter  10 value 364.158073
## final  value 364.158073 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 400.438283 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 364.210111
## iter  10 value 364.210111
## iter  10 value 364.210111
## final  value 364.210111 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 343.760429
## final  value 343.760410 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 387.083157 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 343.826126
## final  value 343.826108 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 377.277862
## iter  10 value 377.277862
## iter  10 value 377.277861
## final  value 377.277861 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 413.479657 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 377.330740
## iter  10 value 377.330739
## iter  10 value 377.330738
## final  value 377.330738 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 363.527477
## final  value 363.527449 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 405.904614 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 363.591426
## final  value 363.591399 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 346.706756
## iter  10 value 346.706754
## iter  10 value 346.706754
## final  value 346.706754 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 393.064300 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 346.778579
## iter  10 value 346.778577
## iter  10 value 346.778577
## final  value 346.778577 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 350.308158
## final  value 350.308124 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 394.686750 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 350.376208
## final  value 350.376174 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 365.423988
## final  value 365.423967 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 407.046095 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 365.486830
## final  value 365.486809 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 375.942875
## final  value 375.942868 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 412.738783 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 375.996860
## final  value 375.996853 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 369.004020
## final  value 369.003531 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 407.374841 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 369.060934
## final  value 369.060455 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 360.551961
## iter  10 value 360.551959
## iter  10 value 360.551959
## final  value 360.551959 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 400.866217 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 360.611945
## iter  10 value 360.611943
## iter  10 value 360.611943
## final  value 360.611943 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 370.467778
## final  value 370.414135 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 406.680836 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 370.519928
## final  value 370.466715 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 355.236387
## final  value 355.236347 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 401.370189 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 355.308279
## final  value 355.308240 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 364.714111
## final  value 364.714051 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 407.312950 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 364.779508
## final  value 364.779448 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 347.812292
## final  value 347.812150 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 389.764148
## iter  10 value 389.764145
## iter  10 value 389.764145
## final  value 389.764145 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 347.875247
## final  value 347.875105 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 319.870357
## final  value 319.870338 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 372.994080 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 319.955663
## final  value 319.955644 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 312.576095
## final  value 312.576064 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 367.284329
## iter  10 value 367.284329
## iter  10 value 367.284329
## final  value 367.284329 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 312.666550
## final  value 312.666520 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 363.313712
## iter  10 value 363.313712
## iter  10 value 363.313712
## final  value 363.313712 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## final  value 403.175943 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 363.373575
## iter  10 value 363.373575
## iter  10 value 363.373575
## final  value 363.373575 
## converged
## # weights:  4 (3 variable)
## initial  value 554.517744 
## iter  10 value 358.900453
## iter  10 value 358.900452
## iter  10 value 358.900452
## final  value 358.900452 
## converged
## [1] &quot;qda&quot;
## [1] &quot;rf&quot;
## note: only 1 unique complexity parameters in default grid. Truncating the grid to 1 .
## 
## [1] &quot;adaboost&quot;</code></pre>
<div class="sourceCode" id="cb914"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb914-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb914-1" aria-hidden="true"></a><span class="kw">names</span>(fits) &lt;-<span class="st"> </span>models</span></code></pre></div>
<p>Did you train all of the models?</p>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
A. Yes</li>
<li><input type="checkbox" disabled="" />
B. No</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Now that you have all the trained models in a list, use <code>sapply()</code> or <code>map()</code> to create a matrix of predictions for the test set. You should end up with a matrix with <code>length(mnist_27$test$y)</code> rows and <code>length(models)</code> columns.</li>
</ol>
<p>What are the dimensions of the matrix of predictions?</p>
<div class="sourceCode" id="cb915"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb915-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb915-1" aria-hidden="true"></a>pred &lt;-<span class="st"> </span><span class="kw">sapply</span>(fits, <span class="cf">function</span>(object) </span>
<span id="cb915-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb915-2" aria-hidden="true"></a>    <span class="kw">predict</span>(object, <span class="dt">newdata =</span> mnist_<span class="dv">27</span><span class="op">$</span>test))</span>
<span id="cb915-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb915-3" aria-hidden="true"></a><span class="kw">dim</span>(pred)</span></code></pre></div>
<pre><code>## [1] 200  10</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Now compute accuracy for each model on the test set.</li>
</ol>
<p>Report the mean accuracy across all models.</p>
<div class="sourceCode" id="cb917"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb917-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb917-1" aria-hidden="true"></a>acc &lt;-<span class="st"> </span><span class="kw">colMeans</span>(pred <span class="op">==</span><span class="st"> </span>mnist_<span class="dv">27</span><span class="op">$</span>test<span class="op">$</span>y)</span>
<span id="cb917-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb917-2" aria-hidden="true"></a>acc</span></code></pre></div>
<pre><code>##         glm         lda naive_bayes   svmLinear         knn    gamLoess    multinom         qda          rf    adaboost 
##       0.750       0.750       0.795       0.755       0.840       0.845       0.750       0.820       0.780       0.805</code></pre>
<div class="sourceCode" id="cb919"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb919-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb919-1" aria-hidden="true"></a><span class="kw">mean</span>(acc)</span></code></pre></div>
<pre><code>## [1] 0.789</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Next, build an ensemble prediction by majority vote and compute the accuracy of the ensemble. Vote 7 if more than 50% of the models are predicting a 7, and 2 otherwise.</li>
</ol>
<p>What is the accuracy of the ensemble?</p>
<div class="sourceCode" id="cb921"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb921-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb921-1" aria-hidden="true"></a>votes &lt;-<span class="st"> </span><span class="kw">rowMeans</span>(pred <span class="op">==</span><span class="st"> &quot;7&quot;</span>)</span>
<span id="cb921-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb921-2" aria-hidden="true"></a>y_hat &lt;-<span class="st"> </span><span class="kw">ifelse</span>(votes <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.5</span>, <span class="st">&quot;7&quot;</span>, <span class="st">&quot;2&quot;</span>)</span>
<span id="cb921-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb921-3" aria-hidden="true"></a><span class="kw">mean</span>(y_hat <span class="op">==</span><span class="st"> </span>mnist_<span class="dv">27</span><span class="op">$</span>test<span class="op">$</span>y)</span></code></pre></div>
<pre><code>## [1] 0.815</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>In Q3, we computed the accuracy of each method on the test set and noticed that the individual accuracies varied.</li>
</ol>
<p>How many of the individual methods do better than the ensemble?</p>
<p>Which individual methods perform better than the ensemble?</p>
<div class="sourceCode" id="cb923"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb923-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb923-1" aria-hidden="true"></a>ind &lt;-<span class="st"> </span>acc <span class="op">&gt;</span><span class="st"> </span><span class="kw">mean</span>(y_hat <span class="op">==</span><span class="st"> </span>mnist_<span class="dv">27</span><span class="op">$</span>test<span class="op">$</span>y)</span>
<span id="cb923-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb923-2" aria-hidden="true"></a><span class="kw">sum</span>(ind)</span></code></pre></div>
<pre><code>## [1] 3</code></pre>
<div class="sourceCode" id="cb925"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb925-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb925-1" aria-hidden="true"></a>models[ind]</span></code></pre></div>
<pre><code>## [1] &quot;knn&quot;      &quot;gamLoess&quot; &quot;qda&quot;</code></pre>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
A. glm</li>
<li><input type="checkbox" disabled="" />
B. lda</li>
<li><input type="checkbox" disabled="" />
C. naive_bayes</li>
<li><input type="checkbox" disabled="" />
D. svmLinear</li>
<li><input type="checkbox" disabled="" checked="" />
E. knn</li>
<li><input type="checkbox" disabled="" checked="" />
F. gamLoess</li>
<li><input type="checkbox" disabled="" />
G. multinom</li>
<li><input type="checkbox" disabled="" checked="" />
H. qda</li>
<li><input type="checkbox" disabled="" />
I. rf</li>
<li><input type="checkbox" disabled="" />
J. adaboost</li>
</ul>
<ol start="6" style="list-style-type: decimal">
<li>It is tempting to remove the methods that do not perform well and re-do the ensemble. The problem with this approach is that we are using the test data to make a decision. However, we could use the minimum accuracy estimates obtained from cross validation with the training data for each model from <code>fit$results$Accuracy</code>. Obtain these estimates and save them in an object. Report the mean of these training set accuracy estimates.</li>
</ol>
<p>What is the mean of these training set accuracy estimates?</p>
<div class="sourceCode" id="cb927"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb927-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb927-1" aria-hidden="true"></a>acc_hat &lt;-<span class="st"> </span><span class="kw">sapply</span>(fits, <span class="cf">function</span>(fit) <span class="kw">min</span>(fit<span class="op">$</span>results<span class="op">$</span>Accuracy))</span>
<span id="cb927-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb927-2" aria-hidden="true"></a><span class="kw">mean</span>(acc_hat)</span></code></pre></div>
<pre><code>## [1] 0.809</code></pre>
<ol start="7" style="list-style-type: decimal">
<li>Now let’s only consider the methods with an estimated accuracy of greater than or equal to 0.8 when constructing the ensemble. Vote 7 if 50% or more of the models are predicting a 7, and 2 otherwise.</li>
</ol>
<p>What is the accuracy of the ensemble now?</p>
<div class="sourceCode" id="cb929"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb929-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb929-1" aria-hidden="true"></a>ind &lt;-<span class="st"> </span>acc_hat <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.8</span></span>
<span id="cb929-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb929-2" aria-hidden="true"></a>votes &lt;-<span class="st"> </span><span class="kw">rowMeans</span>(pred[,ind] <span class="op">==</span><span class="st"> &quot;7&quot;</span>)</span>
<span id="cb929-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb929-3" aria-hidden="true"></a>y_hat &lt;-<span class="st"> </span><span class="kw">ifelse</span>(votes<span class="op">&gt;=</span><span class="fl">0.5</span>, <span class="dv">7</span>, <span class="dv">2</span>)</span>
<span id="cb929-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb929-4" aria-hidden="true"></a><span class="kw">mean</span>(y_hat <span class="op">==</span><span class="st"> </span>mnist_<span class="dv">27</span><span class="op">$</span>test<span class="op">$</span>y)</span></code></pre></div>
<pre><code>## [1] 0.825</code></pre>
</div>
<div id="recommendation-systems" class="section level2" number="7.7">
<h2><span class="header-section-number">7.7</span> Recommendation Systems</h2>
<p>There is a link to the relevant section of the textbook: <a href="https://rafalab.github.io/dsbook/large-datasets.html#recommendation-systems" target="_blank">Recommendation systems</a></p>
<p><strong>Netflix Challenge links</strong></p>
<p>For more information about the “Netflix Challenge,” you can check out these sites:</p>
<ul>
<li><a href="https://bits.blogs.nytimes.com/2009/09/21/netflix-awards-1-million-prize-and-starts-a-new-contest/">https://bits.blogs.nytimes.com/2009/09/21/netflix-awards-1-million-prize-and-starts-a-new-contest/</a></li>
<li><a href="http://blog.echen.me/2011/10/24/winning-the-netflix-prize-a-summary/">http://blog.echen.me/2011/10/24/winning-the-netflix-prize-a-summary/</a></li>
<li><a href="https://www.netflixprize.com/assets/GrandPrize2009_BPC_BellKor.pdf">https://www.netflixprize.com/assets/GrandPrize2009_BPC_BellKor.pdf</a></li>
</ul>
<p><strong>Key points</strong></p>
<ul>
<li><strong>Recommendation systems</strong> are more complicated machine learning challenges because each outcome has a different set of predictors. For example, different users rate a different number of movies and rate different movies.</li>
<li>To compare different models or to see how well we’re doing compared to a baseline, we will use <strong>root mean squared error (RMSE) as our loss function</strong>. We can interpret RMSE similar to standard deviation.</li>
<li>If <span class="math inline">\(N\)</span> is the number of user-movie combinations, <span class="math inline">\(y_{u, i}\)</span> is the rating for movie <span class="math inline">\(i\)</span> by user <span class="math inline">\(u\)</span>, and <span class="math inline">\(\hat{y}_{u, i}\)</span> is our prediction, then <strong>RMSE is defined as follows</strong>:</li>
</ul>
<p><span class="math inline">\(\sqrt{ \frac{1}{N} \sum_{u, i} ( \hat{y}_{u, i} - y_{u, i} )^2}\)</span></p>
<p><em>Code</em></p>
<div class="sourceCode" id="cb931"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb931-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb931-1" aria-hidden="true"></a><span class="kw">data</span>(<span class="st">&quot;movielens&quot;</span>)</span>
<span id="cb931-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb931-2" aria-hidden="true"></a></span>
<span id="cb931-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb931-3" aria-hidden="true"></a><span class="kw">head</span>(movielens)</span></code></pre></div>
<pre><code>##   movieId                                   title year                           genres userId rating  timestamp
## 1      31                         Dangerous Minds 1995                            Drama      1    2.5 1260759144
## 2    1029                                   Dumbo 1941 Animation|Children|Drama|Musical      1    3.0 1260759179
## 3    1061                                Sleepers 1996                         Thriller      1    3.0 1260759182
## 4    1129                    Escape from New York 1981 Action|Adventure|Sci-Fi|Thriller      1    2.0 1260759185
## 5    1172 Cinema Paradiso (Nuovo cinema Paradiso) 1989                            Drama      1    4.0 1260759205
## 6    1263                        Deer Hunter, The 1978                        Drama|War      1    2.0 1260759151</code></pre>
<div class="sourceCode" id="cb933"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb933-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb933-1" aria-hidden="true"></a>movielens <span class="op">%&gt;%</span></span>
<span id="cb933-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb933-2" aria-hidden="true"></a><span class="st">     </span><span class="kw">summarize</span>(<span class="dt">n_users =</span> <span class="kw">n_distinct</span>(userId),</span>
<span id="cb933-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb933-3" aria-hidden="true"></a>               <span class="dt">n_movies =</span> <span class="kw">n_distinct</span>(movieId))</span></code></pre></div>
<pre><code>##   n_users n_movies
## 1     671     9066</code></pre>
<div class="sourceCode" id="cb935"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb935-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb935-1" aria-hidden="true"></a>keep &lt;-<span class="st"> </span>movielens <span class="op">%&gt;%</span></span>
<span id="cb935-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb935-2" aria-hidden="true"></a><span class="st">     </span>dplyr<span class="op">::</span><span class="kw">count</span>(movieId) <span class="op">%&gt;%</span></span>
<span id="cb935-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb935-3" aria-hidden="true"></a><span class="st">     </span><span class="kw">top_n</span>(<span class="dv">5</span>) <span class="op">%&gt;%</span></span>
<span id="cb935-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb935-4" aria-hidden="true"></a><span class="st">     </span><span class="kw">pull</span>(movieId)</span></code></pre></div>
<pre><code>## Selecting by n</code></pre>
<div class="sourceCode" id="cb937"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb937-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb937-1" aria-hidden="true"></a>tab &lt;-<span class="st"> </span>movielens <span class="op">%&gt;%</span></span>
<span id="cb937-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb937-2" aria-hidden="true"></a><span class="st">     </span><span class="kw">filter</span>(userId <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">13</span><span class="op">:</span><span class="dv">20</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb937-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb937-3" aria-hidden="true"></a><span class="st">     </span><span class="kw">filter</span>(movieId <span class="op">%in%</span><span class="st"> </span>keep) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb937-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb937-4" aria-hidden="true"></a><span class="st">     </span>dplyr<span class="op">::</span><span class="kw">select</span>(userId, title, rating) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb937-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb937-5" aria-hidden="true"></a><span class="st">     </span><span class="kw">spread</span>(title, rating)</span>
<span id="cb937-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb937-6" aria-hidden="true"></a>tab <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>()</span></code></pre></div>
<table>
<colgroup>
<col width="5%" />
<col width="10%" />
<col width="10%" />
<col width="21%" />
<col width="21%" />
<col width="29%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">userId</th>
<th align="right">Forrest Gump</th>
<th align="right">Pulp Fiction</th>
<th align="right">Shawshank Redemption, The</th>
<th align="right">Silence of the Lambs, The</th>
<th align="right">Star Wars: Episode IV - A New Hope</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">13</td>
<td align="right">5.0</td>
<td align="right">3.5</td>
<td align="right">4.5</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="right">15</td>
<td align="right">1.0</td>
<td align="right">5.0</td>
<td align="right">2.0</td>
<td align="right">5.0</td>
<td align="right">5.0</td>
</tr>
<tr class="odd">
<td align="right">16</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">4.0</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="right">17</td>
<td align="right">2.5</td>
<td align="right">5.0</td>
<td align="right">5.0</td>
<td align="right">4.5</td>
<td align="right">3.5</td>
</tr>
<tr class="odd">
<td align="right">18</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">3.0</td>
</tr>
<tr class="even">
<td align="right">19</td>
<td align="right">5.0</td>
<td align="right">5.0</td>
<td align="right">4.0</td>
<td align="right">3.0</td>
<td align="right">4.0</td>
</tr>
<tr class="odd">
<td align="right">20</td>
<td align="right">2.0</td>
<td align="right">0.5</td>
<td align="right">4.5</td>
<td align="right">0.5</td>
<td align="right">1.5</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb938"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb938-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb938-1" aria-hidden="true"></a>users &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">unique</span>(movielens<span class="op">$</span>userId), <span class="dv">100</span>)</span>
<span id="cb938-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb938-2" aria-hidden="true"></a>rafalib<span class="op">::</span><span class="kw">mypar</span>()</span>
<span id="cb938-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb938-3" aria-hidden="true"></a>movielens <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(userId <span class="op">%in%</span><span class="st"> </span>users) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb938-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb938-4" aria-hidden="true"></a><span class="st">     </span>dplyr<span class="op">::</span><span class="kw">select</span>(userId, movieId, rating) <span class="op">%&gt;%</span></span>
<span id="cb938-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb938-5" aria-hidden="true"></a><span class="st">     </span><span class="kw">mutate</span>(<span class="dt">rating =</span> <span class="dv">1</span>) <span class="op">%&gt;%</span></span>
<span id="cb938-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb938-6" aria-hidden="true"></a><span class="st">     </span><span class="kw">spread</span>(movieId, rating) <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="kw">sample</span>(<span class="kw">ncol</span>(.), <span class="dv">100</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb938-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb938-7" aria-hidden="true"></a><span class="st">     </span><span class="kw">as.matrix</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">t</span>(.) <span class="op">%&gt;%</span></span>
<span id="cb938-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb938-8" aria-hidden="true"></a><span class="st">     </span><span class="kw">image</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">100</span>,. , <span class="dt">xlab=</span><span class="st">&quot;Movies&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Users&quot;</span>)</span>
<span id="cb938-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb938-9" aria-hidden="true"></a><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span><span class="op">:</span><span class="dv">100</span><span class="fl">+0.5</span>, <span class="dt">v=</span><span class="dv">0</span><span class="op">:</span><span class="dv">100</span><span class="fl">+0.5</span>, <span class="dt">col =</span> <span class="st">&quot;grey&quot;</span>)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-212-1.png" width="672" /></p>
<div class="sourceCode" id="cb939"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb939-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb939-1" aria-hidden="true"></a>movielens <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb939-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb939-2" aria-hidden="true"></a><span class="st">     </span>dplyr<span class="op">::</span><span class="kw">count</span>(movieId) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb939-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb939-3" aria-hidden="true"></a><span class="st">     </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(n)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb939-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb939-4" aria-hidden="true"></a><span class="st">     </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">30</span>, <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb939-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb939-5" aria-hidden="true"></a><span class="st">     </span><span class="kw">scale_x_log10</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb939-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb939-6" aria-hidden="true"></a><span class="st">     </span><span class="kw">ggtitle</span>(<span class="st">&quot;Movies&quot;</span>)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-212-2.png" width="672" /></p>
<div class="sourceCode" id="cb940"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb940-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb940-1" aria-hidden="true"></a>movielens <span class="op">%&gt;%</span></span>
<span id="cb940-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb940-2" aria-hidden="true"></a><span class="st">     </span>dplyr<span class="op">::</span><span class="kw">count</span>(userId) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb940-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb940-3" aria-hidden="true"></a><span class="st">     </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(n)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb940-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb940-4" aria-hidden="true"></a><span class="st">     </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">30</span>, <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb940-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb940-5" aria-hidden="true"></a><span class="st">     </span><span class="kw">scale_x_log10</span>() <span class="op">+</span></span>
<span id="cb940-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb940-6" aria-hidden="true"></a><span class="st">     </span><span class="kw">ggtitle</span>(<span class="st">&quot;Users&quot;</span>)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-212-3.png" width="672" /></p>
<div class="sourceCode" id="cb941"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb941-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb941-1" aria-hidden="true"></a><span class="kw">library</span>(caret)</span>
<span id="cb941-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb941-2" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">755</span>)</span>
<span id="cb941-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb941-3" aria-hidden="true"></a>test_index &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dt">y =</span> movielens<span class="op">$</span>rating, <span class="dt">times =</span> <span class="dv">1</span>,</span>
<span id="cb941-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb941-4" aria-hidden="true"></a>                                  <span class="dt">p =</span> <span class="fl">0.2</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)</span>
<span id="cb941-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb941-5" aria-hidden="true"></a>train_set &lt;-<span class="st"> </span>movielens[<span class="op">-</span>test_index,]</span>
<span id="cb941-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb941-6" aria-hidden="true"></a>test_set &lt;-<span class="st"> </span>movielens[test_index,]</span>
<span id="cb941-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb941-7" aria-hidden="true"></a></span>
<span id="cb941-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb941-8" aria-hidden="true"></a>test_set &lt;-<span class="st"> </span>test_set <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb941-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb941-9" aria-hidden="true"></a><span class="st">     </span><span class="kw">semi_join</span>(train_set, <span class="dt">by =</span> <span class="st">&quot;movieId&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb941-10"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb941-10" aria-hidden="true"></a><span class="st">     </span><span class="kw">semi_join</span>(train_set, <span class="dt">by =</span> <span class="st">&quot;userId&quot;</span>)</span>
<span id="cb941-11"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb941-11" aria-hidden="true"></a></span>
<span id="cb941-12"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb941-12" aria-hidden="true"></a>RMSE &lt;-<span class="st"> </span><span class="cf">function</span>(true_ratings, predicted_ratings){</span>
<span id="cb941-13"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb941-13" aria-hidden="true"></a>     <span class="kw">sqrt</span>(<span class="kw">mean</span>((true_ratings <span class="op">-</span><span class="st"> </span>predicted_ratings)<span class="op">^</span><span class="dv">2</span>))</span>
<span id="cb941-14"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb941-14" aria-hidden="true"></a>}</span></code></pre></div>
</div>
<div id="building-the-recommendation-system" class="section level2" number="7.8">
<h2><span class="header-section-number">7.8</span> Building the Recommendation System</h2>
<p>There is a link to the relevant sections of the textbook: <a href="https://rafalab.github.io/dsbook/large-datasets.html#a-first-model" target="_blank">A first model</a>,<a href="https://rafalab.github.io/dsbook/large-datasets.html#modeling-movie-effects" target="_blank">Modeling movie effects</a> and <a href="https://rafalab.github.io/dsbook/large-datasets.html#user-effects" target="_blank">User effects</a></p>
<p><strong>Key points</strong></p>
<ul>
<li>We start with a model that <strong>assumes the same rating for all movies and all users</strong>, with all the differences explained by random variation: If <span class="math inline">\(\mu\)</span> represents the true rating for all movies and users and <span class="math inline">\(\epsilon\)</span> represents independent errors sampled from the same distribution centered at zero, then:</li>
</ul>
<p><span class="math inline">\(Y_{u, i} = \mu + \epsilon_{u, i}\)</span></p>
<ul>
<li>In this case, the <strong>least squares estimate of <span class="math inline">\(\mu\)</span></strong> — the estimate that minimizes the root mean squared error — is the average rating of all movies across all users.</li>
<li>We can improve our model by adding a term, <span class="math inline">\(b_i\)</span>, that represents the <strong>average rating for movie <span class="math inline">\(i\)</span></strong>:</li>
</ul>
<p><span class="math inline">\(Y_{u, i} = \mu + b_i + \epsilon_{u, i}\)</span></p>
<p><span class="math inline">\(b_i\)</span> is the average of <span class="math inline">\(Y_{u, i}\)</span> minus the overall mean for each movie <span class="math inline">\(i\)</span>.</p>
<p>We can further improve our model by adding <span class="math inline">\(b_u\)</span>, the <strong>user-specific effect</strong>:</p>
<p><span class="math inline">\(Y_{u, i} = \mu + b_i + b_u + \epsilon_{u, i}\)</span></p>
<ul>
<li>Note that because there are thousands of <span class="math inline">\(b\)</span>’s, the <code>lm()</code> function will be very slow or cause R to crash, so <strong>we don’t recommend using linear regression to calculate these effects</strong>.</li>
</ul>
<p><em>Code</em></p>
<div class="sourceCode" id="cb942"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb942-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb942-1" aria-hidden="true"></a>mu_hat &lt;-<span class="st"> </span><span class="kw">mean</span>(train_set<span class="op">$</span>rating)</span>
<span id="cb942-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb942-2" aria-hidden="true"></a>mu_hat</span></code></pre></div>
<pre><code>## [1] 3.54</code></pre>
<div class="sourceCode" id="cb944"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb944-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb944-1" aria-hidden="true"></a>naive_rmse &lt;-<span class="st"> </span><span class="kw">RMSE</span>(test_set<span class="op">$</span>rating, mu_hat)</span>
<span id="cb944-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb944-2" aria-hidden="true"></a>naive_rmse</span></code></pre></div>
<pre><code>## [1] 1.05</code></pre>
<div class="sourceCode" id="cb946"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb946-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb946-1" aria-hidden="true"></a>predictions &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="fl">2.5</span>, <span class="kw">nrow</span>(test_set))</span>
<span id="cb946-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb946-2" aria-hidden="true"></a><span class="kw">RMSE</span>(test_set<span class="op">$</span>rating, predictions)</span></code></pre></div>
<pre><code>## [1] 1.49</code></pre>
<div class="sourceCode" id="cb948"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb948-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb948-1" aria-hidden="true"></a>rmse_results &lt;-<span class="st"> </span><span class="kw">data_frame</span>(<span class="dt">method =</span> <span class="st">&quot;Just the average&quot;</span>, <span class="dt">RMSE =</span> naive_rmse)</span>
<span id="cb948-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb948-2" aria-hidden="true"></a></span>
<span id="cb948-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb948-3" aria-hidden="true"></a><span class="co"># fit &lt;- lm(rating ~ as.factor(userId), data = movielens)</span></span>
<span id="cb948-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb948-4" aria-hidden="true"></a>mu &lt;-<span class="st"> </span><span class="kw">mean</span>(train_set<span class="op">$</span>rating) </span>
<span id="cb948-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb948-5" aria-hidden="true"></a>movie_avgs &lt;-<span class="st"> </span>train_set <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb948-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb948-6" aria-hidden="true"></a><span class="st">     </span><span class="kw">group_by</span>(movieId) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb948-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb948-7" aria-hidden="true"></a><span class="st">     </span><span class="kw">summarize</span>(<span class="dt">b_i =</span> <span class="kw">mean</span>(rating <span class="op">-</span><span class="st"> </span>mu))</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<div class="sourceCode" id="cb950"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb950-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb950-1" aria-hidden="true"></a>movie_avgs <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">qplot</span>(b_i, <span class="dt">geom =</span><span class="st">&quot;histogram&quot;</span>, <span class="dt">bins =</span> <span class="dv">10</span>, <span class="dt">data =</span> ., <span class="dt">color =</span> <span class="kw">I</span>(<span class="st">&quot;black&quot;</span>))</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-213-1.png" width="672" /></p>
<div class="sourceCode" id="cb951"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb951-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb951-1" aria-hidden="true"></a>predicted_ratings &lt;-<span class="st"> </span>mu <span class="op">+</span><span class="st"> </span>test_set <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb951-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb951-2" aria-hidden="true"></a><span class="st">     </span><span class="kw">left_join</span>(movie_avgs, <span class="dt">by=</span><span class="st">&#39;movieId&#39;</span>) <span class="op">%&gt;%</span></span>
<span id="cb951-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb951-3" aria-hidden="true"></a><span class="st">     </span>.<span class="op">$</span>b_i</span>
<span id="cb951-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb951-4" aria-hidden="true"></a></span>
<span id="cb951-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb951-5" aria-hidden="true"></a>model_<span class="dv">1</span>_rmse &lt;-<span class="st"> </span><span class="kw">RMSE</span>(predicted_ratings, test_set<span class="op">$</span>rating)</span>
<span id="cb951-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb951-6" aria-hidden="true"></a>rmse_results &lt;-<span class="st"> </span><span class="kw">bind_rows</span>(rmse_results,</span>
<span id="cb951-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb951-7" aria-hidden="true"></a>                          <span class="kw">data_frame</span>(<span class="dt">method=</span><span class="st">&quot;Movie Effect Model&quot;</span>,</span>
<span id="cb951-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb951-8" aria-hidden="true"></a>                                     <span class="dt">RMSE =</span> model_<span class="dv">1</span>_rmse ))</span>
<span id="cb951-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb951-9" aria-hidden="true"></a></span>
<span id="cb951-10"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb951-10" aria-hidden="true"></a>rmse_results <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>()</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">method</th>
<th align="right">RMSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Just the average</td>
<td align="right">1.048</td>
</tr>
<tr class="even">
<td align="left">Movie Effect Model</td>
<td align="right">0.986</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb952"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb952-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb952-1" aria-hidden="true"></a>train_set <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb952-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb952-2" aria-hidden="true"></a><span class="st">     </span><span class="kw">group_by</span>(userId) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb952-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb952-3" aria-hidden="true"></a><span class="st">     </span><span class="kw">summarize</span>(<span class="dt">b_u =</span> <span class="kw">mean</span>(rating)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb952-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb952-4" aria-hidden="true"></a><span class="st">     </span><span class="kw">filter</span>(<span class="kw">n</span>()<span class="op">&gt;=</span><span class="dv">100</span>) <span class="op">%&gt;%</span></span>
<span id="cb952-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb952-5" aria-hidden="true"></a><span class="st">     </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(b_u)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb952-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb952-6" aria-hidden="true"></a><span class="st">     </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">30</span>, <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>)</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<p><img src="img/figures/unnamed-chunk-213-2.png" width="672" /></p>
<div class="sourceCode" id="cb954"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb954-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb954-1" aria-hidden="true"></a><span class="co"># lm(rating ~ as.factor(movieId) + as.factor(userId))</span></span>
<span id="cb954-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb954-2" aria-hidden="true"></a>user_avgs &lt;-<span class="st"> </span>test_set <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb954-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb954-3" aria-hidden="true"></a><span class="st">     </span><span class="kw">left_join</span>(movie_avgs, <span class="dt">by=</span><span class="st">&#39;movieId&#39;</span>) <span class="op">%&gt;%</span></span>
<span id="cb954-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb954-4" aria-hidden="true"></a><span class="st">     </span><span class="kw">group_by</span>(userId) <span class="op">%&gt;%</span></span>
<span id="cb954-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb954-5" aria-hidden="true"></a><span class="st">     </span><span class="kw">summarize</span>(<span class="dt">b_u =</span> <span class="kw">mean</span>(rating <span class="op">-</span><span class="st"> </span>mu <span class="op">-</span><span class="st"> </span>b_i))</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<div class="sourceCode" id="cb956"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb956-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb956-1" aria-hidden="true"></a>predicted_ratings &lt;-<span class="st"> </span>test_set <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb956-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb956-2" aria-hidden="true"></a><span class="st">     </span><span class="kw">left_join</span>(movie_avgs, <span class="dt">by=</span><span class="st">&#39;movieId&#39;</span>) <span class="op">%&gt;%</span></span>
<span id="cb956-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb956-3" aria-hidden="true"></a><span class="st">     </span><span class="kw">left_join</span>(user_avgs, <span class="dt">by=</span><span class="st">&#39;userId&#39;</span>) <span class="op">%&gt;%</span></span>
<span id="cb956-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb956-4" aria-hidden="true"></a><span class="st">     </span><span class="kw">mutate</span>(<span class="dt">pred =</span> mu <span class="op">+</span><span class="st"> </span>b_i <span class="op">+</span><span class="st"> </span>b_u) <span class="op">%&gt;%</span></span>
<span id="cb956-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb956-5" aria-hidden="true"></a><span class="st">     </span>.<span class="op">$</span>pred</span>
<span id="cb956-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb956-6" aria-hidden="true"></a></span>
<span id="cb956-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb956-7" aria-hidden="true"></a>model_<span class="dv">2</span>_rmse &lt;-<span class="st"> </span><span class="kw">RMSE</span>(predicted_ratings, test_set<span class="op">$</span>rating)</span>
<span id="cb956-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb956-8" aria-hidden="true"></a>rmse_results &lt;-<span class="st"> </span><span class="kw">bind_rows</span>(rmse_results,</span>
<span id="cb956-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb956-9" aria-hidden="true"></a>                          <span class="kw">data_frame</span>(<span class="dt">method=</span><span class="st">&quot;Movie + User Effects Model&quot;</span>,  </span>
<span id="cb956-10"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb956-10" aria-hidden="true"></a>                                     <span class="dt">RMSE =</span> model_<span class="dv">2</span>_rmse ))</span>
<span id="cb956-11"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb956-11" aria-hidden="true"></a>rmse_results <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>()</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">method</th>
<th align="right">RMSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Just the average</td>
<td align="right">1.048</td>
</tr>
<tr class="even">
<td align="left">Movie Effect Model</td>
<td align="right">0.986</td>
</tr>
<tr class="odd">
<td align="left">Movie + User Effects Model</td>
<td align="right">0.885</td>
</tr>
</tbody>
</table>
</div>
<div id="comprehension-check---recommendation-systems" class="section level2" number="7.9">
<h2><span class="header-section-number">7.9</span> Comprehension Check - Recommendation Systems</h2>
<p>The following exercises all work with the movielens data, which can be loaded using the following code:</p>
<div class="sourceCode" id="cb957"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb957-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb957-1" aria-hidden="true"></a><span class="kw">data</span>(<span class="st">&quot;movielens&quot;</span>)</span></code></pre></div>
<ol style="list-style-type: decimal">
<li>Compute the number of ratings for each movie and then plot it against the year the movie came out using a boxplot for each year. Use the square root transformation on the y-axis (number of ratings) when creating your plot.</li>
</ol>
<p>What year has the highest median number of ratings? <code>1995</code></p>
<div class="sourceCode" id="cb958"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb958-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb958-1" aria-hidden="true"></a>movielens <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(movieId) <span class="op">%&gt;%</span></span>
<span id="cb958-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb958-2" aria-hidden="true"></a><span class="st">    </span><span class="kw">summarize</span>(<span class="dt">n =</span> <span class="kw">n</span>(), <span class="dt">year =</span> <span class="kw">as.character</span>(<span class="kw">first</span>(year))) <span class="op">%&gt;%</span></span>
<span id="cb958-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb958-3" aria-hidden="true"></a><span class="st">    </span><span class="kw">qplot</span>(year, n, <span class="dt">data =</span> ., <span class="dt">geom =</span> <span class="st">&quot;boxplot&quot;</span>) <span class="op">+</span></span>
<span id="cb958-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb958-4" aria-hidden="true"></a><span class="st">    </span><span class="kw">coord_trans</span>(<span class="dt">y =</span> <span class="st">&quot;sqrt&quot;</span>) <span class="op">+</span></span>
<span id="cb958-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb958-5" aria-hidden="true"></a><span class="st">    </span><span class="kw">theme</span>(<span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">angle =</span> <span class="dv">90</span>, <span class="dt">hjust =</span> <span class="dv">1</span>))</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<p><img src="img/figures/unnamed-chunk-215-1.png" width="672" /></p>
<ol start="2" style="list-style-type: decimal">
<li>We see that, on average, movies that came out after 1993 get more ratings. We also see that with newer movies, starting in 1993, the number of ratings decreases with year: the more recent a movie is, the less time users have had to rate it.</li>
</ol>
<p>Among movies that came out in 1993 or later, select the top 25 movies with the highest average number of ratings per year (n/year), and caculate the average rating of each of them. To calculate number of ratings per year, use 2018 as the end year.</p>
<p>What is the average rating for the movie The Shawshank Redemption?</p>
<p>What is the average number of ratings per year for the movie Forrest Gump?</p>
<div class="sourceCode" id="cb960"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb960-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb960-1" aria-hidden="true"></a>movielens <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb960-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb960-2" aria-hidden="true"></a><span class="st">    </span><span class="kw">filter</span>(year <span class="op">&gt;=</span><span class="st"> </span><span class="dv">1993</span>) <span class="op">%&gt;%</span></span>
<span id="cb960-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb960-3" aria-hidden="true"></a><span class="st">    </span><span class="kw">group_by</span>(movieId) <span class="op">%&gt;%</span></span>
<span id="cb960-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb960-4" aria-hidden="true"></a><span class="st">    </span><span class="kw">summarize</span>(<span class="dt">n =</span> <span class="kw">n</span>(), <span class="dt">years =</span> <span class="dv">2018</span> <span class="op">-</span><span class="st"> </span><span class="kw">first</span>(year),</span>
<span id="cb960-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb960-5" aria-hidden="true"></a>                <span class="dt">title =</span> title[<span class="dv">1</span>],</span>
<span id="cb960-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb960-6" aria-hidden="true"></a>                <span class="dt">rating =</span> <span class="kw">mean</span>(rating)) <span class="op">%&gt;%</span></span>
<span id="cb960-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb960-7" aria-hidden="true"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">rate =</span> n<span class="op">/</span>years) <span class="op">%&gt;%</span></span>
<span id="cb960-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb960-8" aria-hidden="true"></a><span class="st">    </span><span class="kw">top_n</span>(<span class="dv">25</span>, rate) <span class="op">%&gt;%</span></span>
<span id="cb960-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb960-9" aria-hidden="true"></a><span class="st">    </span><span class="kw">arrange</span>(<span class="kw">desc</span>(rate))</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre><code>## # A tibble: 25 x 6
##    movieId     n years title                                              rating  rate
##      &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;                                               &lt;dbl&gt; &lt;dbl&gt;
##  1     356   341    24 Forrest Gump                                         4.05  14.2
##  2   79132   111     8 Inception                                            4.05  13.9
##  3    2571   259    19 Matrix, The                                          4.18  13.6
##  4     296   324    24 Pulp Fiction                                         4.26  13.5
##  5     318   311    24 Shawshank Redemption, The                            4.49  13.0
##  6   58559   121    10 Dark Knight, The                                     4.24  12.1
##  7    4993   200    17 Lord of the Rings: The Fellowship of the Ring, The   4.18  11.8
##  8    5952   188    16 Lord of the Rings: The Two Towers, The               4.06  11.8
##  9    7153   176    15 Lord of the Rings: The Return of the King, The       4.13  11.7
## 10    2858   220    19 American Beauty                                      4.24  11.6
## # … with 15 more rows</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>From the table constructed in Q2, we can see that the most frequently rated movies tend to have above average ratings. This is not surprising: more people watch popular movies. To confirm this, stratify the post-1993 movies by ratings per year and compute their average ratings. To calculate number of ratings per year, use 2018 as the end year. Make a plot of average rating versus ratings per year and show an estimate of the trend.</li>
</ol>
<p>What type of trend do you observe?</p>
<div class="sourceCode" id="cb963"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb963-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb963-1" aria-hidden="true"></a>movielens <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb963-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb963-2" aria-hidden="true"></a><span class="st">    </span><span class="kw">filter</span>(year <span class="op">&gt;=</span><span class="st"> </span><span class="dv">1993</span>) <span class="op">%&gt;%</span></span>
<span id="cb963-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb963-3" aria-hidden="true"></a><span class="st">    </span><span class="kw">group_by</span>(movieId) <span class="op">%&gt;%</span></span>
<span id="cb963-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb963-4" aria-hidden="true"></a><span class="st">    </span><span class="kw">summarize</span>(<span class="dt">n =</span> <span class="kw">n</span>(), <span class="dt">years =</span> <span class="dv">2018</span> <span class="op">-</span><span class="st"> </span><span class="kw">first</span>(year),</span>
<span id="cb963-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb963-5" aria-hidden="true"></a>                <span class="dt">title =</span> title[<span class="dv">1</span>],</span>
<span id="cb963-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb963-6" aria-hidden="true"></a>                <span class="dt">rating =</span> <span class="kw">mean</span>(rating)) <span class="op">%&gt;%</span></span>
<span id="cb963-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb963-7" aria-hidden="true"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">rate =</span> n<span class="op">/</span>years) <span class="op">%&gt;%</span></span>
<span id="cb963-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb963-8" aria-hidden="true"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(rate, rating)) <span class="op">+</span></span>
<span id="cb963-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb963-9" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb963-10"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb963-10" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_smooth</span>()</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39;</code></pre>
<p><img src="img/figures/unnamed-chunk-217-1.png" width="672" /></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
A. There is no relationship between how often a movie is rated and its average rating.</li>
<li><input type="checkbox" disabled="" />
B. Movies with very few and very many ratings have the highest average ratings.</li>
<li><input type="checkbox" disabled="" checked="" />
C. The more often a movie is rated, the higher its average rating.</li>
<li><input type="checkbox" disabled="" />
D. The more often a movie is rated, the lower its average rating.</li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>Suppose you are doing a predictive analysis in which you need to fill in the missing ratings with some value.</li>
</ol>
<p>Given your observations in the exercise in Q3, which of the following strategies would be most appropriate?</p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
A. Fill in the missing values with the average rating across all movies.</li>
<li><input type="checkbox" disabled="" />
B. Fill in the missing values with 0.</li>
<li><input type="checkbox" disabled="" />
C. Fill in the missing values with a lower value than the average rating across all movies.</li>
<li><input type="checkbox" disabled="" checked="" />
D. Fill in the value with a higher value than the average rating across all movies.</li>
<li><input type="checkbox" disabled="" />
E. None of the above.</li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li>The <code>movielens</code> dataset also includes a time stamp. This variable represents the time and data in which the rating was provided. The units are seconds since January 1, 1970. Create a new column <code>date</code> with the date.</li>
</ol>
<p>Which code correctly creates this new column?</p>
<div class="sourceCode" id="cb966"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb966-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb966-1" aria-hidden="true"></a>movielens &lt;-<span class="st"> </span><span class="kw">mutate</span>(movielens, <span class="dt">date =</span> <span class="kw">as_datetime</span>(timestamp))</span></code></pre></div>
<ul class="task-list">
<li><p><input type="checkbox" disabled="" />
A. <code>movielens &lt;- mutate(movielens, date = as.date(timestamp))</code></p></li>
<li><p><input type="checkbox" disabled="" checked="" />
B. <code>movielens &lt;- mutate(movielens, date = as_datetime(timestamp))</code></p></li>
<li><p><input type="checkbox" disabled="" />
C. <code>movielens &lt;- mutate(movielens, date = as.data(timestamp))</code></p></li>
<li><p><input type="checkbox" disabled="" />
D. <code>movielens &lt;- mutate(movielens, date = timestamp)</code></p></li>
</ul>
<ol start="6" style="list-style-type: decimal">
<li>Compute the average rating for each week and plot this average against date. Hint: use the <code>round_date()</code> function before you <code>group_by()</code>.</li>
</ol>
<p>What type of trend do you observe?</p>
<div class="sourceCode" id="cb967"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb967-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb967-1" aria-hidden="true"></a>movielens <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">date =</span> <span class="kw">round_date</span>(date, <span class="dt">unit =</span> <span class="st">&quot;week&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb967-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb967-2" aria-hidden="true"></a><span class="st">    </span><span class="kw">group_by</span>(date) <span class="op">%&gt;%</span></span>
<span id="cb967-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb967-3" aria-hidden="true"></a><span class="st">    </span><span class="kw">summarize</span>(<span class="dt">rating =</span> <span class="kw">mean</span>(rating)) <span class="op">%&gt;%</span></span>
<span id="cb967-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb967-4" aria-hidden="true"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(date, rating)) <span class="op">+</span></span>
<span id="cb967-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb967-5" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb967-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb967-6" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_smooth</span>()</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="img/figures/unnamed-chunk-219-1.png" width="672" /></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
A. There is very strong evidence of a time effect on average rating.</li>
<li><input type="checkbox" disabled="" checked="" />
B. There is some evidence of a time effect on average rating.</li>
<li><input type="checkbox" disabled="" />
C. There is no evidence of a time effect on average rating (straight horizontal line).</li>
</ul>
<ol start="7" style="list-style-type: decimal">
<li>Consider again the plot you generated in Q6.</li>
</ol>
<p>If we define <span class="math inline">\(d_{u,i}\)</span> as the day for user’s <span class="math inline">\(u\)</span> rating of movie <span class="math inline">\(i\)</span>, which of the following models is most appropriate?</p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
A. <span class="math inline">\(Y_{u,i} = \mu + b_i + b_u + d_{u,i} + \varepsilon_{u,i}\)</span></li>
<li><input type="checkbox" disabled="" />
B. <span class="math inline">\(Y_{u,i} = \mu + b_i + b_u + d_{u,i}\beta + \varepsilon_{u,i}\)</span></li>
<li><input type="checkbox" disabled="" />
C. <span class="math inline">\(Y_{u,i} = \mu + b_i + b_u + d_{u,i}\beta_i + \varepsilon_{u,i}\)</span></li>
<li><input type="checkbox" disabled="" checked="" />
D. <span class="math inline">\(Y_{u,i} = \mu + b_i + b_u + f(d_{u,i}) + \varepsilon_{u,i}\)</span></li>
</ul>
<ol start="8" style="list-style-type: decimal">
<li>The <code>movielens</code> data also has a <code>genres</code> column. This column includes every genre that applies to the movie. Some movies fall under several genres. Define a category as whatever combination appears in this column. Keep only categories with more than 1,000 ratings. Then compute the average and standard error for each category. Plot these as error bar plots.</li>
</ol>
<p>Which genre has the lowest average rating?</p>
<div class="sourceCode" id="cb970"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb970-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb970-1" aria-hidden="true"></a>movielens <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(genres) <span class="op">%&gt;%</span></span>
<span id="cb970-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb970-2" aria-hidden="true"></a><span class="st">    </span><span class="kw">summarize</span>(<span class="dt">n =</span> <span class="kw">n</span>(), <span class="dt">avg =</span> <span class="kw">mean</span>(rating), <span class="dt">se =</span> <span class="kw">sd</span>(rating)<span class="op">/</span><span class="kw">sqrt</span>(<span class="kw">n</span>())) <span class="op">%&gt;%</span></span>
<span id="cb970-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb970-3" aria-hidden="true"></a><span class="st">    </span><span class="kw">filter</span>(n <span class="op">&gt;=</span><span class="st"> </span><span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb970-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb970-4" aria-hidden="true"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">genres =</span> <span class="kw">reorder</span>(genres, avg)) <span class="op">%&gt;%</span></span>
<span id="cb970-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb970-5" aria-hidden="true"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> genres, <span class="dt">y =</span> avg, <span class="dt">ymin =</span> avg <span class="op">-</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span>se, <span class="dt">ymax =</span> avg <span class="op">+</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span>se)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb970-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb970-6" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb970-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb970-7" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_errorbar</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb970-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb970-8" aria-hidden="true"></a><span class="st">    </span><span class="kw">theme</span>(<span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">angle =</span> <span class="dv">90</span>, <span class="dt">hjust =</span> <span class="dv">1</span>))</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<p><img src="img/figures/unnamed-chunk-220-1.png" width="672" /></p>
<ol start="9" style="list-style-type: decimal">
<li>The plot you generated in Q8 shows strong evidence of a genre effect. Consider this plot as you answer the following question.</li>
</ol>
<p>If we define <span class="math inline">\(g_{u,i}\)</span> as the genre for user <span class="math inline">\(u\)</span>’s rating of movie <span class="math inline">\(i\)</span>, which of the following models is most appropriate?</p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
A. <span class="math inline">\(Y_{u,i} = \mu + b_i + b_u + g_{u,i} + \varepsilon_{u,i}\)</span></li>
<li><input type="checkbox" disabled="" />
B. <span class="math inline">\(Y_{u,i} = \mu + b_i + b_u + g_{u,i}\beta + \varepsilon_{u,i}\)</span></li>
<li><input type="checkbox" disabled="" checked="" />
C. <span class="math inline">\(Y_{u,i} = \mu + b_i + b_u + \sum_{k=1}^{K} x_{u,i}^{k} \beta_k + \varepsilon_{u,i}\)</span>, with <span class="math inline">\(x^k_{u,i} = 1\)</span> if <span class="math inline">\(g_{u,i}\)</span> is genre <span class="math inline">\(k\)</span></li>
<li><input type="checkbox" disabled="" />
D. <span class="math inline">\(Y_{u,i} = \mu + b_i + b_u + f(g_{u,i}) + \varepsilon_{u,i}\)</span>, with <span class="math inline">\(f\)</span> a smooth function of <span class="math inline">\(g_{u,i}\)</span></li>
</ul>
</div>
<div id="regularization" class="section level2" number="7.10">
<h2><span class="header-section-number">7.10</span> Regularization</h2>
<p>There is a link to the relevant section of the textbook: <a href="https://rafalab.github.io/dsbook/large-datasets.html#regularization" target="_blank">Regularization</a></p>
<p><strong>Notes</strong></p>
<ul>
<li>To improve our results, we will use <strong>regularization</strong>. Regularization constrains the total variability of the effect sizes by penalizing large estimates that come from small sample sizes.</li>
<li>To estimate the <span class="math inline">\(b\)</span>’s, we will now <strong>minimize this equation</strong>, which contains a penalty term:</li>
</ul>
<p><span class="math inline">\(\frac{1}{N}\sum_{u, i}(y_{u, i}-\mu-b_i)^2 + \lambda\sum_i b_{i}^2\)</span></p>
<p>The first term is the mean squared error and the second is a penalty term that gets larger when many <span class="math inline">\(b\)</span>’s are large.</p>
<p>The values of <span class="math inline">\(b\)</span> that minimize this equation are given by:</p>
<p><span class="math inline">\(\hat{b}_{i}(\lambda) = \frac{1}{\lambda+n_i}\sum_{u=1}^{n_i}(Y_{u, i} - \hat{\mu}),\)</span></p>
<p>where <span class="math inline">\(n_i\)</span> is a number of ratings <span class="math inline">\(b\)</span> for movie <span class="math inline">\(i\)</span>.</p>
<ul>
<li>The <strong>larger <span class="math inline">\(\lambda\)</span> is, the more we shrink</strong>. <span class="math inline">\(\lambda\)</span> is a tuning parameter, so we can use cross-validation to choose it. We should be using full cross-validation on just the training set, without using the test set until the final assessment.</li>
<li>We can also use regularization to estimate the <strong>user effect</strong>. We will now minimize this equation:</li>
</ul>
<p><span class="math inline">\(\frac{1}{N}\sum_{u, i}(y_{u, i}-\mu-b_i-b_u)^2 + \lambda(\sum_i b_{i}^2 + \sum_u b_{u}^2)\)</span></p>
<p><em>Code</em></p>
<div class="sourceCode" id="cb972"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb972-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb972-1" aria-hidden="true"></a><span class="kw">data</span>(<span class="st">&quot;movielens&quot;</span>)</span>
<span id="cb972-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb972-2" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">755</span>)</span>
<span id="cb972-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb972-3" aria-hidden="true"></a>test_index &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dt">y =</span> movielens<span class="op">$</span>rating, <span class="dt">times =</span> <span class="dv">1</span>,</span>
<span id="cb972-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb972-4" aria-hidden="true"></a>                                  <span class="dt">p =</span> <span class="fl">0.2</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)</span>
<span id="cb972-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb972-5" aria-hidden="true"></a>train_set &lt;-<span class="st"> </span>movielens[<span class="op">-</span>test_index,]</span>
<span id="cb972-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb972-6" aria-hidden="true"></a>test_set &lt;-<span class="st"> </span>movielens[test_index,]</span>
<span id="cb972-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb972-7" aria-hidden="true"></a>test_set &lt;-<span class="st"> </span>test_set <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb972-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb972-8" aria-hidden="true"></a><span class="st">     </span><span class="kw">semi_join</span>(train_set, <span class="dt">by =</span> <span class="st">&quot;movieId&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb972-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb972-9" aria-hidden="true"></a><span class="st">     </span><span class="kw">semi_join</span>(train_set, <span class="dt">by =</span> <span class="st">&quot;userId&quot;</span>)</span>
<span id="cb972-10"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb972-10" aria-hidden="true"></a>RMSE &lt;-<span class="st"> </span><span class="cf">function</span>(true_ratings, predicted_ratings){</span>
<span id="cb972-11"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb972-11" aria-hidden="true"></a>     <span class="kw">sqrt</span>(<span class="kw">mean</span>((true_ratings <span class="op">-</span><span class="st"> </span>predicted_ratings)<span class="op">^</span><span class="dv">2</span>))</span>
<span id="cb972-12"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb972-12" aria-hidden="true"></a>}</span>
<span id="cb972-13"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb972-13" aria-hidden="true"></a>mu_hat &lt;-<span class="st"> </span><span class="kw">mean</span>(train_set<span class="op">$</span>rating)</span>
<span id="cb972-14"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb972-14" aria-hidden="true"></a>naive_rmse &lt;-<span class="st"> </span><span class="kw">RMSE</span>(test_set<span class="op">$</span>rating, mu_hat)</span>
<span id="cb972-15"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb972-15" aria-hidden="true"></a>rmse_results &lt;-<span class="st"> </span><span class="kw">data_frame</span>(<span class="dt">method =</span> <span class="st">&quot;Just the average&quot;</span>, <span class="dt">RMSE =</span> naive_rmse)</span>
<span id="cb972-16"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb972-16" aria-hidden="true"></a>mu &lt;-<span class="st"> </span><span class="kw">mean</span>(train_set<span class="op">$</span>rating) </span>
<span id="cb972-17"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb972-17" aria-hidden="true"></a>movie_avgs &lt;-<span class="st"> </span>train_set <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb972-18"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb972-18" aria-hidden="true"></a><span class="st">     </span><span class="kw">group_by</span>(movieId) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb972-19"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb972-19" aria-hidden="true"></a><span class="st">     </span><span class="kw">summarize</span>(<span class="dt">b_i =</span> <span class="kw">mean</span>(rating <span class="op">-</span><span class="st"> </span>mu))</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<div class="sourceCode" id="cb974"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb974-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb974-1" aria-hidden="true"></a>predicted_ratings &lt;-<span class="st"> </span>mu <span class="op">+</span><span class="st"> </span>test_set <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb974-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb974-2" aria-hidden="true"></a><span class="st">     </span><span class="kw">left_join</span>(movie_avgs, <span class="dt">by=</span><span class="st">&#39;movieId&#39;</span>) <span class="op">%&gt;%</span></span>
<span id="cb974-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb974-3" aria-hidden="true"></a><span class="st">     </span>.<span class="op">$</span>b_i</span>
<span id="cb974-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb974-4" aria-hidden="true"></a>model_<span class="dv">1</span>_rmse &lt;-<span class="st"> </span><span class="kw">RMSE</span>(predicted_ratings, test_set<span class="op">$</span>rating)</span>
<span id="cb974-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb974-5" aria-hidden="true"></a>rmse_results &lt;-<span class="st"> </span><span class="kw">bind_rows</span>(rmse_results,</span>
<span id="cb974-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb974-6" aria-hidden="true"></a>                          <span class="kw">data_frame</span>(<span class="dt">method=</span><span class="st">&quot;Movie Effect Model&quot;</span>,</span>
<span id="cb974-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb974-7" aria-hidden="true"></a>                                     <span class="dt">RMSE =</span> model_<span class="dv">1</span>_rmse ))</span>
<span id="cb974-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb974-8" aria-hidden="true"></a>user_avgs &lt;-<span class="st"> </span>test_set <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb974-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb974-9" aria-hidden="true"></a><span class="st">     </span><span class="kw">left_join</span>(movie_avgs, <span class="dt">by=</span><span class="st">&#39;movieId&#39;</span>) <span class="op">%&gt;%</span></span>
<span id="cb974-10"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb974-10" aria-hidden="true"></a><span class="st">     </span><span class="kw">group_by</span>(userId) <span class="op">%&gt;%</span></span>
<span id="cb974-11"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb974-11" aria-hidden="true"></a><span class="st">     </span><span class="kw">summarize</span>(<span class="dt">b_u =</span> <span class="kw">mean</span>(rating <span class="op">-</span><span class="st"> </span>mu <span class="op">-</span><span class="st"> </span>b_i))</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<div class="sourceCode" id="cb976"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb976-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb976-1" aria-hidden="true"></a>predicted_ratings &lt;-<span class="st"> </span>test_set <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb976-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb976-2" aria-hidden="true"></a><span class="st">     </span><span class="kw">left_join</span>(movie_avgs, <span class="dt">by=</span><span class="st">&#39;movieId&#39;</span>) <span class="op">%&gt;%</span></span>
<span id="cb976-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb976-3" aria-hidden="true"></a><span class="st">     </span><span class="kw">left_join</span>(user_avgs, <span class="dt">by=</span><span class="st">&#39;userId&#39;</span>) <span class="op">%&gt;%</span></span>
<span id="cb976-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb976-4" aria-hidden="true"></a><span class="st">     </span><span class="kw">mutate</span>(<span class="dt">pred =</span> mu <span class="op">+</span><span class="st"> </span>b_i <span class="op">+</span><span class="st"> </span>b_u) <span class="op">%&gt;%</span></span>
<span id="cb976-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb976-5" aria-hidden="true"></a><span class="st">     </span>.<span class="op">$</span>pred</span>
<span id="cb976-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb976-6" aria-hidden="true"></a>model_<span class="dv">2</span>_rmse &lt;-<span class="st"> </span><span class="kw">RMSE</span>(predicted_ratings, test_set<span class="op">$</span>rating)</span>
<span id="cb976-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb976-7" aria-hidden="true"></a>rmse_results &lt;-<span class="st"> </span><span class="kw">bind_rows</span>(rmse_results,</span>
<span id="cb976-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb976-8" aria-hidden="true"></a>                          <span class="kw">data_frame</span>(<span class="dt">method=</span><span class="st">&quot;Movie + User Effects Model&quot;</span>,  </span>
<span id="cb976-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb976-9" aria-hidden="true"></a>                                     <span class="dt">RMSE =</span> model_<span class="dv">2</span>_rmse ))</span>
<span id="cb976-10"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb976-10" aria-hidden="true"></a></span>
<span id="cb976-11"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb976-11" aria-hidden="true"></a>test_set <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb976-12"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb976-12" aria-hidden="true"></a><span class="st">     </span><span class="kw">left_join</span>(movie_avgs, <span class="dt">by=</span><span class="st">&#39;movieId&#39;</span>) <span class="op">%&gt;%</span></span>
<span id="cb976-13"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb976-13" aria-hidden="true"></a><span class="st">     </span><span class="kw">mutate</span>(<span class="dt">residual =</span> rating <span class="op">-</span><span class="st"> </span>(mu <span class="op">+</span><span class="st"> </span>b_i)) <span class="op">%&gt;%</span></span>
<span id="cb976-14"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb976-14" aria-hidden="true"></a><span class="st">     </span><span class="kw">arrange</span>(<span class="kw">desc</span>(<span class="kw">abs</span>(residual))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb976-15"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb976-15" aria-hidden="true"></a><span class="st">     </span>dplyr<span class="op">::</span><span class="kw">select</span>(title,  residual) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>) <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>()</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">title</th>
<th align="right">residual</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Day of the Beast, The (Día de la Bestia, El)</td>
<td align="right">4.50</td>
</tr>
<tr class="even">
<td align="left">Horror Express</td>
<td align="right">-4.00</td>
</tr>
<tr class="odd">
<td align="left">No Holds Barred</td>
<td align="right">4.00</td>
</tr>
<tr class="even">
<td align="left">Dear Zachary: A Letter to a Son About His Father</td>
<td align="right">-4.00</td>
</tr>
<tr class="odd">
<td align="left">Faust</td>
<td align="right">-4.00</td>
</tr>
<tr class="even">
<td align="left">Hear My Song</td>
<td align="right">-4.00</td>
</tr>
<tr class="odd">
<td align="left">Confessions of a Shopaholic</td>
<td align="right">-4.00</td>
</tr>
<tr class="even">
<td align="left">Twilight Saga: Breaking Dawn - Part 1, The</td>
<td align="right">-4.00</td>
</tr>
<tr class="odd">
<td align="left">Taxi Driver</td>
<td align="right">-3.81</td>
</tr>
<tr class="even">
<td align="left">Taxi Driver</td>
<td align="right">-3.81</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb977"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb977-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb977-1" aria-hidden="true"></a>movie_titles &lt;-<span class="st"> </span>movielens <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb977-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb977-2" aria-hidden="true"></a><span class="st">     </span>dplyr<span class="op">::</span><span class="kw">select</span>(movieId, title) <span class="op">%&gt;%</span></span>
<span id="cb977-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb977-3" aria-hidden="true"></a><span class="st">     </span><span class="kw">distinct</span>()</span>
<span id="cb977-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb977-4" aria-hidden="true"></a>movie_avgs <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">left_join</span>(movie_titles, <span class="dt">by=</span><span class="st">&quot;movieId&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb977-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb977-5" aria-hidden="true"></a><span class="st">     </span><span class="kw">arrange</span>(<span class="kw">desc</span>(b_i)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb977-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb977-6" aria-hidden="true"></a><span class="st">     </span>dplyr<span class="op">::</span><span class="kw">select</span>(title, b_i) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb977-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb977-7" aria-hidden="true"></a><span class="st">     </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>) <span class="op">%&gt;%</span><span class="st">  </span></span>
<span id="cb977-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb977-8" aria-hidden="true"></a><span class="st">     </span>knitr<span class="op">::</span><span class="kw">kable</span>()</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">title</th>
<th align="right">b_i</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Lamerica</td>
<td align="right">1.46</td>
</tr>
<tr class="even">
<td align="left">Love &amp; Human Remains</td>
<td align="right">1.46</td>
</tr>
<tr class="odd">
<td align="left">Enfer, L’</td>
<td align="right">1.46</td>
</tr>
<tr class="even">
<td align="left">Picture Bride (Bijo photo)</td>
<td align="right">1.46</td>
</tr>
<tr class="odd">
<td align="left">Red Firecracker, Green Firecracker (Pao Da Shuang Deng)</td>
<td align="right">1.46</td>
</tr>
<tr class="even">
<td align="left">Faces</td>
<td align="right">1.46</td>
</tr>
<tr class="odd">
<td align="left">Maya Lin: A Strong Clear Vision</td>
<td align="right">1.46</td>
</tr>
<tr class="even">
<td align="left">Heavy</td>
<td align="right">1.46</td>
</tr>
<tr class="odd">
<td align="left">Gate of Heavenly Peace, The</td>
<td align="right">1.46</td>
</tr>
<tr class="even">
<td align="left">Death in the Garden (Mort en ce jardin, La)</td>
<td align="right">1.46</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb978"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb978-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb978-1" aria-hidden="true"></a>movie_avgs <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">left_join</span>(movie_titles, <span class="dt">by=</span><span class="st">&quot;movieId&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb978-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb978-2" aria-hidden="true"></a><span class="st">     </span><span class="kw">arrange</span>(b_i) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb978-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb978-3" aria-hidden="true"></a><span class="st">     </span>dplyr<span class="op">::</span><span class="kw">select</span>(title, b_i) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb978-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb978-4" aria-hidden="true"></a><span class="st">     </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>) <span class="op">%&gt;%</span><span class="st">  </span></span>
<span id="cb978-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb978-5" aria-hidden="true"></a><span class="st">     </span>knitr<span class="op">::</span><span class="kw">kable</span>()</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">title</th>
<th align="right">b_i</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Santa with Muscles</td>
<td align="right">-3.04</td>
</tr>
<tr class="even">
<td align="left">B<em>A</em>P*S</td>
<td align="right">-3.04</td>
</tr>
<tr class="odd">
<td align="left">3 Ninjas: High Noon On Mega Mountain</td>
<td align="right">-3.04</td>
</tr>
<tr class="even">
<td align="left">Barney’s Great Adventure</td>
<td align="right">-3.04</td>
</tr>
<tr class="odd">
<td align="left">Merry War, A</td>
<td align="right">-3.04</td>
</tr>
<tr class="even">
<td align="left">Day of the Beast, The (Día de la Bestia, El)</td>
<td align="right">-3.04</td>
</tr>
<tr class="odd">
<td align="left">Children of the Corn III</td>
<td align="right">-3.04</td>
</tr>
<tr class="even">
<td align="left">Whiteboyz</td>
<td align="right">-3.04</td>
</tr>
<tr class="odd">
<td align="left">Catfish in Black Bean Sauce</td>
<td align="right">-3.04</td>
</tr>
<tr class="even">
<td align="left">Watcher, The</td>
<td align="right">-3.04</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb979"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb979-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb979-1" aria-hidden="true"></a>train_set <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">count</span>(movieId) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb979-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb979-2" aria-hidden="true"></a><span class="st">     </span><span class="kw">left_join</span>(movie_avgs) <span class="op">%&gt;%</span></span>
<span id="cb979-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb979-3" aria-hidden="true"></a><span class="st">     </span><span class="kw">left_join</span>(movie_titles, <span class="dt">by=</span><span class="st">&quot;movieId&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb979-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb979-4" aria-hidden="true"></a><span class="st">     </span><span class="kw">arrange</span>(<span class="kw">desc</span>(b_i)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb979-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb979-5" aria-hidden="true"></a><span class="st">     </span>dplyr<span class="op">::</span><span class="kw">select</span>(title, b_i, n) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb979-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb979-6" aria-hidden="true"></a><span class="st">     </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb979-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb979-7" aria-hidden="true"></a><span class="st">     </span>knitr<span class="op">::</span><span class="kw">kable</span>()</span></code></pre></div>
<pre><code>## Joining, by = &quot;movieId&quot;</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">title</th>
<th align="right">b_i</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Lamerica</td>
<td align="right">1.46</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Love &amp; Human Remains</td>
<td align="right">1.46</td>
<td align="right">3</td>
</tr>
<tr class="odd">
<td align="left">Enfer, L’</td>
<td align="right">1.46</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Picture Bride (Bijo photo)</td>
<td align="right">1.46</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">Red Firecracker, Green Firecracker (Pao Da Shuang Deng)</td>
<td align="right">1.46</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="left">Faces</td>
<td align="right">1.46</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">Maya Lin: A Strong Clear Vision</td>
<td align="right">1.46</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left">Heavy</td>
<td align="right">1.46</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">Gate of Heavenly Peace, The</td>
<td align="right">1.46</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Death in the Garden (Mort en ce jardin, La)</td>
<td align="right">1.46</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb981"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb981-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb981-1" aria-hidden="true"></a>train_set <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">count</span>(movieId) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb981-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb981-2" aria-hidden="true"></a><span class="st">     </span><span class="kw">left_join</span>(movie_avgs) <span class="op">%&gt;%</span></span>
<span id="cb981-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb981-3" aria-hidden="true"></a><span class="st">     </span><span class="kw">left_join</span>(movie_titles, <span class="dt">by=</span><span class="st">&quot;movieId&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb981-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb981-4" aria-hidden="true"></a><span class="st">     </span><span class="kw">arrange</span>(b_i) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb981-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb981-5" aria-hidden="true"></a><span class="st">     </span>dplyr<span class="op">::</span><span class="kw">select</span>(title, b_i, n) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb981-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb981-6" aria-hidden="true"></a><span class="st">     </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb981-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb981-7" aria-hidden="true"></a><span class="st">     </span>knitr<span class="op">::</span><span class="kw">kable</span>()</span></code></pre></div>
<pre><code>## Joining, by = &quot;movieId&quot;</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">title</th>
<th align="right">b_i</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Santa with Muscles</td>
<td align="right">-3.04</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">B<em>A</em>P*S</td>
<td align="right">-3.04</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">3 Ninjas: High Noon On Mega Mountain</td>
<td align="right">-3.04</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Barney’s Great Adventure</td>
<td align="right">-3.04</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">Merry War, A</td>
<td align="right">-3.04</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Day of the Beast, The (Día de la Bestia, El)</td>
<td align="right">-3.04</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">Children of the Corn III</td>
<td align="right">-3.04</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Whiteboyz</td>
<td align="right">-3.04</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">Catfish in Black Bean Sauce</td>
<td align="right">-3.04</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Watcher, The</td>
<td align="right">-3.04</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb983"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb983-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb983-1" aria-hidden="true"></a>lambda &lt;-<span class="st"> </span><span class="dv">3</span></span>
<span id="cb983-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb983-2" aria-hidden="true"></a>mu &lt;-<span class="st"> </span><span class="kw">mean</span>(train_set<span class="op">$</span>rating)</span>
<span id="cb983-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb983-3" aria-hidden="true"></a>movie_reg_avgs &lt;-<span class="st"> </span>train_set <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb983-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb983-4" aria-hidden="true"></a><span class="st">     </span><span class="kw">group_by</span>(movieId) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb983-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb983-5" aria-hidden="true"></a><span class="st">     </span><span class="kw">summarize</span>(<span class="dt">b_i =</span> <span class="kw">sum</span>(rating <span class="op">-</span><span class="st"> </span>mu)<span class="op">/</span>(<span class="kw">n</span>()<span class="op">+</span>lambda), <span class="dt">n_i =</span> <span class="kw">n</span>()) </span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<div class="sourceCode" id="cb985"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb985-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb985-1" aria-hidden="true"></a><span class="kw">data_frame</span>(<span class="dt">original =</span> movie_avgs<span class="op">$</span>b_i, </span>
<span id="cb985-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb985-2" aria-hidden="true"></a>           <span class="dt">regularlized =</span> movie_reg_avgs<span class="op">$</span>b_i, </span>
<span id="cb985-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb985-3" aria-hidden="true"></a>           <span class="dt">n =</span> movie_reg_avgs<span class="op">$</span>n_i) <span class="op">%&gt;%</span></span>
<span id="cb985-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb985-4" aria-hidden="true"></a><span class="st">     </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(original, regularlized, <span class="dt">size=</span><span class="kw">sqrt</span>(n))) <span class="op">+</span><span class="st"> </span></span>
<span id="cb985-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb985-5" aria-hidden="true"></a><span class="st">     </span><span class="kw">geom_point</span>(<span class="dt">shape=</span><span class="dv">1</span>, <span class="dt">alpha=</span><span class="fl">0.5</span>)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-221-1.png" width="672" /></p>
<div class="sourceCode" id="cb986"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb986-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb986-1" aria-hidden="true"></a>train_set <span class="op">%&gt;%</span></span>
<span id="cb986-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb986-2" aria-hidden="true"></a><span class="st">     </span>dplyr<span class="op">::</span><span class="kw">count</span>(movieId) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb986-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb986-3" aria-hidden="true"></a><span class="st">     </span><span class="kw">left_join</span>(movie_reg_avgs) <span class="op">%&gt;%</span></span>
<span id="cb986-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb986-4" aria-hidden="true"></a><span class="st">     </span><span class="kw">left_join</span>(movie_titles, <span class="dt">by=</span><span class="st">&quot;movieId&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb986-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb986-5" aria-hidden="true"></a><span class="st">     </span><span class="kw">arrange</span>(<span class="kw">desc</span>(b_i)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb986-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb986-6" aria-hidden="true"></a><span class="st">     </span>dplyr<span class="op">::</span><span class="kw">select</span>(title, b_i, n) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb986-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb986-7" aria-hidden="true"></a><span class="st">     </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb986-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb986-8" aria-hidden="true"></a><span class="st">     </span>knitr<span class="op">::</span><span class="kw">kable</span>()</span></code></pre></div>
<pre><code>## Joining, by = &quot;movieId&quot;</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">title</th>
<th align="right">b_i</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">All About Eve</td>
<td align="right">0.927</td>
<td align="right">26</td>
</tr>
<tr class="even">
<td align="left">Shawshank Redemption, The</td>
<td align="right">0.921</td>
<td align="right">240</td>
</tr>
<tr class="odd">
<td align="left">Godfather, The</td>
<td align="right">0.897</td>
<td align="right">153</td>
</tr>
<tr class="even">
<td align="left">Godfather: Part II, The</td>
<td align="right">0.871</td>
<td align="right">100</td>
</tr>
<tr class="odd">
<td align="left">Maltese Falcon, The</td>
<td align="right">0.860</td>
<td align="right">47</td>
</tr>
<tr class="even">
<td align="left">Best Years of Our Lives, The</td>
<td align="right">0.859</td>
<td align="right">11</td>
</tr>
<tr class="odd">
<td align="left">On the Waterfront</td>
<td align="right">0.847</td>
<td align="right">23</td>
</tr>
<tr class="even">
<td align="left">Face in the Crowd, A</td>
<td align="right">0.833</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td align="left">African Queen, The</td>
<td align="right">0.832</td>
<td align="right">36</td>
</tr>
<tr class="even">
<td align="left">All Quiet on the Western Front</td>
<td align="right">0.824</td>
<td align="right">11</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb988"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb988-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb988-1" aria-hidden="true"></a>train_set <span class="op">%&gt;%</span></span>
<span id="cb988-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb988-2" aria-hidden="true"></a><span class="st">     </span>dplyr<span class="op">::</span><span class="kw">count</span>(movieId) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb988-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb988-3" aria-hidden="true"></a><span class="st">     </span><span class="kw">left_join</span>(movie_reg_avgs) <span class="op">%&gt;%</span></span>
<span id="cb988-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb988-4" aria-hidden="true"></a><span class="st">     </span><span class="kw">left_join</span>(movie_titles, <span class="dt">by=</span><span class="st">&quot;movieId&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb988-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb988-5" aria-hidden="true"></a><span class="st">     </span><span class="kw">arrange</span>(b_i) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb988-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb988-6" aria-hidden="true"></a><span class="st">     </span>dplyr<span class="op">::</span><span class="kw">select</span>(title, b_i, n) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb988-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb988-7" aria-hidden="true"></a><span class="st">     </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb988-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb988-8" aria-hidden="true"></a><span class="st">     </span>knitr<span class="op">::</span><span class="kw">kable</span>()</span></code></pre></div>
<pre><code>## Joining, by = &quot;movieId&quot;</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">title</th>
<th align="right">b_i</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Battlefield Earth</td>
<td align="right">-2.06</td>
<td align="right">14</td>
</tr>
<tr class="even">
<td align="left">Joe’s Apartment</td>
<td align="right">-1.78</td>
<td align="right">7</td>
</tr>
<tr class="odd">
<td align="left">Speed 2: Cruise Control</td>
<td align="right">-1.69</td>
<td align="right">20</td>
</tr>
<tr class="even">
<td align="left">Super Mario Bros.</td>
<td align="right">-1.60</td>
<td align="right">13</td>
</tr>
<tr class="odd">
<td align="left">Police Academy 6: City Under Siege</td>
<td align="right">-1.57</td>
<td align="right">10</td>
</tr>
<tr class="even">
<td align="left">After Earth</td>
<td align="right">-1.52</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td align="left">Disaster Movie</td>
<td align="right">-1.52</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="left">Little Nicky</td>
<td align="right">-1.51</td>
<td align="right">17</td>
</tr>
<tr class="odd">
<td align="left">Cats &amp; Dogs</td>
<td align="right">-1.47</td>
<td align="right">6</td>
</tr>
<tr class="even">
<td align="left">Blade: Trinity</td>
<td align="right">-1.46</td>
<td align="right">11</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb990"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb990-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb990-1" aria-hidden="true"></a>predicted_ratings &lt;-<span class="st"> </span>test_set <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb990-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb990-2" aria-hidden="true"></a><span class="st">     </span><span class="kw">left_join</span>(movie_reg_avgs, <span class="dt">by=</span><span class="st">&#39;movieId&#39;</span>) <span class="op">%&gt;%</span></span>
<span id="cb990-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb990-3" aria-hidden="true"></a><span class="st">     </span><span class="kw">mutate</span>(<span class="dt">pred =</span> mu <span class="op">+</span><span class="st"> </span>b_i) <span class="op">%&gt;%</span></span>
<span id="cb990-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb990-4" aria-hidden="true"></a><span class="st">     </span>.<span class="op">$</span>pred</span>
<span id="cb990-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb990-5" aria-hidden="true"></a></span>
<span id="cb990-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb990-6" aria-hidden="true"></a>model_<span class="dv">3</span>_rmse &lt;-<span class="st"> </span><span class="kw">RMSE</span>(predicted_ratings, test_set<span class="op">$</span>rating)</span>
<span id="cb990-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb990-7" aria-hidden="true"></a>rmse_results &lt;-<span class="st"> </span><span class="kw">bind_rows</span>(rmse_results,</span>
<span id="cb990-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb990-8" aria-hidden="true"></a>                          <span class="kw">data_frame</span>(<span class="dt">method=</span><span class="st">&quot;Regularized Movie Effect Model&quot;</span>,  </span>
<span id="cb990-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb990-9" aria-hidden="true"></a>                                     <span class="dt">RMSE =</span> model_<span class="dv">3</span>_rmse ))</span>
<span id="cb990-10"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb990-10" aria-hidden="true"></a>rmse_results <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>()</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">method</th>
<th align="right">RMSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Just the average</td>
<td align="right">1.048</td>
</tr>
<tr class="even">
<td align="left">Movie Effect Model</td>
<td align="right">0.986</td>
</tr>
<tr class="odd">
<td align="left">Movie + User Effects Model</td>
<td align="right">0.885</td>
</tr>
<tr class="even">
<td align="left">Regularized Movie Effect Model</td>
<td align="right">0.965</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb991"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb991-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb991-1" aria-hidden="true"></a>lambdas &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="fl">0.25</span>)</span>
<span id="cb991-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb991-2" aria-hidden="true"></a>mu &lt;-<span class="st"> </span><span class="kw">mean</span>(train_set<span class="op">$</span>rating)</span>
<span id="cb991-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb991-3" aria-hidden="true"></a>just_the_sum &lt;-<span class="st"> </span>train_set <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb991-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb991-4" aria-hidden="true"></a><span class="st">     </span><span class="kw">group_by</span>(movieId) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb991-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb991-5" aria-hidden="true"></a><span class="st">     </span><span class="kw">summarize</span>(<span class="dt">s =</span> <span class="kw">sum</span>(rating <span class="op">-</span><span class="st"> </span>mu), <span class="dt">n_i =</span> <span class="kw">n</span>())</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<div class="sourceCode" id="cb993"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb993-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb993-1" aria-hidden="true"></a>rmses &lt;-<span class="st"> </span><span class="kw">sapply</span>(lambdas, <span class="cf">function</span>(l){</span>
<span id="cb993-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb993-2" aria-hidden="true"></a>     predicted_ratings &lt;-<span class="st"> </span>test_set <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb993-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb993-3" aria-hidden="true"></a><span class="st">          </span><span class="kw">left_join</span>(just_the_sum, <span class="dt">by=</span><span class="st">&#39;movieId&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb993-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb993-4" aria-hidden="true"></a><span class="st">          </span><span class="kw">mutate</span>(<span class="dt">b_i =</span> s<span class="op">/</span>(n_i<span class="op">+</span>l)) <span class="op">%&gt;%</span></span>
<span id="cb993-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb993-5" aria-hidden="true"></a><span class="st">          </span><span class="kw">mutate</span>(<span class="dt">pred =</span> mu <span class="op">+</span><span class="st"> </span>b_i) <span class="op">%&gt;%</span></span>
<span id="cb993-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb993-6" aria-hidden="true"></a><span class="st">          </span>.<span class="op">$</span>pred</span>
<span id="cb993-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb993-7" aria-hidden="true"></a>     <span class="kw">return</span>(<span class="kw">RMSE</span>(predicted_ratings, test_set<span class="op">$</span>rating))</span>
<span id="cb993-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb993-8" aria-hidden="true"></a>})</span>
<span id="cb993-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb993-9" aria-hidden="true"></a><span class="kw">qplot</span>(lambdas, rmses)  </span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-221-2.png" width="672" /></p>
<div class="sourceCode" id="cb994"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb994-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb994-1" aria-hidden="true"></a>lambdas[<span class="kw">which.min</span>(rmses)]</span></code></pre></div>
<pre><code>## [1] 3</code></pre>
<div class="sourceCode" id="cb996"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb996-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb996-1" aria-hidden="true"></a>lambdas &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="fl">0.25</span>)</span>
<span id="cb996-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb996-2" aria-hidden="true"></a>rmses &lt;-<span class="st"> </span><span class="kw">sapply</span>(lambdas, <span class="cf">function</span>(l){</span>
<span id="cb996-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb996-3" aria-hidden="true"></a>     mu &lt;-<span class="st"> </span><span class="kw">mean</span>(train_set<span class="op">$</span>rating)</span>
<span id="cb996-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb996-4" aria-hidden="true"></a>     b_i &lt;-<span class="st"> </span>train_set <span class="op">%&gt;%</span></span>
<span id="cb996-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb996-5" aria-hidden="true"></a><span class="st">          </span><span class="kw">group_by</span>(movieId) <span class="op">%&gt;%</span></span>
<span id="cb996-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb996-6" aria-hidden="true"></a><span class="st">          </span><span class="kw">summarize</span>(<span class="dt">b_i =</span> <span class="kw">sum</span>(rating <span class="op">-</span><span class="st"> </span>mu)<span class="op">/</span>(<span class="kw">n</span>()<span class="op">+</span>l))</span>
<span id="cb996-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb996-7" aria-hidden="true"></a>     b_u &lt;-<span class="st"> </span>train_set <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb996-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb996-8" aria-hidden="true"></a><span class="st">          </span><span class="kw">left_join</span>(b_i, <span class="dt">by=</span><span class="st">&quot;movieId&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb996-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb996-9" aria-hidden="true"></a><span class="st">          </span><span class="kw">group_by</span>(userId) <span class="op">%&gt;%</span></span>
<span id="cb996-10"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb996-10" aria-hidden="true"></a><span class="st">          </span><span class="kw">summarize</span>(<span class="dt">b_u =</span> <span class="kw">sum</span>(rating <span class="op">-</span><span class="st"> </span>b_i <span class="op">-</span><span class="st"> </span>mu)<span class="op">/</span>(<span class="kw">n</span>()<span class="op">+</span>l))</span>
<span id="cb996-11"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb996-11" aria-hidden="true"></a>     predicted_ratings &lt;-<span class="st"> </span></span>
<span id="cb996-12"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb996-12" aria-hidden="true"></a><span class="st">          </span>test_set <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb996-13"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb996-13" aria-hidden="true"></a><span class="st">          </span><span class="kw">left_join</span>(b_i, <span class="dt">by =</span> <span class="st">&quot;movieId&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb996-14"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb996-14" aria-hidden="true"></a><span class="st">          </span><span class="kw">left_join</span>(b_u, <span class="dt">by =</span> <span class="st">&quot;userId&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb996-15"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb996-15" aria-hidden="true"></a><span class="st">          </span><span class="kw">mutate</span>(<span class="dt">pred =</span> mu <span class="op">+</span><span class="st"> </span>b_i <span class="op">+</span><span class="st"> </span>b_u) <span class="op">%&gt;%</span></span>
<span id="cb996-16"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb996-16" aria-hidden="true"></a><span class="st">          </span>.<span class="op">$</span>pred</span>
<span id="cb996-17"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb996-17" aria-hidden="true"></a>     <span class="kw">return</span>(<span class="kw">RMSE</span>(predicted_ratings, test_set<span class="op">$</span>rating))</span>
<span id="cb996-18"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb996-18" aria-hidden="true"></a>})</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)
## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<div class="sourceCode" id="cb998"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb998-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb998-1" aria-hidden="true"></a><span class="kw">qplot</span>(lambdas, rmses)  </span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-221-3.png" width="672" /></p>
<div class="sourceCode" id="cb999"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb999-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb999-1" aria-hidden="true"></a>lambda &lt;-<span class="st"> </span>lambdas[<span class="kw">which.min</span>(rmses)]</span>
<span id="cb999-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb999-2" aria-hidden="true"></a>lambda</span></code></pre></div>
<pre><code>## [1] 3.75</code></pre>
<div class="sourceCode" id="cb1001"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1001-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1001-1" aria-hidden="true"></a>rmse_results &lt;-<span class="st"> </span><span class="kw">bind_rows</span>(rmse_results,</span>
<span id="cb1001-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1001-2" aria-hidden="true"></a>                          <span class="kw">data_frame</span>(<span class="dt">method=</span><span class="st">&quot;Regularized Movie + User Effect Model&quot;</span>,  </span>
<span id="cb1001-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1001-3" aria-hidden="true"></a>                                     <span class="dt">RMSE =</span> <span class="kw">min</span>(rmses)))</span>
<span id="cb1001-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1001-4" aria-hidden="true"></a>rmse_results <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>()</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">method</th>
<th align="right">RMSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Just the average</td>
<td align="right">1.048</td>
</tr>
<tr class="even">
<td align="left">Movie Effect Model</td>
<td align="right">0.986</td>
</tr>
<tr class="odd">
<td align="left">Movie + User Effects Model</td>
<td align="right">0.885</td>
</tr>
<tr class="even">
<td align="left">Regularized Movie Effect Model</td>
<td align="right">0.965</td>
</tr>
<tr class="odd">
<td align="left">Regularized Movie + User Effect Model</td>
<td align="right">0.881</td>
</tr>
</tbody>
</table>
</div>
<div id="comprehension-check---regularization" class="section level2" number="7.11">
<h2><span class="header-section-number">7.11</span> Comprehension Check - Regularization</h2>
<p>The exercises in Q1-Q8 work with a simulated dataset for 1000 schools. This pre-exercise setup walks you through the code needed to simulate the dataset.</p>
<p>If you have not done so already since the Titanic Exercises, please restart R or reset the number of digits that are printed with <code>options(digits=7)</code>.</p>
<p>An education expert is advocating for smaller schools. The expert bases this recommendation on the fact that among the best performing schools, many are small schools. Let’s simulate a dataset for 1000 schools. First, let’s simulate the number of students in each school, using the following code:</p>
<div class="sourceCode" id="cb1002"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1002-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1002-1" aria-hidden="true"></a><span class="co"># set.seed(1986) # if using R 3.5 or earlier</span></span>
<span id="cb1002-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1002-2" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">1986</span>, <span class="dt">sample.kind=</span><span class="st">&quot;Rounding&quot;</span>) <span class="co"># if using R 3.6 or later</span></span></code></pre></div>
<pre><code>## Warning in set.seed(1986, sample.kind = &quot;Rounding&quot;): non-uniform &#39;Rounding&#39; sampler used</code></pre>
<div class="sourceCode" id="cb1004"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1004-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1004-1" aria-hidden="true"></a>n &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="dv">2</span><span class="op">^</span><span class="kw">rnorm</span>(<span class="dv">1000</span>, <span class="dv">8</span>, <span class="dv">1</span>))</span></code></pre></div>
<p>Now let’s assign a <strong>true</strong> quality for each school that is completely independent from size. This is the parameter we want to estimate in our analysis. The true quality can be assigned using the following code:</p>
<div class="sourceCode" id="cb1005"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1005-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1005-1" aria-hidden="true"></a><span class="co"># set.seed(1) # if using R 3.5 or earlier</span></span>
<span id="cb1005-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1005-2" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">1</span>, <span class="dt">sample.kind=</span><span class="st">&quot;Rounding&quot;</span>) <span class="co"># if using R 3.6 or later</span></span></code></pre></div>
<pre><code>## Warning in set.seed(1, sample.kind = &quot;Rounding&quot;): non-uniform &#39;Rounding&#39; sampler used</code></pre>
<div class="sourceCode" id="cb1007"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1007-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1007-1" aria-hidden="true"></a>mu &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="dv">80</span> <span class="op">+</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span><span class="kw">rt</span>(<span class="dv">1000</span>, <span class="dv">5</span>))</span>
<span id="cb1007-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1007-2" aria-hidden="true"></a><span class="kw">range</span>(mu)</span></code></pre></div>
<pre><code>## [1] 67 94</code></pre>
<div class="sourceCode" id="cb1009"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1009-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1009-1" aria-hidden="true"></a>schools &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">id =</span> <span class="kw">paste</span>(<span class="st">&quot;PS&quot;</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>),</span>
<span id="cb1009-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1009-2" aria-hidden="true"></a>                      <span class="dt">size =</span> n,</span>
<span id="cb1009-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1009-3" aria-hidden="true"></a>                      <span class="dt">quality =</span> mu,</span>
<span id="cb1009-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1009-4" aria-hidden="true"></a>                      <span class="dt">rank =</span> <span class="kw">rank</span>(<span class="op">-</span>mu))</span></code></pre></div>
<p>We can see the top 10 schools using this code:</p>
<div class="sourceCode" id="cb1010"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1010-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1010-1" aria-hidden="true"></a>schools <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">top_n</span>(<span class="dv">10</span>, quality) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(quality))</span></code></pre></div>
<pre><code>##        id size quality rank
## 1  PS 191 1036      94  1.0
## 2  PS 567  121      93  2.0
## 3   PS 95  235      91  3.0
## 4  PS 430   61      90  4.0
## 5  PS 343   78      89  5.0
## 6  PS 981  293      88  6.0
## 7  PS 558  196      87  7.0
## 8   PS 79  105      86 13.5
## 9  PS 113  653      86 13.5
## 10 PS 163  300      86 13.5
## 11 PS 266 2369      86 13.5
## 12 PS 400  550      86 13.5
## 13 PS 451  217      86 13.5
## 14 PS 477  341      86 13.5
## 15 PS 484  967      86 13.5
## 16 PS 561  723      86 13.5
## 17 PS 563  828      86 13.5
## 18 PS 865  586      86 13.5
## 19 PS 963  208      86 13.5</code></pre>
<p>Now let’s have the students in the school take a test. There is random variability in test taking, so we will simulate the test scores as normally distributed with the average determined by the school quality with a standard deviation of 30 percentage points. This code will simulate the test scores:</p>
<div class="sourceCode" id="cb1012"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1012-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1012-1" aria-hidden="true"></a><span class="co"># set.seed(1) # if using R 3.5 or earlier</span></span>
<span id="cb1012-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1012-2" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">1</span>, <span class="dt">sample.kind=</span><span class="st">&quot;Rounding&quot;</span>) <span class="co"># if using R 3.6 or later</span></span></code></pre></div>
<pre><code>## Warning in set.seed(1, sample.kind = &quot;Rounding&quot;): non-uniform &#39;Rounding&#39; sampler used</code></pre>
<div class="sourceCode" id="cb1014"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1014-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1014-1" aria-hidden="true"></a>mu &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="dv">80</span> <span class="op">+</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span><span class="kw">rt</span>(<span class="dv">1000</span>, <span class="dv">5</span>))</span>
<span id="cb1014-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1014-2" aria-hidden="true"></a></span>
<span id="cb1014-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1014-3" aria-hidden="true"></a>scores &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(schools), <span class="cf">function</span>(i){</span>
<span id="cb1014-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1014-4" aria-hidden="true"></a>       scores &lt;-<span class="st"> </span><span class="kw">rnorm</span>(schools<span class="op">$</span>size[i], schools<span class="op">$</span>quality[i], <span class="dv">30</span>)</span>
<span id="cb1014-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1014-5" aria-hidden="true"></a>       scores</span>
<span id="cb1014-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1014-6" aria-hidden="true"></a>})</span>
<span id="cb1014-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1014-7" aria-hidden="true"></a>schools &lt;-<span class="st"> </span>schools <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">score =</span> <span class="kw">sapply</span>(scores, mean))</span></code></pre></div>
<ol style="list-style-type: decimal">
<li>What are the top schools based on the average score? Show just the ID, size, and the average score.</li>
</ol>
<p>Report the ID of the top school and average score of the 10th school.</p>
<p>What is the ID of the top school?</p>
<p>What is the average score of the 10th school (after sorting from highest to lowest average score)?</p>
<div class="sourceCode" id="cb1015"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1015-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1015-1" aria-hidden="true"></a>schools <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">top_n</span>(<span class="dv">10</span>, score) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(score)) <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">select</span>(id, size, score)</span></code></pre></div>
<pre><code>##        id size score
## 1  PS 567  121  95.8
## 2  PS 191 1036  93.5
## 3  PS 330  162  91.0
## 4  PS 701   83  90.5
## 5  PS 591  213  89.7
## 6  PS 205  172  89.3
## 7  PS 574  199  89.2
## 8  PS 963  208  89.0
## 9  PS 430   61  88.7
## 10 PS 756  245  88.0</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Compare the median school size to the median school size of the top 10 schools based on the score.</li>
</ol>
<p>What is the median school size overall?</p>
<p>What is the median school size of the of the top 10 schools based on the score?</p>
<div class="sourceCode" id="cb1017"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1017-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1017-1" aria-hidden="true"></a><span class="kw">median</span>(schools<span class="op">$</span>size)</span></code></pre></div>
<pre><code>## [1] 261</code></pre>
<div class="sourceCode" id="cb1019"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1019-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1019-1" aria-hidden="true"></a>schools <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">top_n</span>(<span class="dv">10</span>, score) <span class="op">%&gt;%</span><span class="st"> </span>.<span class="op">$</span>size <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">median</span>()</span></code></pre></div>
<pre><code>## [1] 186</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>According to this analysis, it appears that small schools produce better test scores than large schools. Four out of the top 10 schools have 100 or fewer students. But how can this be? We constructed the simulation so that quality and size were independent. Repeat the exercise for the worst 10 schools.</li>
</ol>
<p>What is the median school size of the bottom 10 schools based on the score?</p>
<div class="sourceCode" id="cb1021"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1021-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1021-1" aria-hidden="true"></a><span class="kw">median</span>(schools<span class="op">$</span>size)</span></code></pre></div>
<pre><code>## [1] 261</code></pre>
<div class="sourceCode" id="cb1023"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1023-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1023-1" aria-hidden="true"></a>schools <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">top_n</span>(<span class="op">-</span><span class="dv">10</span>, score) <span class="op">%&gt;%</span><span class="st"> </span>.<span class="op">$</span>size <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">median</span>()</span></code></pre></div>
<pre><code>## [1] 219</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>From this analysis, we see that the worst schools are also small. Plot the average score versus school size to see what’s going on. Highlight the top 10 schools based on the <strong>true</strong> quality.</li>
</ol>
<p>What do you observe?</p>
<div class="sourceCode" id="cb1025"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1025-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1025-1" aria-hidden="true"></a>schools <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(size, score)) <span class="op">+</span></span>
<span id="cb1025-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1025-2" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span></span>
<span id="cb1025-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1025-3" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">data =</span> <span class="kw">filter</span>(schools, rank<span class="op">&lt;=</span><span class="dv">10</span>), <span class="dt">col =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-229-1.png" width="672" /></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
A. There is no difference in the standard error of the score based on school size; there must be an error in how we generated our data.</li>
<li><input type="checkbox" disabled="" checked="" />
B. The standard error of the score has larger variability when the school is smaller, which is why both the best and the worst schools are more likely to be small.</li>
<li><input type="checkbox" disabled="" />
C. The standard error of the score has smaller variability when the school is smaller, which is why both the best and the worst schools are more likely to be small.</li>
<li><input type="checkbox" disabled="" />
D. The standard error of the score has larger variability when the school is very small or very large, which is why both the best and the worst schools are more likely to be small.</li>
<li><input type="checkbox" disabled="" />
E. The standard error of the score has smaller variability when the school is very small or very large, which is why both the best and the worst schools are more likely to be small.</li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li>Let’s use regularization to pick the best schools. Remember regularization <strong>shrinks</strong> deviations from the average towards 0. To apply regularization here, we first need to define the overall average for all schools, using the following code:</li>
</ol>
<div class="sourceCode" id="cb1026"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1026-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1026-1" aria-hidden="true"></a>overall &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">sapply</span>(scores, mean))</span></code></pre></div>
<p>Then, we need to define, for each school, how it deviates from that average.</p>
<p>Write code that estimates the score above the average for each school but dividing by <span class="math inline">\(n + \alpha\)</span> instead of <span class="math inline">\(n\)</span>, with <span class="math inline">\(n\)</span> the school size and <span class="math inline">\(\alpha\)</span> a regularization parameter. Try <span class="math inline">\(\alpha = 25\)</span>.</p>
<p>What is the ID of the top school with regularization?</p>
<p>What is the regularized score of the 10th school?</p>
<div class="sourceCode" id="cb1027"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1027-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1027-1" aria-hidden="true"></a>alpha &lt;-<span class="st"> </span><span class="dv">25</span></span>
<span id="cb1027-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1027-2" aria-hidden="true"></a>score_reg &lt;-<span class="st"> </span><span class="kw">sapply</span>(scores, <span class="cf">function</span>(x)  overall <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(x<span class="op">-</span>overall)<span class="op">/</span>(<span class="kw">length</span>(x)<span class="op">+</span>alpha))</span>
<span id="cb1027-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1027-3" aria-hidden="true"></a>schools <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">score_reg =</span> score_reg) <span class="op">%&gt;%</span></span>
<span id="cb1027-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1027-4" aria-hidden="true"></a><span class="st">    </span><span class="kw">top_n</span>(<span class="dv">10</span>, score_reg) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(score_reg))</span></code></pre></div>
<pre><code>##        id size quality  rank score score_reg
## 1  PS 191 1036      94   1.0  93.5      93.2
## 2  PS 567  121      93   2.0  95.8      93.1
## 3  PS 330  162      84  53.5  91.0      89.5
## 4  PS 591  213      83 104.5  89.7      88.7
## 5  PS 574  199      84  53.5  89.2      88.2
## 6  PS 205  172      85  28.5  89.3      88.1
## 7  PS 701   83      83 104.5  90.5      88.1
## 8  PS 963  208      86  13.5  89.0      88.0
## 9  PS 756  245      83 104.5  88.0      87.2
## 10 PS 561  723      86  13.5  87.4      87.2</code></pre>
<ol start="6" style="list-style-type: decimal">
<li>Notice that this improves things a bit. The number of small schools that are not highly ranked is now lower. Is there a better <span class="math inline">\(\alpha\)</span>? Using values of <span class="math inline">\(\alpha\)</span> from 10 to 250, find the <span class="math inline">\(\alpha\)</span> that minimizes the RMSE.</li>
</ol>
<p><span class="math inline">\(\text{RMSE} = \sqrt{\frac{1}{1000} \sum_{i=1}^{1000} (\mbox{quality} - \mbox{estimate})^2}\)</span></p>
<p>What value of <span class="math inline">\(\alpha\)</span> gives the minimum RMSE?</p>
<div class="sourceCode" id="cb1029"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1029-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1029-1" aria-hidden="true"></a>alphas &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">10</span>,<span class="dv">250</span>)</span>
<span id="cb1029-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1029-2" aria-hidden="true"></a>rmse &lt;-<span class="st"> </span><span class="kw">sapply</span>(alphas, <span class="cf">function</span>(alpha){</span>
<span id="cb1029-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1029-3" aria-hidden="true"></a>    score_reg &lt;-<span class="st"> </span><span class="kw">sapply</span>(scores, <span class="cf">function</span>(x) overall<span class="op">+</span><span class="kw">sum</span>(x<span class="op">-</span>overall)<span class="op">/</span>(<span class="kw">length</span>(x)<span class="op">+</span>alpha))</span>
<span id="cb1029-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1029-4" aria-hidden="true"></a>    <span class="kw">sqrt</span>(<span class="kw">mean</span>((score_reg <span class="op">-</span><span class="st"> </span>schools<span class="op">$</span>quality)<span class="op">^</span><span class="dv">2</span>))</span>
<span id="cb1029-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1029-5" aria-hidden="true"></a>})</span>
<span id="cb1029-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1029-6" aria-hidden="true"></a><span class="kw">plot</span>(alphas, rmse)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-232-1.png" width="672" /></p>
<div class="sourceCode" id="cb1030"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1030-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1030-1" aria-hidden="true"></a>alphas[<span class="kw">which.min</span>(rmse)]</span></code></pre></div>
<pre><code>## [1] 135</code></pre>
<ol start="7" style="list-style-type: decimal">
<li>Rank the schools based on the average obtained with the best <span class="math inline">\(\alpha\)</span> from Q6. Note that no small school is incorrectly included.</li>
</ol>
<p>What is the ID of the top school now?</p>
<p>What is the regularized average score of the 10th school now?</p>
<div class="sourceCode" id="cb1032"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1032-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1032-1" aria-hidden="true"></a>alpha &lt;-<span class="st"> </span>alphas[<span class="kw">which.min</span>(rmse)]  </span>
<span id="cb1032-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1032-2" aria-hidden="true"></a>score_reg &lt;-<span class="st"> </span><span class="kw">sapply</span>(scores, <span class="cf">function</span>(x)</span>
<span id="cb1032-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1032-3" aria-hidden="true"></a>    overall<span class="op">+</span><span class="kw">sum</span>(x<span class="op">-</span>overall)<span class="op">/</span>(<span class="kw">length</span>(x)<span class="op">+</span>alpha))</span>
<span id="cb1032-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1032-4" aria-hidden="true"></a>schools <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">score_reg =</span> score_reg) <span class="op">%&gt;%</span></span>
<span id="cb1032-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1032-5" aria-hidden="true"></a><span class="st">    </span><span class="kw">top_n</span>(<span class="dv">10</span>, score_reg) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(score_reg))</span></code></pre></div>
<pre><code>##        id size quality  rank score score_reg
## 1  PS 191 1036      94   1.0  93.5      92.0
## 2  PS 567  121      93   2.0  95.8      87.5
## 3  PS 561  723      86  13.5  87.4      86.2
## 4  PS 330  162      84  53.5  91.0      86.0
## 5  PS 591  213      83 104.5  89.7      86.0
## 6  PS 400  550      86  13.5  87.4      85.9
## 7  PS 865  586      86  13.5  87.2      85.8
## 8  PS 266 2369      86  13.5  86.0      85.7
## 9  PS 563  828      86  13.5  86.5      85.5
## 10 PS 574  199      84  53.5  89.2      85.5</code></pre>
<ol start="8" style="list-style-type: decimal">
<li>A common mistake made when using regularization is shrinking values towards 0 that are not centered around 0. For example, if we don’t subtract the overall average before shrinking, we actually obtain a very similar result. Confirm this by re-running the code from the exercise in Q6 but without removing the overall mean.</li>
</ol>
<p>What value of <span class="math inline">\(\alpha\)</span> gives the minimum RMSE here?</p>
<div class="sourceCode" id="cb1034"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1034-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1034-1" aria-hidden="true"></a>alphas &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">10</span>,<span class="dv">250</span>)</span>
<span id="cb1034-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1034-2" aria-hidden="true"></a>rmse &lt;-<span class="st"> </span><span class="kw">sapply</span>(alphas, <span class="cf">function</span>(alpha){</span>
<span id="cb1034-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1034-3" aria-hidden="true"></a>    score_reg &lt;-<span class="st"> </span><span class="kw">sapply</span>(scores, <span class="cf">function</span>(x) <span class="kw">sum</span>(x)<span class="op">/</span>(<span class="kw">length</span>(x)<span class="op">+</span>alpha))</span>
<span id="cb1034-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1034-4" aria-hidden="true"></a>    <span class="kw">sqrt</span>(<span class="kw">mean</span>((score_reg <span class="op">-</span><span class="st"> </span>schools<span class="op">$</span>quality)<span class="op">^</span><span class="dv">2</span>))</span>
<span id="cb1034-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1034-5" aria-hidden="true"></a>})</span>
<span id="cb1034-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1034-6" aria-hidden="true"></a><span class="kw">plot</span>(alphas, rmse)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-234-1.png" width="672" /></p>
<div class="sourceCode" id="cb1035"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1035-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1035-1" aria-hidden="true"></a>alphas[<span class="kw">which.min</span>(rmse)]</span></code></pre></div>
<pre><code>## [1] 10</code></pre>
</div>
<div id="matrix-factorization" class="section level2" number="7.12">
<h2><span class="header-section-number">7.12</span> Matrix Factorization</h2>
<p>There is a link to the relevant section of the textbook: <a href="https://rafalab.github.io/dsbook/large-datasets.html#matrix-factorization" target="_blank">Matrix factorization</a></p>
<p><strong>Key points</strong></p>
<ul>
<li>Our earlier models fail to account for an important source of variation related to the fact that groups of movies and groups of users have similar rating patterns. We can observe these patterns by studying the residuals and <strong>converting our data into a matrix where each user gets a row and each movie gets a column</strong>:</li>
</ul>
<p><span class="math inline">\(r_{u, i} = y_{u, i} - \hat{b}_i - \hat{b}_u,\)</span></p>
<p>where <span class="math inline">\(y_{u, i}\)</span> is the entry in row <span class="math inline">\(u\)</span> and column <span class="math inline">\(i\)</span>.</p>
<ul>
<li>We can <strong>factorize the matrix of residuals <span class="math inline">\(r\)</span></strong> into a vector <span class="math inline">\(p\)</span> and vector <span class="math inline">\(q\)</span>, <span class="math inline">\(r_{u, i} \approx p_u q_i\)</span>, allowing us to explain more of the variance using a model like this:</li>
</ul>
<p><span class="math inline">\(Y_{u, i} = \mu + b_i + b_u + p_u q_i + \epsilon_{i, j}\)</span></p>
<ul>
<li>Because our example is more complicated, we can use <strong>two factors to explain the structure and two sets of coefficients to describe users</strong>:</li>
</ul>
<p><span class="math inline">\(Y_{u, i} = \mu + b_i + b_u + p_{u,1} q_{1,i} + p_{u,2} q_{2,i} + \epsilon_{i, j}\)</span></p>
<ul>
<li>To estimate factors using our data instead of constructing them ourselves, we can use <strong>principal component analysis (PCA) or singular value decomposition (SVD)</strong>.</li>
</ul>
<p><em>Code</em></p>
<div class="sourceCode" id="cb1037"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1037-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1037-1" aria-hidden="true"></a>train_small &lt;-<span class="st"> </span>movielens <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1037-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1037-2" aria-hidden="true"></a><span class="st">     </span><span class="kw">group_by</span>(movieId) <span class="op">%&gt;%</span></span>
<span id="cb1037-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1037-3" aria-hidden="true"></a><span class="st">     </span><span class="kw">filter</span>(<span class="kw">n</span>() <span class="op">&gt;=</span><span class="st"> </span><span class="dv">50</span> <span class="op">|</span><span class="st"> </span>movieId <span class="op">==</span><span class="st"> </span><span class="dv">3252</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="co">#3252 is Scent of a Woman used in example</span></span>
<span id="cb1037-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1037-4" aria-hidden="true"></a><span class="st">     </span><span class="kw">group_by</span>(userId) <span class="op">%&gt;%</span></span>
<span id="cb1037-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1037-5" aria-hidden="true"></a><span class="st">     </span><span class="kw">filter</span>(<span class="kw">n</span>() <span class="op">&gt;=</span><span class="st"> </span><span class="dv">50</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ungroup</span>()</span>
<span id="cb1037-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1037-6" aria-hidden="true"></a></span>
<span id="cb1037-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1037-7" aria-hidden="true"></a>y &lt;-<span class="st"> </span>train_small <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1037-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1037-8" aria-hidden="true"></a><span class="st">     </span>dplyr<span class="op">::</span><span class="kw">select</span>(userId, movieId, rating) <span class="op">%&gt;%</span></span>
<span id="cb1037-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1037-9" aria-hidden="true"></a><span class="st">     </span><span class="kw">spread</span>(movieId, rating) <span class="op">%&gt;%</span></span>
<span id="cb1037-10"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1037-10" aria-hidden="true"></a><span class="st">     </span><span class="kw">as.matrix</span>()</span>
<span id="cb1037-11"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1037-11" aria-hidden="true"></a></span>
<span id="cb1037-12"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1037-12" aria-hidden="true"></a><span class="kw">rownames</span>(y)&lt;-<span class="st"> </span>y[,<span class="dv">1</span>]</span>
<span id="cb1037-13"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1037-13" aria-hidden="true"></a>y &lt;-<span class="st"> </span>y[,<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb1037-14"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1037-14" aria-hidden="true"></a><span class="kw">colnames</span>(y) &lt;-<span class="st"> </span><span class="kw">with</span>(movie_titles, title[<span class="kw">match</span>(<span class="kw">colnames</span>(y), movieId)])</span>
<span id="cb1037-15"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1037-15" aria-hidden="true"></a></span>
<span id="cb1037-16"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1037-16" aria-hidden="true"></a>y &lt;-<span class="st"> </span><span class="kw">sweep</span>(y, <span class="dv">1</span>, <span class="kw">rowMeans</span>(y, <span class="dt">na.rm=</span><span class="ot">TRUE</span>))</span>
<span id="cb1037-17"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1037-17" aria-hidden="true"></a>y &lt;-<span class="st"> </span><span class="kw">sweep</span>(y, <span class="dv">2</span>, <span class="kw">colMeans</span>(y, <span class="dt">na.rm=</span><span class="ot">TRUE</span>))</span>
<span id="cb1037-18"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1037-18" aria-hidden="true"></a></span>
<span id="cb1037-19"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1037-19" aria-hidden="true"></a>m_<span class="dv">1</span> &lt;-<span class="st"> &quot;Godfather, The&quot;</span></span>
<span id="cb1037-20"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1037-20" aria-hidden="true"></a>m_<span class="dv">2</span> &lt;-<span class="st"> &quot;Godfather: Part II, The&quot;</span></span>
<span id="cb1037-21"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1037-21" aria-hidden="true"></a><span class="kw">qplot</span>(y[ ,m_<span class="dv">1</span>], y[,m_<span class="dv">2</span>], <span class="dt">xlab =</span> m_<span class="dv">1</span>, <span class="dt">ylab =</span> m_<span class="dv">2</span>)</span></code></pre></div>
<pre><code>## Warning: Removed 199 rows containing missing values (geom_point).</code></pre>
<p><img src="img/figures/unnamed-chunk-235-1.png" width="672" /></p>
<div class="sourceCode" id="cb1039"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1039-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1039-1" aria-hidden="true"></a>m_<span class="dv">1</span> &lt;-<span class="st"> &quot;Godfather, The&quot;</span></span>
<span id="cb1039-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1039-2" aria-hidden="true"></a>m_<span class="dv">3</span> &lt;-<span class="st"> &quot;Goodfellas&quot;</span></span>
<span id="cb1039-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1039-3" aria-hidden="true"></a><span class="kw">qplot</span>(y[ ,m_<span class="dv">1</span>], y[,m_<span class="dv">3</span>], <span class="dt">xlab =</span> m_<span class="dv">1</span>, <span class="dt">ylab =</span> m_<span class="dv">3</span>)</span></code></pre></div>
<pre><code>## Warning: Removed 204 rows containing missing values (geom_point).</code></pre>
<p><img src="img/figures/unnamed-chunk-235-2.png" width="672" /></p>
<div class="sourceCode" id="cb1041"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1041-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1041-1" aria-hidden="true"></a>m_<span class="dv">4</span> &lt;-<span class="st"> &quot;You&#39;ve Got Mail&quot;</span> </span>
<span id="cb1041-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1041-2" aria-hidden="true"></a>m_<span class="dv">5</span> &lt;-<span class="st"> &quot;Sleepless in Seattle&quot;</span> </span>
<span id="cb1041-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1041-3" aria-hidden="true"></a><span class="kw">qplot</span>(y[ ,m_<span class="dv">4</span>], y[,m_<span class="dv">5</span>], <span class="dt">xlab =</span> m_<span class="dv">4</span>, <span class="dt">ylab =</span> m_<span class="dv">5</span>)</span></code></pre></div>
<pre><code>## Warning: Removed 259 rows containing missing values (geom_point).</code></pre>
<p><img src="img/figures/unnamed-chunk-235-3.png" width="672" /></p>
<div class="sourceCode" id="cb1043"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1043-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1043-1" aria-hidden="true"></a><span class="kw">cor</span>(y[, <span class="kw">c</span>(m_<span class="dv">1</span>, m_<span class="dv">2</span>, m_<span class="dv">3</span>, m_<span class="dv">4</span>, m_<span class="dv">5</span>)], <span class="dt">use=</span><span class="st">&quot;pairwise.complete&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1043-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1043-2" aria-hidden="true"></a><span class="st">     </span>knitr<span class="op">::</span><span class="kw">kable</span>()</span></code></pre></div>
<table>
<colgroup>
<col width="21%" />
<col width="13%" />
<col width="21%" />
<col width="9%" />
<col width="14%" />
<col width="18%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Godfather, The</th>
<th align="right">Godfather: Part II, The</th>
<th align="right">Goodfellas</th>
<th align="right">You’ve Got Mail</th>
<th align="right">Sleepless in Seattle</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Godfather, The</td>
<td align="right">1.000</td>
<td align="right">0.832</td>
<td align="right">0.454</td>
<td align="right">-0.454</td>
<td align="right">-0.354</td>
</tr>
<tr class="even">
<td align="left">Godfather: Part II, The</td>
<td align="right">0.832</td>
<td align="right">1.000</td>
<td align="right">0.540</td>
<td align="right">-0.338</td>
<td align="right">-0.326</td>
</tr>
<tr class="odd">
<td align="left">Goodfellas</td>
<td align="right">0.454</td>
<td align="right">0.540</td>
<td align="right">1.000</td>
<td align="right">-0.489</td>
<td align="right">-0.367</td>
</tr>
<tr class="even">
<td align="left">You’ve Got Mail</td>
<td align="right">-0.454</td>
<td align="right">-0.338</td>
<td align="right">-0.489</td>
<td align="right">1.000</td>
<td align="right">0.542</td>
</tr>
<tr class="odd">
<td align="left">Sleepless in Seattle</td>
<td align="right">-0.354</td>
<td align="right">-0.326</td>
<td align="right">-0.367</td>
<td align="right">0.542</td>
<td align="right">1.000</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb1044"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1044-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1044-1" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb1044-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1044-2" aria-hidden="true"></a><span class="kw">options</span>(<span class="dt">digits =</span> <span class="dv">2</span>)</span>
<span id="cb1044-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1044-3" aria-hidden="true"></a>Q &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span> , <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">-1</span>, <span class="dv">-1</span>), <span class="dt">ncol=</span><span class="dv">1</span>)</span>
<span id="cb1044-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1044-4" aria-hidden="true"></a><span class="kw">rownames</span>(Q) &lt;-<span class="st"> </span><span class="kw">c</span>(m_<span class="dv">1</span>, m_<span class="dv">2</span>, m_<span class="dv">3</span>, m_<span class="dv">4</span>, m_<span class="dv">5</span>)</span>
<span id="cb1044-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1044-5" aria-hidden="true"></a>P &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>), <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">4</span>)), <span class="dt">ncol=</span><span class="dv">1</span>)</span>
<span id="cb1044-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1044-6" aria-hidden="true"></a><span class="kw">rownames</span>(P) &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(P)</span>
<span id="cb1044-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1044-7" aria-hidden="true"></a></span>
<span id="cb1044-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1044-8" aria-hidden="true"></a>X &lt;-<span class="st"> </span><span class="kw">jitter</span>(P<span class="op">%*%</span><span class="kw">t</span>(Q))</span>
<span id="cb1044-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1044-9" aria-hidden="true"></a>X <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>(<span class="dt">align =</span> <span class="st">&quot;c&quot;</span>)</span></code></pre></div>
<table>
<colgroup>
<col width="17%" />
<col width="27%" />
<col width="13%" />
<col width="18%" />
<col width="23%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Godfather, The</th>
<th align="center">Godfather: Part II, The</th>
<th align="center">Goodfellas</th>
<th align="center">You’ve Got Mail</th>
<th align="center">Sleepless in Seattle</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1.81</td>
<td align="center">2.15</td>
<td align="center">1.81</td>
<td align="center">-1.76</td>
<td align="center">-1.81</td>
</tr>
<tr class="even">
<td align="center">1.90</td>
<td align="center">1.91</td>
<td align="center">1.91</td>
<td align="center">-2.31</td>
<td align="center">-1.85</td>
</tr>
<tr class="odd">
<td align="center">2.06</td>
<td align="center">2.22</td>
<td align="center">1.61</td>
<td align="center">-1.82</td>
<td align="center">-2.02</td>
</tr>
<tr class="even">
<td align="center">0.33</td>
<td align="center">0.00</td>
<td align="center">-0.09</td>
<td align="center">-0.07</td>
<td align="center">0.29</td>
</tr>
<tr class="odd">
<td align="center">-0.24</td>
<td align="center">0.17</td>
<td align="center">0.30</td>
<td align="center">0.26</td>
<td align="center">-0.05</td>
</tr>
<tr class="even">
<td align="center">0.32</td>
<td align="center">0.39</td>
<td align="center">-0.13</td>
<td align="center">0.12</td>
<td align="center">-0.20</td>
</tr>
<tr class="odd">
<td align="center">0.36</td>
<td align="center">-0.10</td>
<td align="center">-0.01</td>
<td align="center">0.23</td>
<td align="center">-0.34</td>
</tr>
<tr class="even">
<td align="center">0.13</td>
<td align="center">0.22</td>
<td align="center">0.08</td>
<td align="center">0.04</td>
<td align="center">-0.32</td>
</tr>
<tr class="odd">
<td align="center">-1.90</td>
<td align="center">-1.65</td>
<td align="center">-2.01</td>
<td align="center">2.02</td>
<td align="center">1.85</td>
</tr>
<tr class="even">
<td align="center">-2.35</td>
<td align="center">-2.23</td>
<td align="center">-2.25</td>
<td align="center">2.23</td>
<td align="center">2.01</td>
</tr>
<tr class="odd">
<td align="center">-2.24</td>
<td align="center">-1.88</td>
<td align="center">-1.74</td>
<td align="center">1.62</td>
<td align="center">2.13</td>
</tr>
<tr class="even">
<td align="center">-2.26</td>
<td align="center">-2.30</td>
<td align="center">-1.87</td>
<td align="center">1.98</td>
<td align="center">1.93</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb1045"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1045-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1045-1" aria-hidden="true"></a><span class="kw">cor</span>(X)</span></code></pre></div>
<pre><code>##                         Godfather, The Godfather: Part II, The Goodfellas You&#39;ve Got Mail Sleepless in Seattle
## Godfather, The                    1.00                    0.99       0.98           -0.98                -0.99
## Godfather: Part II, The           0.99                    1.00       0.99           -0.98                -0.99
## Goodfellas                        0.98                    0.99       1.00           -0.99                -0.99
## You&#39;ve Got Mail                  -0.98                   -0.98      -0.99            1.00                 0.98
## Sleepless in Seattle             -0.99                   -0.99      -0.99            0.98                 1.00</code></pre>
<div class="sourceCode" id="cb1047"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1047-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1047-1" aria-hidden="true"></a><span class="kw">t</span>(Q) <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>(<span class="dt">aling=</span><span class="st">&quot;c&quot;</span>)</span></code></pre></div>
<table>
<colgroup>
<col width="17%" />
<col width="27%" />
<col width="12%" />
<col width="18%" />
<col width="24%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">Godfather, The</th>
<th align="right">Godfather: Part II, The</th>
<th align="right">Goodfellas</th>
<th align="right">You’ve Got Mail</th>
<th align="right">Sleepless in Seattle</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">-1</td>
<td align="right">-1</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb1048"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1048-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1048-1" aria-hidden="true"></a>P</span></code></pre></div>
<pre><code>##    [,1]
## 1     2
## 2     2
## 3     2
## 4     0
## 5     0
## 6     0
## 7     0
## 8     0
## 9    -2
## 10   -2
## 11   -2
## 12   -2</code></pre>
<div class="sourceCode" id="cb1050"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1050-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1050-1" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb1050-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1050-2" aria-hidden="true"></a><span class="kw">options</span>(<span class="dt">digits =</span> <span class="dv">2</span>)</span>
<span id="cb1050-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1050-3" aria-hidden="true"></a>m_<span class="dv">6</span> &lt;-<span class="st"> &quot;Scent of a Woman&quot;</span></span>
<span id="cb1050-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1050-4" aria-hidden="true"></a>Q &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="kw">c</span>(<span class="dv">1</span> , <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">-1</span>, <span class="dv">-1</span>, <span class="dv">-1</span>), </span>
<span id="cb1050-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1050-5" aria-hidden="true"></a>           <span class="kw">c</span>(<span class="dv">1</span> , <span class="dv">1</span>, <span class="dv">-1</span>, <span class="dv">-1</span>, <span class="dv">-1</span>, <span class="dv">1</span>))</span>
<span id="cb1050-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1050-6" aria-hidden="true"></a><span class="kw">rownames</span>(Q) &lt;-<span class="st"> </span><span class="kw">c</span>(m_<span class="dv">1</span>, m_<span class="dv">2</span>, m_<span class="dv">3</span>, m_<span class="dv">4</span>, m_<span class="dv">5</span>, m_<span class="dv">6</span>)</span>
<span id="cb1050-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1050-7" aria-hidden="true"></a>P &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>), <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">4</span>)), </span>
<span id="cb1050-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1050-8" aria-hidden="true"></a>           <span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>))<span class="op">/</span><span class="dv">2</span></span>
<span id="cb1050-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1050-9" aria-hidden="true"></a><span class="kw">rownames</span>(P) &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(X)</span>
<span id="cb1050-10"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1050-10" aria-hidden="true"></a></span>
<span id="cb1050-11"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1050-11" aria-hidden="true"></a>X &lt;-<span class="st"> </span><span class="kw">jitter</span>(P<span class="op">%*%</span><span class="kw">t</span>(Q), <span class="dt">factor=</span><span class="dv">1</span>)</span>
<span id="cb1050-12"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1050-12" aria-hidden="true"></a>X <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>(<span class="dt">align =</span> <span class="st">&quot;c&quot;</span>)</span></code></pre></div>
<table style="width:100%;">
<colgroup>
<col width="14%" />
<col width="22%" />
<col width="10%" />
<col width="15%" />
<col width="20%" />
<col width="16%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Godfather, The</th>
<th align="center">Godfather: Part II, The</th>
<th align="center">Goodfellas</th>
<th align="center">You’ve Got Mail</th>
<th align="center">Sleepless in Seattle</th>
<th align="center">Scent of a Woman</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">0.45</td>
<td align="center">0.54</td>
<td align="center">1.45</td>
<td align="center">-0.44</td>
<td align="center">-0.45</td>
<td align="center">-1.42</td>
</tr>
<tr class="even">
<td align="center">1.47</td>
<td align="center">1.48</td>
<td align="center">0.48</td>
<td align="center">-1.58</td>
<td align="center">-1.46</td>
<td align="center">-0.54</td>
</tr>
<tr class="odd">
<td align="center">1.51</td>
<td align="center">1.55</td>
<td align="center">0.40</td>
<td align="center">-1.46</td>
<td align="center">-1.50</td>
<td align="center">-0.51</td>
</tr>
<tr class="even">
<td align="center">0.08</td>
<td align="center">0.00</td>
<td align="center">-0.02</td>
<td align="center">-0.02</td>
<td align="center">0.07</td>
<td align="center">-0.03</td>
</tr>
<tr class="odd">
<td align="center">-0.06</td>
<td align="center">0.04</td>
<td align="center">0.07</td>
<td align="center">0.06</td>
<td align="center">-0.01</td>
<td align="center">0.03</td>
</tr>
<tr class="even">
<td align="center">0.58</td>
<td align="center">0.60</td>
<td align="center">-0.53</td>
<td align="center">-0.47</td>
<td align="center">-0.55</td>
<td align="center">0.45</td>
</tr>
<tr class="odd">
<td align="center">0.59</td>
<td align="center">0.48</td>
<td align="center">-0.50</td>
<td align="center">-0.44</td>
<td align="center">-0.59</td>
<td align="center">0.50</td>
</tr>
<tr class="even">
<td align="center">0.53</td>
<td align="center">0.56</td>
<td align="center">-0.48</td>
<td align="center">-0.49</td>
<td align="center">-0.58</td>
<td align="center">0.55</td>
</tr>
<tr class="odd">
<td align="center">-0.97</td>
<td align="center">-0.91</td>
<td align="center">-1.00</td>
<td align="center">1.01</td>
<td align="center">0.96</td>
<td align="center">0.92</td>
</tr>
<tr class="even">
<td align="center">-1.59</td>
<td align="center">-1.56</td>
<td align="center">-0.56</td>
<td align="center">1.56</td>
<td align="center">1.50</td>
<td align="center">0.58</td>
</tr>
<tr class="odd">
<td align="center">-1.56</td>
<td align="center">-1.47</td>
<td align="center">-0.43</td>
<td align="center">1.40</td>
<td align="center">1.53</td>
<td align="center">0.47</td>
</tr>
<tr class="even">
<td align="center">-1.56</td>
<td align="center">-1.57</td>
<td align="center">-0.47</td>
<td align="center">1.50</td>
<td align="center">1.48</td>
<td align="center">0.57</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb1051"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1051-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1051-1" aria-hidden="true"></a><span class="kw">cor</span>(X)</span></code></pre></div>
<pre><code>##                         Godfather, The Godfather: Part II, The Goodfellas You&#39;ve Got Mail Sleepless in Seattle Scent of a Woman
## Godfather, The                    1.00                    1.00       0.53           -1.00                -1.00            -0.57
## Godfather: Part II, The           1.00                    1.00       0.55           -1.00                -1.00            -0.59
## Goodfellas                        0.53                    0.55       1.00           -0.55                -0.53            -0.99
## You&#39;ve Got Mail                  -1.00                   -1.00      -0.55            1.00                 1.00             0.60
## Sleepless in Seattle             -1.00                   -1.00      -0.53            1.00                 1.00             0.57
## Scent of a Woman                 -0.57                   -0.59      -0.99            0.60                 0.57             1.00</code></pre>
<div class="sourceCode" id="cb1053"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1053-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1053-1" aria-hidden="true"></a><span class="kw">t</span>(Q) <span class="op">%&gt;%</span><span class="st"> </span>knitr<span class="op">::</span><span class="kw">kable</span>(<span class="dt">align=</span><span class="st">&quot;c&quot;</span>)</span></code></pre></div>
<table style="width:100%;">
<colgroup>
<col width="14%" />
<col width="22%" />
<col width="10%" />
<col width="15%" />
<col width="20%" />
<col width="16%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Godfather, The</th>
<th align="center">Godfather: Part II, The</th>
<th align="center">Goodfellas</th>
<th align="center">You’ve Got Mail</th>
<th align="center">Sleepless in Seattle</th>
<th align="center">Scent of a Woman</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">-1</td>
<td align="center">-1</td>
<td align="center">-1</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">-1</td>
<td align="center">-1</td>
<td align="center">-1</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb1054"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1054-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1054-1" aria-hidden="true"></a>P</span></code></pre></div>
<pre><code>##    [,1] [,2]
## 1     1 -0.5
## 2     1  0.5
## 3     1  0.5
## 4     0  0.0
## 5     0  0.0
## 6     0  0.5
## 7     0  0.5
## 8     0  0.5
## 9    -1  0.0
## 10   -1 -0.5
## 11   -1 -0.5
## 12   -1 -0.5</code></pre>
<div class="sourceCode" id="cb1056"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1056-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1056-1" aria-hidden="true"></a>six_movies &lt;-<span class="st"> </span><span class="kw">c</span>(m_<span class="dv">1</span>, m_<span class="dv">2</span>, m_<span class="dv">3</span>, m_<span class="dv">4</span>, m_<span class="dv">5</span>, m_<span class="dv">6</span>)</span>
<span id="cb1056-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1056-2" aria-hidden="true"></a>tmp &lt;-<span class="st"> </span>y[,six_movies]</span>
<span id="cb1056-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1056-3" aria-hidden="true"></a><span class="kw">cor</span>(tmp, <span class="dt">use=</span><span class="st">&quot;pairwise.complete&quot;</span>)</span></code></pre></div>
<pre><code>##                         Godfather, The Godfather: Part II, The Goodfellas You&#39;ve Got Mail Sleepless in Seattle Scent of a Woman
## Godfather, The                    1.00                    0.83       0.45           -0.45                -0.35             0.07
## Godfather: Part II, The           0.83                    1.00       0.54           -0.34                -0.33             0.14
## Goodfellas                        0.45                    0.54       1.00           -0.49                -0.37            -0.17
## You&#39;ve Got Mail                  -0.45                   -0.34      -0.49            1.00                 0.54            -0.20
## Sleepless in Seattle             -0.35                   -0.33      -0.37            0.54                 1.00            -0.18
## Scent of a Woman                  0.07                    0.14      -0.17           -0.20                -0.18             1.00</code></pre>
</div>
<div id="svd-and-pca" class="section level2" number="7.13">
<h2><span class="header-section-number">7.13</span> SVD and PCA</h2>
<p>There is a link to the relevant section of the textbook: <a href="https://rafalab.github.io/dsbook/large-datasets.html#connection-to-svd-and-pca" target="_blank">Connection to SVD and PCA</a></p>
<p><strong>Key points</strong></p>
<ul>
<li>You can think of <strong>singular value decomposition (SVD)</strong> as an algorithm that finds the vectors <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> that permit us to write the matrix of residuals <span class="math inline">\(r\)</span> with <span class="math inline">\(m\)</span> rows and <span class="math inline">\(n\)</span> columns in the following way:</li>
</ul>
<p><span class="math inline">\(r_{u, i} = p_{u, 1} q_{1, i} + p_{u, 2} q_{2, i} + ... + p_{u, m} q_{m, i},\)</span></p>
<p>with the variability of these terms decreasing and the <span class="math inline">\(p\)</span>’s uncorrelated to each other.</p>
<ul>
<li><strong>SVD also computes the variabilities</strong> so that we can know how much of the matrix’s total variability is explained as we add new terms.</li>
<li>The <strong>vectors <span class="math inline">\(q\)</span> are called the principal components</strong> and the <strong>vectors <span class="math inline">\(p\)</span> are the user effects</strong>. By using principal components analysis (PCA), matrix factorization can capture structure in the data determined by user opinions about movies.</li>
</ul>
<p><em>Code</em></p>
<div class="sourceCode" id="cb1058"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1058-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1058-1" aria-hidden="true"></a>y[<span class="kw">is.na</span>(y)] &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb1058-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1058-2" aria-hidden="true"></a>y &lt;-<span class="st"> </span><span class="kw">sweep</span>(y, <span class="dv">1</span>, <span class="kw">rowMeans</span>(y))</span>
<span id="cb1058-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1058-3" aria-hidden="true"></a>pca &lt;-<span class="st"> </span><span class="kw">prcomp</span>(y)</span>
<span id="cb1058-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1058-4" aria-hidden="true"></a></span>
<span id="cb1058-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1058-5" aria-hidden="true"></a><span class="kw">dim</span>(pca<span class="op">$</span>rotation)</span></code></pre></div>
<pre><code>## [1] 454 292</code></pre>
<div class="sourceCode" id="cb1060"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1060-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1060-1" aria-hidden="true"></a><span class="kw">dim</span>(pca<span class="op">$</span>x)</span></code></pre></div>
<pre><code>## [1] 292 292</code></pre>
<div class="sourceCode" id="cb1062"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1062-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1062-1" aria-hidden="true"></a><span class="kw">plot</span>(pca<span class="op">$</span>sdev)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-236-1.png" width="672" /></p>
<div class="sourceCode" id="cb1063"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1063-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1063-1" aria-hidden="true"></a>var_explained &lt;-<span class="st"> </span><span class="kw">cumsum</span>(pca<span class="op">$</span>sdev<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="kw">sum</span>(pca<span class="op">$</span>sdev<span class="op">^</span><span class="dv">2</span>))</span>
<span id="cb1063-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1063-2" aria-hidden="true"></a><span class="kw">plot</span>(var_explained)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-236-2.png" width="672" /></p>
<div class="sourceCode" id="cb1064"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1064-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1064-1" aria-hidden="true"></a>pcs &lt;-<span class="st"> </span><span class="kw">data.frame</span>(pca<span class="op">$</span>rotation, <span class="dt">name =</span> <span class="kw">colnames</span>(y))</span>
<span id="cb1064-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1064-2" aria-hidden="true"></a>pcs <span class="op">%&gt;%</span><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(PC1, PC2)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb1064-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1064-3" aria-hidden="true"></a><span class="st">     </span><span class="kw">geom_text_repel</span>(<span class="kw">aes</span>(PC1, PC2, <span class="dt">label=</span>name),</span>
<span id="cb1064-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1064-4" aria-hidden="true"></a>                     <span class="dt">data =</span> <span class="kw">filter</span>(pcs, </span>
<span id="cb1064-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1064-5" aria-hidden="true"></a>                                   PC1 <span class="op">&lt;</span><span class="st"> </span><span class="fl">-0.1</span> <span class="op">|</span><span class="st"> </span>PC1 <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.1</span> <span class="op">|</span><span class="st"> </span>PC2 <span class="op">&lt;</span><span class="st"> </span><span class="fl">-0.075</span> <span class="op">|</span><span class="st"> </span>PC2 <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.1</span>))</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-236-3.png" width="672" /></p>
<div class="sourceCode" id="cb1065"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1065-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1065-1" aria-hidden="true"></a>pcs <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">select</span>(name, PC1) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(PC1) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>)</span></code></pre></div>
<pre><code>##                                                name   PC1
## Pulp Fiction                           Pulp Fiction -0.16
## Seven (a.k.a. Se7en)           Seven (a.k.a. Se7en) -0.14
## Fargo                                         Fargo -0.14
## Taxi Driver                             Taxi Driver -0.13
## 2001: A Space Odyssey         2001: A Space Odyssey -0.13
## Silence of the Lambs, The Silence of the Lambs, The -0.13
## Clockwork Orange, A             Clockwork Orange, A -0.12
## Being John Malkovich           Being John Malkovich -0.11
## Fight Club                               Fight Club -0.10
## Godfather, The                       Godfather, The -0.10</code></pre>
<div class="sourceCode" id="cb1067"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1067-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1067-1" aria-hidden="true"></a>pcs <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">select</span>(name, PC1) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(PC1)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>)</span></code></pre></div>
<pre><code>##                                                                                                                                                                            name   PC1
## Independence Day (a.k.a. ID4)                                                                                                                     Independence Day (a.k.a. ID4) 0.161
## Shrek                                                                                                                                                                     Shrek 0.128
## Twister                                                                                                                                                                 Twister 0.119
## Titanic                                                                                                                                                                 Titanic 0.118
## Armageddon                                                                                                                                                           Armageddon 0.111
## Spider-Man                                                                                                                                                           Spider-Man 0.107
## Harry Potter and the Sorcerer&#39;s Stone (a.k.a. Harry Potter and the Philosopher&#39;s Stone) Harry Potter and the Sorcerer&#39;s Stone (a.k.a. Harry Potter and the Philosopher&#39;s Stone) 0.102
## Batman Forever                                                                                                                                                   Batman Forever 0.101
## Forrest Gump                                                                                                                                                       Forrest Gump 0.100
## Enemy of the State                                                                                                                                           Enemy of the State 0.092</code></pre>
<div class="sourceCode" id="cb1069"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1069-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1069-1" aria-hidden="true"></a>pcs <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">select</span>(name, PC2) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(PC2) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>)</span></code></pre></div>
<pre><code>##                                                                                        name    PC2
## Little Miss Sunshine                                                   Little Miss Sunshine -0.081
## Truman Show, The                                                           Truman Show, The -0.079
## Slumdog Millionaire                                                     Slumdog Millionaire -0.076
## Mars Attacks!                                                                 Mars Attacks! -0.073
## American Beauty                                                             American Beauty -0.069
## Amelie (Fabuleux destin d&#39;Amélie Poulain, Le) Amelie (Fabuleux destin d&#39;Amélie Poulain, Le) -0.068
## City of God (Cidade de Deus)                                   City of God (Cidade de Deus) -0.068
## Monty Python&#39;s Life of Brian                                   Monty Python&#39;s Life of Brian -0.068
## Shawshank Redemption, The                                         Shawshank Redemption, The -0.066
## Beautiful Mind, A                                                         Beautiful Mind, A -0.064</code></pre>
<div class="sourceCode" id="cb1071"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1071-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1071-1" aria-hidden="true"></a>pcs <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">select</span>(name, PC2) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(PC2)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>)</span></code></pre></div>
<pre><code>##                                                                                                  name   PC2
## Lord of the Rings: The Two Towers, The                         Lord of the Rings: The Two Towers, The 0.336
## Lord of the Rings: The Fellowship of the Ring, The Lord of the Rings: The Fellowship of the Ring, The 0.332
## Lord of the Rings: The Return of the King, The         Lord of the Rings: The Return of the King, The 0.237
## Matrix, The                                                                               Matrix, The 0.231
## Star Wars: Episode IV - A New Hope                                 Star Wars: Episode IV - A New Hope 0.217
## Star Wars: Episode VI - Return of the Jedi                 Star Wars: Episode VI - Return of the Jedi 0.192
## Star Wars: Episode V - The Empire Strikes Back         Star Wars: Episode V - The Empire Strikes Back 0.168
## Spider-Man 2                                                                             Spider-Man 2 0.114
## Dark Knight, The                                                                     Dark Knight, The 0.103
## X2: X-Men United                                                                     X2: X-Men United 0.094</code></pre>
</div>
<div id="comprehension-check---matrix-factorization" class="section level2" number="7.14">
<h2><span class="header-section-number">7.14</span> Comprehension Check - Matrix Factorization</h2>
<p>In this exercise set, we will be covering a topic useful for understanding matrix factorization: the singular value decomposition (SVD). SVD is a mathematical result that is widely used in machine learning, both in practice and to understand the mathematical properties of some algorithms. This is a rather advanced topic and to complete this exercise set you will have to be familiar with linear algebra concepts such as matrix multiplication, orthogonal matrices, and diagonal matrices.</p>
<p>The SVD tells us that we can <strong>decompose</strong> an <span class="math inline">\(N\times p\)</span> matrix <span class="math inline">\(Y\)</span> with <span class="math inline">\(p &lt; N\)</span> as</p>
<p><span class="math inline">\(Y = U D V^{\top}\)</span></p>
<p>with <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span> <strong>orthogonal</strong> of dimensions <span class="math inline">\(N\times p\)</span> and <span class="math inline">\(p\times p\)</span> respectively and <span class="math inline">\(D\)</span> a <span class="math inline">\(p\times p\)</span> <strong>diagonal</strong> matrix with the values of the diagonal decreasing:</p>
<p><span class="math inline">\(d_{1,1} \geq d_{2,2} \geq \dots d_{p,p}\)</span></p>
<p>In this exercise, we will see one of the ways that this decomposition can be useful. To do this, we will construct a dataset that represents grade scores for 100 students in 24 different subjects. The overall average has been removed so this data represents the percentage point each student received above or below the average test score. So a 0 represents an average grade (C), a 25 is a high grade (A+), and a -25 represents a low grade (F). You can simulate the data like this:</p>
<div class="sourceCode" id="cb1073"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1073-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1073-1" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">1987</span>)</span>
<span id="cb1073-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1073-2" aria-hidden="true"></a><span class="co">#if using R 3.6 or later, use `set.seed(1987, sample.kind=&quot;Rounding&quot;)` instead</span></span>
<span id="cb1073-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1073-3" aria-hidden="true"></a>n &lt;-<span class="st"> </span><span class="dv">100</span></span>
<span id="cb1073-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1073-4" aria-hidden="true"></a>k &lt;-<span class="st"> </span><span class="dv">8</span></span>
<span id="cb1073-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1073-5" aria-hidden="true"></a>Sigma &lt;-<span class="st"> </span><span class="dv">64</span>  <span class="op">*</span><span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="fl">.75</span>, <span class="fl">.5</span>, <span class="fl">.75</span>, <span class="dv">1</span>, <span class="fl">.5</span>, <span class="fl">.5</span>, <span class="fl">.5</span>, <span class="dv">1</span>), <span class="dv">3</span>, <span class="dv">3</span>) </span>
<span id="cb1073-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1073-6" aria-hidden="true"></a>m &lt;-<span class="st"> </span>MASS<span class="op">::</span><span class="kw">mvrnorm</span>(n, <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">3</span>), Sigma)</span>
<span id="cb1073-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1073-7" aria-hidden="true"></a>m &lt;-<span class="st"> </span>m[<span class="kw">order</span>(<span class="kw">rowMeans</span>(m), <span class="dt">decreasing =</span> <span class="ot">TRUE</span>),]</span>
<span id="cb1073-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1073-8" aria-hidden="true"></a>y &lt;-<span class="st"> </span>m <span class="op">%x%</span><span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rep</span>(<span class="dv">1</span>, k), <span class="dt">nrow =</span> <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(<span class="kw">matrix</span>(n<span class="op">*</span>k<span class="op">*</span><span class="dv">3</span>)), n, k<span class="op">*</span><span class="dv">3</span>)</span>
<span id="cb1073-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1073-9" aria-hidden="true"></a><span class="kw">colnames</span>(y) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">paste</span>(<span class="kw">rep</span>(<span class="st">&quot;Math&quot;</span>,k), <span class="dv">1</span><span class="op">:</span>k, <span class="dt">sep=</span><span class="st">&quot;_&quot;</span>),</span>
<span id="cb1073-10"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1073-10" aria-hidden="true"></a>                 <span class="kw">paste</span>(<span class="kw">rep</span>(<span class="st">&quot;Science&quot;</span>,k), <span class="dv">1</span><span class="op">:</span>k, <span class="dt">sep=</span><span class="st">&quot;_&quot;</span>),</span>
<span id="cb1073-11"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1073-11" aria-hidden="true"></a>                 <span class="kw">paste</span>(<span class="kw">rep</span>(<span class="st">&quot;Arts&quot;</span>,k), <span class="dv">1</span><span class="op">:</span>k, <span class="dt">sep=</span><span class="st">&quot;_&quot;</span>))</span></code></pre></div>
<p>Our goal is to describe the student performances as succinctly as possible. For example, we want to know if these test results are all just a random independent numbers. Are all students just about as good? Does being good in one subject imply you will be good in another? How does the SVD help with all this? We will go step by step to show that with just three relatively small pairs of vectors we can explain much of the variability in this <span class="math inline">\(100 \times 24\)</span> dataset.</p>
<ol style="list-style-type: decimal">
<li>You can visualize the 24 test scores for the 100 students by plotting an image:</li>
</ol>
<div class="sourceCode" id="cb1074"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1074-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1074-1" aria-hidden="true"></a>my_image &lt;-<span class="st"> </span><span class="cf">function</span>(x, <span class="dt">zlim =</span> <span class="kw">range</span>(x), ...){</span>
<span id="cb1074-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1074-2" aria-hidden="true"></a>    colors =<span class="st"> </span><span class="kw">rev</span>(RColorBrewer<span class="op">::</span><span class="kw">brewer.pal</span>(<span class="dv">9</span>, <span class="st">&quot;RdBu&quot;</span>))</span>
<span id="cb1074-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1074-3" aria-hidden="true"></a>    cols &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">ncol</span>(x)</span>
<span id="cb1074-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1074-4" aria-hidden="true"></a>    rows &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(x)</span>
<span id="cb1074-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1074-5" aria-hidden="true"></a>    <span class="kw">image</span>(cols, rows, <span class="kw">t</span>(x[<span class="kw">rev</span>(rows),,<span class="dt">drop=</span><span class="ot">FALSE</span>]), <span class="dt">xaxt =</span> <span class="st">&quot;n&quot;</span>, <span class="dt">yaxt =</span> <span class="st">&quot;n&quot;</span>,</span>
<span id="cb1074-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1074-6" aria-hidden="true"></a>            <span class="dt">xlab=</span><span class="st">&quot;&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;&quot;</span>,  <span class="dt">col =</span> colors, <span class="dt">zlim =</span> zlim, ...)</span>
<span id="cb1074-7"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1074-7" aria-hidden="true"></a>    <span class="kw">abline</span>(<span class="dt">h=</span>rows <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span>, <span class="dt">v =</span> cols <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span>)</span>
<span id="cb1074-8"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1074-8" aria-hidden="true"></a>    <span class="kw">axis</span>(<span class="dt">side =</span> <span class="dv">1</span>, cols, <span class="kw">colnames</span>(x), <span class="dt">las =</span> <span class="dv">2</span>)</span>
<span id="cb1074-9"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1074-9" aria-hidden="true"></a>}</span>
<span id="cb1074-10"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1074-10" aria-hidden="true"></a></span>
<span id="cb1074-11"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1074-11" aria-hidden="true"></a><span class="kw">my_image</span>(y)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-238-1.png" width="672" /></p>
<p>How would you describe the data based on this figure?</p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
A. The test scores are all independent of each other.</li>
<li><input type="checkbox" disabled="" />
B. The students that are good at math are not good at science.</li>
<li><input type="checkbox" disabled="" />
C. The students that are good at math are not good at arts.</li>
<li><input type="checkbox" disabled="" checked="" />
D. The students that test well are at the top of the image and there seem to be three groupings by subject.</li>
<li><input type="checkbox" disabled="" />
E. The students that test well are at the bottom of the image and there seem to be three groupings by subject.</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>You can examine the correlation between the test scores directly like this:</li>
</ol>
<div class="sourceCode" id="cb1075"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1075-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1075-1" aria-hidden="true"></a><span class="kw">my_image</span>(<span class="kw">cor</span>(y), <span class="dt">zlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb1075-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1075-2" aria-hidden="true"></a><span class="kw">range</span>(<span class="kw">cor</span>(y))</span></code></pre></div>
<pre><code>## [1] 0.49 1.00</code></pre>
<div class="sourceCode" id="cb1077"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1077-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1077-1" aria-hidden="true"></a><span class="kw">axis</span>(<span class="dt">side =</span> <span class="dv">2</span>, <span class="dv">1</span><span class="op">:</span><span class="kw">ncol</span>(y), <span class="kw">rev</span>(<span class="kw">colnames</span>(y)), <span class="dt">las =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-239-1.png" width="672" /></p>
<p>Which of the following best describes what you see?</p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
A. The test scores are independent.</li>
<li><input type="checkbox" disabled="" />
B. Test scores in math and science are highly correlated but scores in arts are not.</li>
<li><input type="checkbox" disabled="" />
C. There is high correlation between tests in the same subject but no correlation across subjects.</li>
<li><input type="checkbox" disabled="" checked="" />
D. There is correlation among all tests, but higher if the tests are in science and math and even higher within each subject.</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>Remember that orthogonality means that <span class="math inline">\(U^{\top}U\)</span> and <span class="math inline">\(V^{\top}V\)</span> are equal to the identity matrix. This implies that we can also rewrite the decomposition as</li>
</ol>
<p><span class="math inline">\(Y V = U D \mbox{ or } U^{\top}Y = D V^{\top}\)</span></p>
<p>We can think of <span class="math inline">\(YV\)</span> and <span class="math inline">\(U^{\top}V\)</span> as two transformations of <span class="math inline">\(Y\)</span> that preserve the total variability of <span class="math inline">\(Y\)</span> since <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span> are orthogonal.</p>
<p>Use the function <code>svd()</code> to compute the SVD of <code>y</code>. This function will return <span class="math inline">\(U\)</span>, <span class="math inline">\(V\)</span>, and the diagonal entries of <span class="math inline">\(D\)</span>.</p>
<div class="sourceCode" id="cb1078"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1078-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1078-1" aria-hidden="true"></a>s &lt;-<span class="st"> </span><span class="kw">svd</span>(y)</span>
<span id="cb1078-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1078-2" aria-hidden="true"></a><span class="kw">names</span>(s)</span></code></pre></div>
<pre><code>## [1] &quot;d&quot; &quot;u&quot; &quot;v&quot;</code></pre>
<p>You can check that the SVD works by typing:</p>
<div class="sourceCode" id="cb1080"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1080-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1080-1" aria-hidden="true"></a>y_svd &lt;-<span class="st"> </span>s<span class="op">$</span>u <span class="op">%*%</span><span class="st"> </span><span class="kw">diag</span>(s<span class="op">$</span>d) <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(s<span class="op">$</span>v)</span>
<span id="cb1080-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1080-2" aria-hidden="true"></a><span class="kw">max</span>(<span class="kw">abs</span>(y <span class="op">-</span><span class="st"> </span>y_svd))</span></code></pre></div>
<pre><code>## [1] 5.3e-14</code></pre>
<p>Compute the sum of squares of the columns of <span class="math inline">\(Y\)</span> and store them in <code>ss_y</code>. Then compute the sum of squares of columns of the transformed <span class="math inline">\(YV\)</span> and store them in <code>ss_yv</code>. Confirm that <code>sum(ss_y)</code> is equal to <code>sum(ss_yv)</code>.</p>
<p>What is the value of <code>sum(ss_y)</code> (and also the value of <code>sum(ss_yv))</code>?</p>
<div class="sourceCode" id="cb1082"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1082-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1082-1" aria-hidden="true"></a>ss_y &lt;-<span class="st"> </span><span class="kw">apply</span>(y<span class="op">^</span><span class="dv">2</span>, <span class="dv">2</span>, sum)</span>
<span id="cb1082-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1082-2" aria-hidden="true"></a>ss_yv &lt;-<span class="st"> </span><span class="kw">apply</span>((y<span class="op">%*%</span>s<span class="op">$</span>v)<span class="op">^</span><span class="dv">2</span>, <span class="dv">2</span>, sum)</span>
<span id="cb1082-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1082-3" aria-hidden="true"></a><span class="kw">sum</span>(ss_y)</span></code></pre></div>
<pre><code>## [1] 175435</code></pre>
<div class="sourceCode" id="cb1084"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1084-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1084-1" aria-hidden="true"></a><span class="kw">sum</span>(ss_yv)</span></code></pre></div>
<pre><code>## [1] 175435</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>We see that the total sum of squares is preserved. This is because <span class="math inline">\(V\)</span> is orthogonal. Now to start understanding how <span class="math inline">\(YV\)</span> is useful, plot <code>ss_y</code> against the column number and then do the same for <code>ss_yv</code>.</li>
</ol>
<p>What do you observe?</p>
<div class="sourceCode" id="cb1086"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1086-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1086-1" aria-hidden="true"></a><span class="kw">plot</span>(ss_y)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-243-1.png" width="672" /></p>
<div class="sourceCode" id="cb1087"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1087-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1087-1" aria-hidden="true"></a><span class="kw">plot</span>(ss_yv)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-243-2.png" width="672" /></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
A. <code>ss_y</code> and <code>ss_yv</code> are decreasing and close to 0 for the 4th column and beyond.</li>
<li><input type="checkbox" disabled="" checked="" />
B. <code>ss_yv</code> is decreasing and close to 0 for the 4th column and beyond.</li>
<li><input type="checkbox" disabled="" />
C. <code>ss_y</code> is decreasing and close to 0 for the 4th column and beyond.</li>
<li><input type="checkbox" disabled="" />
D. There is no discernible pattern to either <code>ss_y</code> or <code>ss_yv</code>.</li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li>Now notice that we didn’t have to compute <code>ss_yv</code> because we already have the answer. How? Remember that <span class="math inline">\(YV = UD\)</span> and because <span class="math inline">\(U\)</span> is orthogonal, we know that the sum of squares of the columns of <span class="math inline">\(UD\)</span> are the diagonal entries of <span class="math inline">\(D\)</span> squared. Confirm this by plotting the square root of <code>ss_yv</code> versus the diagonal entries of <span class="math inline">\(D\)</span>.</li>
</ol>
<div class="sourceCode" id="cb1088"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1088-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1088-1" aria-hidden="true"></a><span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="kw">sqrt</span>(ss_yv), <span class="dt">y =</span> s<span class="op">$</span>d) <span class="op">%&gt;%</span></span>
<span id="cb1088-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1088-2" aria-hidden="true"></a><span class="kw">ggplot</span>(<span class="kw">aes</span>(x,y)) <span class="op">+</span></span>
<span id="cb1088-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1088-3" aria-hidden="true"></a><span class="kw">geom_point</span>()</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-244-1.png" width="672" /></p>
<p>Which of these plots is correct?</p>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
A.</li>
</ul>
<p><img src="images/ss_yv%20versus%20D_A.png" /></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
B.</li>
</ul>
<p><img src="images/ss_yv%20versus%20D_B.png" /></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
C.</li>
</ul>
<p><img src="images/ss_yv%20versus%20D_C.png" /></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
D.</li>
</ul>
<p><img src="images/ss_yv%20versus%20D_D.png" /></p>
<ol start="6" style="list-style-type: decimal">
<li>So from the above we know that the sum of squares of the columns of <span class="math inline">\(Y\)</span> (the total sum of squares) adds up to the sum of <code>s$d^2</code> and that the transformation <span class="math inline">\(YV\)</span> gives us columns with sums of squares equal to <code>s$d^2</code>. Now compute the percent of the total variability that is explained by just the first three columns of <span class="math inline">\(YV\)</span>.</li>
</ol>
<p>What proportion of the total variability is explained by the first three columns of <span class="math inline">\(YV\)</span>?</p>
<div class="sourceCode" id="cb1089"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1089-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1089-1" aria-hidden="true"></a><span class="kw">sum</span>(s<span class="op">$</span>d[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>]<span class="op">^</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(s<span class="op">$</span>d<span class="op">^</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 0.99</code></pre>
<ol start="7" style="list-style-type: decimal">
<li>Before we continue, let’s show a useful computational trick to avoid creating the matrix <code>diag(s$d)</code>. To motivate this, we note that if we write <span class="math inline">\(U\)</span> out in its columns <span class="math inline">\([U_1, U_2, \dots, U_p]\)</span> then <span class="math inline">\(UD\)</span> is equal to</li>
</ol>
<p><span class="math inline">\(UD = [U_1 d_{1,1}, U_2 d_{2,2}, \dots, U_p d_{p,p}]\)</span></p>
<p>Use the <code>sweep</code> function to compute <span class="math inline">\(UD\)</span> without constructing <code>diag(s$d)</code> or using matrix multiplication.</p>
<p>Which code is correct?</p>
<ul class="task-list">
<li><p><input type="checkbox" disabled="" />
A. <code>identical(t(s$u %*% diag(s$d)), sweep(s$u, 2, s$d, FUN = "*"))</code></p></li>
<li><p><input type="checkbox" disabled="" checked="" />
B. <code>identical(s$u %*% diag(s$d), sweep(s$u, 2, s$d, FUN = "*"))</code></p></li>
<li><p><input type="checkbox" disabled="" />
C. <code>identical(s$u %*% t(diag(s$d)), sweep(s$u, 2, s$d, FUN = "*"))</code></p></li>
<li><p><input type="checkbox" disabled="" />
D. <code>identical(s$u %*% diag(s$d), sweep(s$u, 2, s, FUN = "*"))</code></p></li>
</ul>
<ol start="8" style="list-style-type: decimal">
<li>We know that <span class="math inline">\(U_1 d_{1,1}\)</span>, the first column of <span class="math inline">\(UD\)</span>, has the most variability of all the columns of <span class="math inline">\(UD\)</span>. Earlier we looked at an image of <span class="math inline">\(Y\)</span> using <code>my_image(y)</code>, in which we saw that the student to student variability is quite large and that students that are good in one subject tend to be good in all. This implies that the average (across all subjects) for each student should explain a lot of the variability. Compute the average score for each student, plot it against <span class="math inline">\(U_1 d_{1,1}\)</span>, and describe what you find.</li>
</ol>
<p>What do you observe?</p>
<div class="sourceCode" id="cb1091"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1091-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1091-1" aria-hidden="true"></a><span class="kw">plot</span>(s<span class="op">$</span>u[,<span class="dv">1</span>]<span class="op">*</span>s<span class="op">$</span>d[<span class="dv">1</span>], <span class="kw">rowMeans</span>(y))</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-246-1.png" width="672" /></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
A. There is no relationship between the average score for each student and <span class="math inline">\(U_1 d_{1,1}\)</span>.</li>
<li><input type="checkbox" disabled="" />
B. There is an exponential relationship between the average score for each student and <span class="math inline">\(U_1 d_{1,1}\)</span>.</li>
<li><input type="checkbox" disabled="" checked="" />
C. There is a linear relationship between the average score for each student and <span class="math inline">\(U_1 d_{1,1}\)</span>.</li>
</ul>
<ol start="9" style="list-style-type: decimal">
<li>We note that the signs in SVD are arbitrary because:</li>
</ol>
<p><span class="math inline">\(U D V^{\top} = (-U) D (-V)^{\top}\)</span></p>
<p>With this in mind we see that the first column of <span class="math inline">\(UD\)</span> is almost identical to the average score for each student except for the sign.</p>
<p>This implies that multiplying 𝑌 by the first column of 𝑉 must be performing a similar operation to taking the average. Make an image plot of 𝑉 and describe the first column relative to others and how this relates to taking an average.</p>
<p>How does the first column relate to the others, and how does this relate to taking an average?</p>
<div class="sourceCode" id="cb1092"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1092-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1092-1" aria-hidden="true"></a><span class="kw">my_image</span>(s<span class="op">$</span>v)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-247-1.png" width="672" /></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
A. The first column is very variable, which implies that the first column of YV is the sum of the rows of Y multiplied by some non-constant function, and is thus not proportional to an average.</li>
<li><input type="checkbox" disabled="" />
B. The first column is very variable, which implies that the first column of YV is the sum of the rows of Y multiplied by some non-constant function, and is thus proportional to an average.</li>
<li><input type="checkbox" disabled="" checked="" />
C. The first column is very close to being a constant, which implies that the first column of YV is the sum of the rows of Y multiplied by some constant, and is thus proportional to an average.</li>
<li><input type="checkbox" disabled="" />
D. The first three columns are all very close to being a constant, which implies that these columns are the sum of the rows of Y multiplied by some constant, and are thus proportional to an average.</li>
</ul>
<ol start="10" style="list-style-type: decimal">
<li>We already saw that we can rewrite <span class="math inline">\(UD\)</span> as</li>
</ol>
<p><span class="math inline">\(U_1 d_{1,1} + U_2 d_{2,2} + \dots + U_p d_{p,p}\)</span></p>
<p>with <span class="math inline">\(U_j\)</span> the j-th column of <span class="math inline">\(U\)</span>. This implies that we can rewrite the entire SVD as:</p>
<p><span class="math inline">\(Y = U_1 d_{1,1} V_1 ^{\top} + U_2 d_{2,2} V_2 ^{\top} + \dots + U_p d_{p,p} V_p ^{\top}\)</span></p>
<p>with <span class="math inline">\(V_j\)</span> the jth column of <span class="math inline">\(V\)</span>. Plot <span class="math inline">\(U_1\)</span>, then plot <span class="math inline">\(V_1^{\top}\)</span> using the same range for the y-axis limits, then make an image of <span class="math inline">\(U_1 d_{1,1} V_1 ^{\top}\)</span> and compare it to the image of <span class="math inline">\(Y\)</span>. Hint: use the <code>my_image()</code> function defined above. Use the <code>drop=FALSE</code> argument to assure the subsets of matrices are matrices.</p>
<div class="sourceCode" id="cb1093"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1093-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1093-1" aria-hidden="true"></a><span class="kw">plot</span>(s<span class="op">$</span>u[,<span class="dv">1</span>], <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="fl">0.25</span>, <span class="fl">0.25</span>))</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-248-1.png" width="672" /></p>
<div class="sourceCode" id="cb1094"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1094-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1094-1" aria-hidden="true"></a><span class="kw">plot</span>(s<span class="op">$</span>v[,<span class="dv">1</span>], <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="fl">0.25</span>, <span class="fl">0.25</span>))</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-248-2.png" width="672" /></p>
<div class="sourceCode" id="cb1095"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1095-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1095-1" aria-hidden="true"></a><span class="kw">with</span>(s, <span class="kw">my_image</span>((u[, <span class="dv">1</span>, <span class="dt">drop=</span><span class="ot">FALSE</span>]<span class="op">*</span>d[<span class="dv">1</span>]) <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(v[, <span class="dv">1</span>, <span class="dt">drop=</span><span class="ot">FALSE</span>])))</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-248-3.png" width="672" /></p>
<div class="sourceCode" id="cb1096"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1096-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1096-1" aria-hidden="true"></a><span class="kw">my_image</span>(y)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-248-4.png" width="672" /></p>
<ol start="11" style="list-style-type: decimal">
<li>We see that with just a vector of length 100, a scalar, and a vector of length 24, we can actually come close to reconstructing the a <span class="math inline">\(100 \times 24\)</span> matrix. This is our first matrix factorization:</li>
</ol>
<p><span class="math inline">\(Y \approx d_{1,1} U_1 V_1^{\top}\)</span></p>
<p>In the exercise in Q6, we saw how to calculate the percent of total variability explained. However, our approximation only explains the observation that good students tend to be good in all subjects. Another aspect of the original data that our approximation does not explain was the higher similarity we observed within subjects. We can see this by computing the difference between our approximation and original data and then computing the correlations. You can see this by running this code:</p>
<div class="sourceCode" id="cb1097"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1097-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1097-1" aria-hidden="true"></a>resid &lt;-<span class="st"> </span>y <span class="op">-</span><span class="st"> </span><span class="kw">with</span>(s,(u[, <span class="dv">1</span>, <span class="dt">drop=</span><span class="ot">FALSE</span>]<span class="op">*</span>d[<span class="dv">1</span>]) <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(v[, <span class="dv">1</span>, <span class="dt">drop=</span><span class="ot">FALSE</span>]))</span>
<span id="cb1097-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1097-2" aria-hidden="true"></a><span class="kw">my_image</span>(<span class="kw">cor</span>(resid), <span class="dt">zlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb1097-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1097-3" aria-hidden="true"></a><span class="kw">axis</span>(<span class="dt">side =</span> <span class="dv">2</span>, <span class="dv">1</span><span class="op">:</span><span class="kw">ncol</span>(y), <span class="kw">rev</span>(<span class="kw">colnames</span>(y)), <span class="dt">las =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-249-1.png" width="672" /></p>
<p>Now that we have removed the overall student effect, the correlation plot reveals that we have not yet explained the within subject correlation nor the fact that math and science are closer to each other than to the arts. So let’s explore the second column of the SVD.</p>
<p>Repeat the previous exercise (Q10) but for the second column: Plot <span class="math inline">\(U_2\)</span>, then plot <span class="math inline">\(V_2^{\top}\)</span> using the same range for the y-axis limits, then make an image of <span class="math inline">\(U_2 d_{2,2} V_2 ^{\top}\)</span> and compare it to the image of <code>resid</code>.</p>
<div class="sourceCode" id="cb1098"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1098-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1098-1" aria-hidden="true"></a><span class="kw">plot</span>(s<span class="op">$</span>u[,<span class="dv">2</span>], <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">0.5</span>))</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-250-1.png" width="672" /></p>
<div class="sourceCode" id="cb1099"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1099-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1099-1" aria-hidden="true"></a><span class="kw">plot</span>(s<span class="op">$</span>v[,<span class="dv">2</span>], <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">0.5</span>))</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-250-2.png" width="672" /></p>
<div class="sourceCode" id="cb1100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1100-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1100-1" aria-hidden="true"></a><span class="kw">with</span>(s, <span class="kw">my_image</span>((u[, <span class="dv">2</span>, <span class="dt">drop=</span><span class="ot">FALSE</span>]<span class="op">*</span>d[<span class="dv">2</span>]) <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(v[, <span class="dv">2</span>, <span class="dt">drop=</span><span class="ot">FALSE</span>])))</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-250-3.png" width="672" /></p>
<div class="sourceCode" id="cb1101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1101-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1101-1" aria-hidden="true"></a><span class="kw">my_image</span>(resid)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-250-4.png" width="672" /></p>
<ol start="12" style="list-style-type: decimal">
<li>The second column clearly relates to a student’s difference in ability in math/science versus the arts. We can see this most clearly from the plot of <code>s$v[,2]</code>. Adding the matrix we obtain with these two columns will help with our approximation:</li>
</ol>
<p><span class="math inline">\(Y \approx d_{1,1} U_1 V_1^{\top} + d_{2,2} U_2 V_2^{\top}\)</span></p>
<p>We know it will explain <code>sum(s$d[1:2]^2)/sum(s$d^2) * 100</code> percent of the total variability. We can compute new residuals like this:</p>
<div class="sourceCode" id="cb1102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1102-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1102-1" aria-hidden="true"></a>resid &lt;-<span class="st"> </span>y <span class="op">-</span><span class="st"> </span><span class="kw">with</span>(s,<span class="kw">sweep</span>(u[, <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>], <span class="dv">2</span>, d[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>], <span class="dt">FUN=</span><span class="st">&quot;*&quot;</span>) <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(v[, <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>]))</span>
<span id="cb1102-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1102-2" aria-hidden="true"></a><span class="kw">my_image</span>(<span class="kw">cor</span>(resid), <span class="dt">zlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb1102-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1102-3" aria-hidden="true"></a><span class="kw">axis</span>(<span class="dt">side =</span> <span class="dv">2</span>, <span class="dv">1</span><span class="op">:</span><span class="kw">ncol</span>(y), <span class="kw">rev</span>(<span class="kw">colnames</span>(y)), <span class="dt">las =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-251-1.png" width="672" /></p>
<p>and see that the structure that is left is driven by the differences between math and science. Confirm this by first plotting <span class="math inline">\(U_3\)</span>, then plotting <span class="math inline">\(V_3^{\top}\)</span> using the same range for the y-axis limits, then making an image of <span class="math inline">\(U_3 d_{3,3} V_3 ^{\top}\)</span> and comparing it to the image of <code>resid</code>.</p>
<div class="sourceCode" id="cb1103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1103-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1103-1" aria-hidden="true"></a><span class="kw">plot</span>(s<span class="op">$</span>u[,<span class="dv">3</span>], <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">0.5</span>))</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-252-1.png" width="672" /></p>
<div class="sourceCode" id="cb1104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1104-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1104-1" aria-hidden="true"></a><span class="kw">plot</span>(s<span class="op">$</span>v[,<span class="dv">3</span>], <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">0.5</span>))</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-252-2.png" width="672" /></p>
<div class="sourceCode" id="cb1105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1105-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1105-1" aria-hidden="true"></a><span class="kw">with</span>(s, <span class="kw">my_image</span>((u[, <span class="dv">3</span>, <span class="dt">drop=</span><span class="ot">FALSE</span>]<span class="op">*</span>d[<span class="dv">3</span>]) <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(v[, <span class="dv">3</span>, <span class="dt">drop=</span><span class="ot">FALSE</span>])))</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-252-3.png" width="672" /></p>
<div class="sourceCode" id="cb1106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1106-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1106-1" aria-hidden="true"></a><span class="kw">my_image</span>(resid)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-252-4.png" width="672" /></p>
<ol start="13" style="list-style-type: decimal">
<li>The third column clearly relates to a student’s difference in ability in math and science. We can see this most clearly from the plot of <code>s$v[,3]</code>. Adding the matrix we obtain with these two columns will help with our approximation:</li>
</ol>
<p><span class="math inline">\(Y \approx d_{1,1} U_1 V_1^{\top} + d_{2,2} U_2 V_2^{\top} + d_{3,3} U_3 V_3^{\top}\)</span></p>
<p>We know it will explain: <code>sum(s$d[1:3]^2)/sum(s$d^2) * 100</code> percent of the total variability. We can compute new residuals like this:</p>
<div class="sourceCode" id="cb1107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1107-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1107-1" aria-hidden="true"></a>resid &lt;-<span class="st"> </span>y <span class="op">-</span><span class="st"> </span><span class="kw">with</span>(s,<span class="kw">sweep</span>(u[, <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dv">2</span>, d[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">FUN=</span><span class="st">&quot;*&quot;</span>) <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(v[, <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>]))</span>
<span id="cb1107-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1107-2" aria-hidden="true"></a><span class="kw">my_image</span>(<span class="kw">cor</span>(resid), <span class="dt">zlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb1107-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1107-3" aria-hidden="true"></a><span class="kw">axis</span>(<span class="dt">side =</span> <span class="dv">2</span>, <span class="dv">1</span><span class="op">:</span><span class="kw">ncol</span>(y), <span class="kw">rev</span>(<span class="kw">colnames</span>(y)), <span class="dt">las =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-253-1.png" width="672" /></p>
<p>We no longer see structure in the residuals: they seem to be independent of each other. This implies that we can describe the data with the following model:</p>
<p><span class="math inline">\(Y = d_{1,1} U_1 V_1^{\top} + d_{2,2} U_2 V_2^{\top} + d_{3,3} U_3 V_3^{\top} + \varepsilon\)</span></p>
<p>with <span class="math inline">\(\varepsilon\)</span> a matrix of independent identically distributed errors. This model is useful because we summarize of <span class="math inline">\(100 \times 24\)</span> observations with <span class="math inline">\(3 \times (100+24+1) = 375\)</span> numbers.</p>
<p>Furthermore, the three components of the model have useful interpretations:</p>
<p>1 - the overall ability of a student</p>
<p>2 - the difference in ability between the math/sciences and arts</p>
<p>3 - the remaining differences between the three subjects.</p>
<p>The sizes <span class="math inline">\(d_{1,1}, d_{2,2}\)</span> and <span class="math inline">\(d_{3,3}\)</span> tell us the variability explained by each component. Finally, note that the components <span class="math inline">\(d_{j,j} U_j V_j^{\top}\)</span> are equivalent to the jth principal component.</p>
<p>Finish the exercise by plotting an image of <span class="math inline">\(Y\)</span>, an image of <span class="math inline">\(d_{1,1} U_1 V_1^{\top} + d_{2,2} U_2 V_2^{\top} + d_{3,3} U_3 V_3^{\top}\)</span> and an image of the residuals, all with the same <code>zlim</code>.</p>
<div class="sourceCode" id="cb1108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1108-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1108-1" aria-hidden="true"></a>y_hat &lt;-<span class="st"> </span><span class="kw">with</span>(s,<span class="kw">sweep</span>(u[, <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dv">2</span>, d[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">FUN=</span><span class="st">&quot;*&quot;</span>) <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(v[, <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>]))</span>
<span id="cb1108-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1108-2" aria-hidden="true"></a><span class="kw">my_image</span>(y, <span class="dt">zlim =</span> <span class="kw">range</span>(y))</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-254-1.png" width="672" /></p>
<div class="sourceCode" id="cb1109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1109-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1109-1" aria-hidden="true"></a><span class="kw">my_image</span>(y_hat, <span class="dt">zlim =</span> <span class="kw">range</span>(y))</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-254-2.png" width="672" /></p>
<div class="sourceCode" id="cb1110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1110-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1110-1" aria-hidden="true"></a><span class="kw">my_image</span>(y <span class="op">-</span><span class="st"> </span>y_hat, <span class="dt">zlim =</span> <span class="kw">range</span>(y))</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-254-3.png" width="672" /></p>
</div>
<div id="comprehension-check---dimension-reduction" class="section level2" number="7.15">
<h2><span class="header-section-number">7.15</span> Comprehension Check - Dimension Reduction</h2>
<ol style="list-style-type: decimal">
<li>We want to explore the <code>tissue_gene_expression</code> predictors by plotting them.</li>
</ol>
<div class="sourceCode" id="cb1111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1111-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1111-1" aria-hidden="true"></a><span class="kw">data</span>(<span class="st">&quot;tissue_gene_expression&quot;</span>)</span>
<span id="cb1111-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1111-2" aria-hidden="true"></a><span class="kw">dim</span>(tissue_gene_expression<span class="op">$</span>x)</span></code></pre></div>
<pre><code>## [1] 189 500</code></pre>
<p>We want to get an idea of which observations are close to each other, but, as you can see from the dimensions, the predictors are 500-dimensional, making plotting difficult. Plot the first two principal components with color representing tissue type.</p>
<p>Which tissue is in a cluster by itself?</p>
<div class="sourceCode" id="cb1113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1113-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1113-1" aria-hidden="true"></a>pc &lt;-<span class="st"> </span><span class="kw">prcomp</span>(tissue_gene_expression<span class="op">$</span>x)</span>
<span id="cb1113-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1113-2" aria-hidden="true"></a><span class="kw">data.frame</span>(<span class="dt">pc_1 =</span> pc<span class="op">$</span>x[,<span class="dv">1</span>], <span class="dt">pc_2 =</span> pc<span class="op">$</span>x[,<span class="dv">2</span>], </span>
<span id="cb1113-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1113-3" aria-hidden="true"></a>            <span class="dt">tissue =</span> tissue_gene_expression<span class="op">$</span>y) <span class="op">%&gt;%</span></span>
<span id="cb1113-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1113-4" aria-hidden="true"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(pc_<span class="dv">1</span>, pc_<span class="dv">2</span>, <span class="dt">color =</span> tissue)) <span class="op">+</span></span>
<span id="cb1113-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1113-5" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_point</span>()</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-256-1.png" width="672" /></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
A. cerebellum</li>
<li><input type="checkbox" disabled="" />
B. colon</li>
<li><input type="checkbox" disabled="" />
C. endometrium</li>
<li><input type="checkbox" disabled="" />
D. hippocampus</li>
<li><input type="checkbox" disabled="" />
E. kidney</li>
<li><input type="checkbox" disabled="" checked="" />
F. liver</li>
<li><input type="checkbox" disabled="" />
G. placenta</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>The predictors for each observation are measured using the same device and experimental procedure. This introduces biases that can affect all the predictors from one observation. For each observation, compute the average across all predictors, and then plot this against the first PC with color representing tissue. Report the correlation.</li>
</ol>
<p>What is the correlation?</p>
<div class="sourceCode" id="cb1114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1114-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1114-1" aria-hidden="true"></a>avgs &lt;-<span class="st"> </span><span class="kw">rowMeans</span>(tissue_gene_expression<span class="op">$</span>x)</span>
<span id="cb1114-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1114-2" aria-hidden="true"></a><span class="kw">data.frame</span>(<span class="dt">pc_1 =</span> pc<span class="op">$</span>x[,<span class="dv">1</span>], <span class="dt">avg =</span> avgs, </span>
<span id="cb1114-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1114-3" aria-hidden="true"></a>            <span class="dt">tissue =</span> tissue_gene_expression<span class="op">$</span>y) <span class="op">%&gt;%</span></span>
<span id="cb1114-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1114-4" aria-hidden="true"></a><span class="kw">ggplot</span>(<span class="kw">aes</span>(avgs, pc_<span class="dv">1</span>, <span class="dt">color =</span> tissue)) <span class="op">+</span></span>
<span id="cb1114-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1114-5" aria-hidden="true"></a><span class="st">    </span><span class="kw">geom_point</span>()</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-257-1.png" width="672" /></p>
<div class="sourceCode" id="cb1115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1115-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1115-1" aria-hidden="true"></a><span class="kw">cor</span>(avgs, pc<span class="op">$</span>x[,<span class="dv">1</span>])</span></code></pre></div>
<pre><code>## [1] 0.6</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>We see an association with the first PC and the observation averages. Redo the PCA but only after removing the center. Part of the code is provided for you.</li>
</ol>
<div class="sourceCode" id="cb1117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1117-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1117-1" aria-hidden="true"></a><span class="co">#BLANK</span></span>
<span id="cb1117-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1117-2" aria-hidden="true"></a>pc &lt;-<span class="st"> </span><span class="kw">prcomp</span>(x)</span>
<span id="cb1117-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1117-3" aria-hidden="true"></a><span class="kw">data.frame</span>(<span class="dt">pc_1 =</span> pc<span class="op">$</span>x[,<span class="dv">1</span>], <span class="dt">pc_2 =</span> pc<span class="op">$</span>x[,<span class="dv">2</span>], </span>
<span id="cb1117-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1117-4" aria-hidden="true"></a>       <span class="dt">tissue =</span> tissue_gene_expression<span class="op">$</span>y) <span class="op">%&gt;%</span></span>
<span id="cb1117-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1117-5" aria-hidden="true"></a><span class="st">       </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(pc_<span class="dv">1</span>, pc_<span class="dv">2</span>, <span class="dt">color =</span> tissue)) <span class="op">+</span></span>
<span id="cb1117-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1117-6" aria-hidden="true"></a><span class="st">       </span><span class="kw">geom_point</span>()</span></code></pre></div>
<p>Which line of code should be used to replace #BLANK in the code block above?</p>
<div class="sourceCode" id="cb1118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1118-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1118-1" aria-hidden="true"></a>x &lt;-<span class="st"> </span><span class="kw">with</span>(tissue_gene_expression, <span class="kw">sweep</span>(x, <span class="dv">1</span>, <span class="kw">rowMeans</span>(x)))</span>
<span id="cb1118-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1118-2" aria-hidden="true"></a>pc &lt;-<span class="st"> </span><span class="kw">prcomp</span>(x)</span>
<span id="cb1118-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1118-3" aria-hidden="true"></a><span class="kw">data.frame</span>(<span class="dt">pc_1 =</span> pc<span class="op">$</span>x[,<span class="dv">1</span>], <span class="dt">pc_2 =</span> pc<span class="op">$</span>x[,<span class="dv">2</span>], </span>
<span id="cb1118-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1118-4" aria-hidden="true"></a>       <span class="dt">tissue =</span> tissue_gene_expression<span class="op">$</span>y) <span class="op">%&gt;%</span></span>
<span id="cb1118-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1118-5" aria-hidden="true"></a><span class="st">       </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(pc_<span class="dv">1</span>, pc_<span class="dv">2</span>, <span class="dt">color =</span> tissue)) <span class="op">+</span></span>
<span id="cb1118-6"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1118-6" aria-hidden="true"></a><span class="st">       </span><span class="kw">geom_point</span>()</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-259-1.png" width="672" /></p>
<ul class="task-list">
<li><p><input type="checkbox" disabled="" />
A. <code>x &lt;- with(tissue_gene_expression, sweep(x, 1, mean(x)))</code></p></li>
<li><p><input type="checkbox" disabled="" />
B. <code>x &lt;- sweep(x, 1, rowMeans(tissue_gene_expression$x))</code></p></li>
<li><p><input type="checkbox" disabled="" />
C. <code>x &lt;- tissue_gene_expression$x - mean(tissue_gene_expression$x)</code></p></li>
<li><p><input type="checkbox" disabled="" checked="" />
D. <code>x &lt;- with(tissue_gene_expression, sweep(x, 1, rowMeans(x)))</code></p></li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>For the first 10 PCs, make a boxplot showing the values for each tissue.</li>
</ol>
<p>For the 7th PC, which two tissues have the greatest median difference?</p>
<div class="sourceCode" id="cb1119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1119-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1119-1" aria-hidden="true"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>){</span>
<span id="cb1119-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1119-2" aria-hidden="true"></a>    <span class="kw">boxplot</span>(pc<span class="op">$</span>x[,i] <span class="op">~</span><span class="st"> </span>tissue_gene_expression<span class="op">$</span>y, <span class="dt">main =</span> <span class="kw">paste</span>(<span class="st">&quot;PC&quot;</span>, i))</span>
<span id="cb1119-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1119-3" aria-hidden="true"></a>}</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-260-1.png" width="672" /><img src="img/figures/unnamed-chunk-260-2.png" width="672" /><img src="img/figures/unnamed-chunk-260-3.png" width="672" /><img src="img/figures/unnamed-chunk-260-4.png" width="672" /><img src="img/figures/unnamed-chunk-260-5.png" width="672" /><img src="img/figures/unnamed-chunk-260-6.png" width="672" /><img src="img/figures/unnamed-chunk-260-7.png" width="672" /><img src="img/figures/unnamed-chunk-260-8.png" width="672" /><img src="img/figures/unnamed-chunk-260-9.png" width="672" /><img src="img/figures/unnamed-chunk-260-10.png" width="672" /></p>
<p>Select the TWO tissues that have the greatest difference between their medians.</p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
A. cerebellum</li>
<li><input type="checkbox" disabled="" checked="" />
B. colon</li>
<li><input type="checkbox" disabled="" />
C. endometrium</li>
<li><input type="checkbox" disabled="" />
D. hippocampus</li>
<li><input type="checkbox" disabled="" />
E. kidney</li>
<li><input type="checkbox" disabled="" />
F. liver</li>
<li><input type="checkbox" disabled="" checked="" />
G. placenta</li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li>Plot the percent variance explained by PC number. Hint: use the <code>summary</code> function.</li>
</ol>
<p>How many PCs are required to reach a cumulative percent variance explained greater than 50%? <code>3</code></p>
<div class="sourceCode" id="cb1120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1120-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1120-1" aria-hidden="true"></a><span class="kw">plot</span>(<span class="kw">summary</span>(pc)<span class="op">$</span>importance[<span class="dv">3</span>,])</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-261-1.png" width="672" /></p>
</div>
<div id="comprehension-check---clustering" class="section level2" number="7.16">
<h2><span class="header-section-number">7.16</span> Comprehension Check - Clustering</h2>
<p>These exercises will work with the <code>tissue_gene_expression</code> dataset, which is part of the <strong>dslabs</strong> package.</p>
<ol style="list-style-type: decimal">
<li>Load the <code>tissue_gene_expression</code> dataset. Remove the row means and compute the distance between each observation. Store the result in <code>d</code>.</li>
</ol>
<p>Which of the following lines of code correctly does this computation?</p>
<div class="sourceCode" id="cb1121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1121-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1121-1" aria-hidden="true"></a>d &lt;-<span class="st"> </span><span class="kw">dist</span>(tissue_gene_expression<span class="op">$</span>x <span class="op">-</span><span class="st"> </span><span class="kw">rowMeans</span>(tissue_gene_expression<span class="op">$</span>x))</span></code></pre></div>
<ul class="task-list">
<li><p><input type="checkbox" disabled="" />
A. <code>d &lt;- dist(tissue_gene_expression$x)</code></p></li>
<li><p><input type="checkbox" disabled="" />
B. <code>d &lt;- dist(rowMeans(tissue_gene_expression$x))</code></p></li>
<li><p><input type="checkbox" disabled="" />
C. <code>d &lt;- dist(rowMeans(tissue_gene_expression$y))</code></p></li>
<li><p><input type="checkbox" disabled="" checked="" />
D. <code>d &lt;- dist(tissue_gene_expression$x - rowMeans(tissue_gene_expression$x))</code></p></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Make a hierarchical clustering plot and add the tissue types as labels.</li>
</ol>
<p>You will observe multiple branches.</p>
<p>Which tissue type is in the branch farthest to the left?</p>
<div class="sourceCode" id="cb1122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1122-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1122-1" aria-hidden="true"></a>h &lt;-<span class="st"> </span><span class="kw">hclust</span>(d)</span>
<span id="cb1122-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1122-2" aria-hidden="true"></a><span class="kw">plot</span>(h)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-263-1.png" width="672" /></p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
A. cerebellum</li>
<li><input type="checkbox" disabled="" />
B. colon</li>
<li><input type="checkbox" disabled="" />
C. endometrium</li>
<li><input type="checkbox" disabled="" />
D. hippocampus</li>
<li><input type="checkbox" disabled="" />
E. kidney</li>
<li><input type="checkbox" disabled="" checked="" />
F. liver</li>
<li><input type="checkbox" disabled="" />
G. placenta</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>Select the 50 most variable genes. Make sure the observations show up in the columns, that the predictor are centered, and add a color bar to show the different tissue types. Hint: use the <code>ColSideColors</code> argument to assign colors. Also, use <code>col = RColorBrewer::brewer.pal(11, "RdBu")</code> for a better use of colors.</li>
</ol>
<p>Part of the code is provided for you here:</p>
<div class="sourceCode" id="cb1123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1123-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1123-1" aria-hidden="true"></a><span class="kw">library</span>(RColorBrewer)</span>
<span id="cb1123-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1123-2" aria-hidden="true"></a>sds &lt;-<span class="st"> </span>matrixStats<span class="op">::</span><span class="kw">colSds</span>(tissue_gene_expression<span class="op">$</span>x)</span>
<span id="cb1123-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1123-3" aria-hidden="true"></a>ind &lt;-<span class="st"> </span><span class="kw">order</span>(sds, <span class="dt">decreasing =</span> <span class="ot">TRUE</span>)[<span class="dv">1</span><span class="op">:</span><span class="dv">50</span>]</span>
<span id="cb1123-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1123-4" aria-hidden="true"></a>colors &lt;-<span class="st"> </span><span class="kw">brewer.pal</span>(<span class="dv">7</span>, <span class="st">&quot;Dark2&quot;</span>)[<span class="kw">as.numeric</span>(tissue_gene_expression<span class="op">$</span>y)]</span>
<span id="cb1123-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1123-5" aria-hidden="true"></a><span class="co">#BLANK</span></span></code></pre></div>
<p>Which line of code should replace #BLANK in the code above?</p>
<div class="sourceCode" id="cb1124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1124-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1124-1" aria-hidden="true"></a><span class="cf">if</span>(<span class="op">!</span><span class="kw">require</span>(RColorBrewer)) <span class="kw">install.packages</span>(<span class="st">&quot;RColorBrewer&quot;</span>)</span></code></pre></div>
<pre><code>## Loading required package: RColorBrewer</code></pre>
<div class="sourceCode" id="cb1126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1126-1"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1126-1" aria-hidden="true"></a><span class="kw">library</span>(RColorBrewer)</span>
<span id="cb1126-2"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1126-2" aria-hidden="true"></a>sds &lt;-<span class="st"> </span>matrixStats<span class="op">::</span><span class="kw">colSds</span>(tissue_gene_expression<span class="op">$</span>x)</span>
<span id="cb1126-3"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1126-3" aria-hidden="true"></a>ind &lt;-<span class="st"> </span><span class="kw">order</span>(sds, <span class="dt">decreasing =</span> <span class="ot">TRUE</span>)[<span class="dv">1</span><span class="op">:</span><span class="dv">50</span>]</span>
<span id="cb1126-4"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1126-4" aria-hidden="true"></a>colors &lt;-<span class="st"> </span><span class="kw">brewer.pal</span>(<span class="dv">7</span>, <span class="st">&quot;Dark2&quot;</span>)[<span class="kw">as.numeric</span>(tissue_gene_expression<span class="op">$</span>y)]</span>
<span id="cb1126-5"><a href="section-6-model-fitting-and-recommendation-systems-overview.html#cb1126-5" aria-hidden="true"></a><span class="kw">heatmap</span>(<span class="kw">t</span>(tissue_gene_expression<span class="op">$</span>x[,ind]), <span class="dt">col =</span> <span class="kw">brewer.pal</span>(<span class="dv">11</span>, <span class="st">&quot;RdBu&quot;</span>), <span class="dt">scale =</span> <span class="st">&quot;row&quot;</span>, <span class="dt">ColSideColors =</span> colors)</span></code></pre></div>
<p><img src="img/figures/unnamed-chunk-265-1.png" width="672" /></p>
<ul class="task-list">
<li><p><input type="checkbox" disabled="" checked="" />
A. <code>heatmap(t(tissue_gene_expression$x[,ind]), col = brewer.pal(11, "RdBu"), scale = "row", ColSideColors = colors)</code></p></li>
<li><p><input type="checkbox" disabled="" />
B. <code>heatmap(t(tissue_gene_expression$x[,ind]), col = brewer.pal(11, "RdBu"), scale = "row", ColSideColors = rev(colors))</code></p></li>
<li><p><input type="checkbox" disabled="" />
C. <code>heatmap(t(tissue_gene_expression$x[,ind]), col = brewer.pal(11, "RdBu"), scale = "row", ColSideColors = sample(colors))</code></p></li>
<li><p><input type="checkbox" disabled="" />
D. <code>heatmap(t(tissue_gene_expression$x[,ind]), col = brewer.pal(11, "RdBu"), scale = "row", ColSideColors = sample(colors))</code></p></li>
</ul>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="section-5-classification-with-more-than-two-classes-and-the-caret-package.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="section-7-final-assessment.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
